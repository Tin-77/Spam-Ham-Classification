{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Spam/Ham Classification\n",
    "## Feature Engineering, Logistic Regression, Cross Validation\n",
    "## Due Date: Monday 11/30, 11:59 PM PST\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about\n",
    "the project, we ask that you **write your solutions individually**. If you do\n",
    "discuss the assignments with others please **include their names** at the top\n",
    "of your notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Collaborators**: *Rongsen Li*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "proj2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "## This Assignment\n",
    "In this project, you will use what you've learned in class to create a classifier that can distinguish spam (junk or commercial or bulk) emails from ham (non-spam) emails. In addition to providing some skeleton code to fill in, we will evaluate your work based on your model's accuracy and your written responses in this notebook.\n",
    "\n",
    "After this project, you should feel comfortable with the following:\n",
    "\n",
    "- Feature engineering with text data\n",
    "- Using `sklearn` libraries to process data and fit models\n",
    "- Validating the performance of your model and minimizing overfitting\n",
    "- Generating and analyzing precision-recall curves\n",
    "\n",
    "## Warning\n",
    "This is a **real world** dataset– the emails you are trying to classify are actual spam and legitimate emails. As a result, some of the spam emails may be in poor taste or be considered inappropriate. We think the benefit of working with realistic data outweighs these innapropriate emails, and wanted to give a warning at the beginning of the project so that you are made aware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disclaimer about `sns.distplot()`\n",
    "\n",
    "This project was designed for a slightly older version of seaborn, which does not support the new `displot` method taught in Lecture 9. Instead, in this project will occasionally call `distplot` (with a `t`). As you may have noticed in several of the previous assignments, use of the `distplot` function triggers a deprecation warning to notify the user that they should replace all deprecated functions with the updated version. Generally, warnings should not be suppressed but we will do so in this assignment to avoid cluttering.\n",
    "\n",
    "See the seaborn documentation on [distributions](https://seaborn.pydata.org/tutorial/distributions.html) and [functions](https://seaborn.pydata.org/tutorial/function_overview.html) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to suppress all FutureWarnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Breakdown\n",
    "Question | Points\n",
    "--- | ---\n",
    "1a | 1\n",
    "1b | 1\n",
    "1c | 2\n",
    "2 | 3\n",
    "3a | 2\n",
    "3b | 2\n",
    "4 | 2\n",
    "5 | 2\n",
    "6a | 1\n",
    "6b | 1\n",
    "6c | 2\n",
    "6d | 2\n",
    "6e | 1\n",
    "6f | 3\n",
    "7 | 6\n",
    "8 | 6\n",
    "9 | 3\n",
    "10 | 15\n",
    "Total | 55"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Part I - Initial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:41.341673Z",
     "start_time": "2019-04-03T20:17:41.330307Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "imports",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style = \"whitegrid\", \n",
    "        color_codes = True,\n",
    "        font_scale = 1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "loading",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Loading in the Data\n",
    "\n",
    "In email classification, our goal is to classify emails as spam or not spam (referred to as \"ham\") using features generated from the text in the email. \n",
    "\n",
    "The dataset consists of email messages and their labels (0 for ham, 1 for spam). Your labeled training dataset contains 8348 labeled examples, and the unlabeled test set contains 1000 unlabeled examples.\n",
    "\n",
    "Run the following cells to load in the data into DataFrames.\n",
    "\n",
    "The `train` DataFrame contains labeled data that you will use to train your model. It contains four columns:\n",
    "\n",
    "1. `id`: An identifier for the training example\n",
    "1. `subject`: The subject of the email\n",
    "1. `email`: The text of the email\n",
    "1. `spam`: 1 if the email is spam, 0 if the email is ham (not spam)\n",
    "\n",
    "The `test` DataFrame contains 1000 unlabeled emails. You will predict labels for these emails and submit your predictions to the autograder for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.181245Z",
     "start_time": "2019-04-03T20:17:41.343927Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "fetch-data",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using version already downloaded: Fri Nov 13 15:02:22 2020\n",
      "MD5 hash of file: 0380c4cf72746622947b9ca5db9b8be8\n",
      "Using version already downloaded: Fri Nov 13 15:02:23 2020\n",
      "MD5 hash of file: a2e7abd8c7d9abf6e6fafc1d1f9ee6bf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>subject</th>\n",
       "      <th>email</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Subject: A&amp;L Daily to be auctioned in bankrupt...</td>\n",
       "      <td>url: http://boingboing.net/#85534171\\n date: n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Subject: Wired: \"Stronger ties between ISPs an...</td>\n",
       "      <td>url: http://scriptingnews.userland.com/backiss...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Subject: It's just too small                  ...</td>\n",
       "      <td>&lt;html&gt;\\n &lt;head&gt;\\n &lt;/head&gt;\\n &lt;body&gt;\\n &lt;font siz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Subject: liberal defnitions\\n</td>\n",
       "      <td>depends on how much over spending vs. how much...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Subject: RE: [ILUG] Newbie seeks advice - Suse...</td>\n",
       "      <td>hehe sorry but if you hit caps lock twice the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            subject  \\\n",
       "0   0  Subject: A&L Daily to be auctioned in bankrupt...   \n",
       "1   1  Subject: Wired: \"Stronger ties between ISPs an...   \n",
       "2   2  Subject: It's just too small                  ...   \n",
       "3   3                      Subject: liberal defnitions\\n   \n",
       "4   4  Subject: RE: [ILUG] Newbie seeks advice - Suse...   \n",
       "\n",
       "                                               email  spam  \n",
       "0  url: http://boingboing.net/#85534171\\n date: n...     0  \n",
       "1  url: http://scriptingnews.userland.com/backiss...     0  \n",
       "2  <html>\\n <head>\\n </head>\\n <body>\\n <font siz...     1  \n",
       "3  depends on how much over spending vs. how much...     0  \n",
       "4  hehe sorry but if you hit caps lock twice the ...     0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import fetch_and_cache_gdrive\n",
    "fetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\n",
    "fetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n",
    "\n",
    "original_training_data = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Convert the emails to lower case as a first step to processing the text\n",
    "original_training_data['email'] = original_training_data['email'].str.lower()\n",
    "test['email'] = test['email'].str.lower()\n",
    "\n",
    "original_training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-34476156ed73b800",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1a\n",
    "First, let's check if our data contains any missing values. Fill in the cell below to print the number of NaN values in each column. If there are NaN values, replace them with appropriate filler values (i.e., NaN values in the `subject` or `email` columns should be replaced with empty strings). Print the number of NaN values in each column after this modification to verify that there are no NaN values left.\n",
    "\n",
    "Note that while there are no NaN values in the `spam` column, we should be careful when replacing NaN labels. Doing so without consideration may introduce significant bias into our model when fitting.\n",
    "\n",
    "*The provided test checks that there are no missing values in your dataset.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.203231Z",
     "start_time": "2019-04-03T20:17:42.185104Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b1fb39d9b651ca1b",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "subject    6\n",
       "email      0\n",
       "spam       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_training_data['subject'].fillna('', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         0\n",
       "subject    0\n",
       "email      0\n",
       "spam       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_training_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q1",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 1b\n",
    "\n",
    "In the cell below, print the text of the `email` field for the first ham and the first spam email in the original training set.\n",
    "\n",
    "*The provided tests just ensure that you have assigned `first_ham` and `first_spam` to rows in the data, but only the hidden tests check that you selected the correct observations.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.247245Z",
     "start_time": "2019-04-03T20:17:42.228451Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q1-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url: http://boingboing.net/#85534171\n",
      " date: not supplied\n",
      " \n",
      " arts and letters daily, a wonderful and dense blog, has folded up its tent due \n",
      " to the bankruptcy of its parent company. a&l daily will be auctioned off by the \n",
      " receivers. link[1] discuss[2] (_thanks, misha!_)\n",
      " \n",
      " [1] http://www.aldaily.com/\n",
      " [2] http://www.quicktopic.com/boing/h/zlfterjnd6jf\n",
      " \n",
      " \n",
      "\n",
      "<html>\n",
      " <head>\n",
      " </head>\n",
      " <body>\n",
      " <font size=3d\"4\"><b> a man endowed with a 7-8\" hammer is simply<br>\n",
      "  better equipped than a man with a 5-6\"hammer. <br>\n",
      " <br>would you rather have<br>more than enough to get the job done or fall =\n",
      " short. it's totally up<br>to you. our methods are guaranteed to increase y=\n",
      " our size by 1-3\"<br> <a href=3d\"http://209.163.187.47/cgi-bin/index.php?10=\n",
      " 004\">come in here and see how</a>\n",
      " </body>\n",
      " </html>\n",
      " \n",
      " \n",
      " \n",
      "\n"
     ]
    }
   ],
   "source": [
    "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\n",
    "first_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\n",
    "print(first_ham)\n",
    "print(first_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 1c\n",
    "\n",
    "Discuss one thing you notice that is different between the two emails that might relate to the identification of spam.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q1c\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_While ham typically lacks HTML in the email body and contains normal English sentences such as a short description or words of gratitude, spam often has HTML code to emphasize marketing phrases._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-78513403ef52a957",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "## Training Validation Split\n",
    "The training data we downloaded is all the data we have available for both training models and **validating** the models that we train.  We therefore need to split the training data into separate training and validation datsets.  You will need this **validation data** to assess the performance of your classifier once you are finished training. Note that we set the seed (random_state) to 42. This will produce a pseudo-random sequence of random numbers that is the same for every student. **Do not modify this in the following questions, as our tests depend on this random seed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.317970Z",
     "start_time": "2019-04-03T20:17:42.294532Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-873194ed3e686dfb",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This creates a 90/10 train-validation split on our labeled data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, val = train_test_split(original_training_data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "feat-eng",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Basic Feature Engineering\n",
    "\n",
    "We would like to take the text of an email and predict whether the email is ham or spam. This is a *classification* problem, so we can use logistic regression to train a classifier. Recall that to train an logistic regression model we need a numeric feature matrix $X$ and a vector of corresponding binary labels $y$.  Unfortunately, our data are text, not numbers. To address this, we can create numeric features derived from the email text and use those features for logistic regression.\n",
    "\n",
    "Each row of $X$ is an email. Each column of $X$ contains one feature for all the emails. We'll guide you through creating a simple feature, and you'll create more interesting ones as you try to increase the accuracy of your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 2\n",
    "\n",
    "Create a function called `words_in_texts` that takes in a list of `words` and a pandas Series of email `texts`. It should output a 2-dimensional NumPy array containing one row for each email text. The row should contain either a 0 or a 1 for each word in the list: 0 if the word doesn't appear in the text and 1 if the word does. For example:\n",
    "\n",
    "```\n",
    ">>> words_in_texts(['hello', 'bye', 'world'], \n",
    "                   pd.Series(['hello', 'hello worldhello']))\n",
    "\n",
    "array([[1, 0, 0],\n",
    "       [1, 0, 1]])\n",
    "```\n",
    "\n",
    "*The provided tests make sure that your function works correctly, so that you can use it for future questions.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q2\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.337281Z",
     "start_time": "2019-04-03T20:17:42.320567Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q2-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [],
   "source": [
    "def words_in_texts(words, texts):\n",
    "    '''\n",
    "    Args:\n",
    "        words (list): words to find\n",
    "        texts (Series): strings to search in\n",
    "    \n",
    "    Returns:\n",
    "        NumPy array of 0s and 1s with shape (n, p) where n is the\n",
    "        number of texts and p is the number of words.\n",
    "    '''\n",
    "    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n",
    "    return indicator_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "eda",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "# Basic EDA\n",
    "\n",
    "We need to identify some features that allow us to distinguish spam emails from ham emails. One idea is to compare the distribution of a single feature in spam emails to the distribution of the same feature in ham emails. If the feature is itself a binary indicator, such as whether a certain word occurs in the text, this amounts to comparing the proportion of spam emails with the word to the proportion of ham emails with the word.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3a",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following plot (which was created using `sns.barplot`) compares the proportion of emails in each class containing a particular set of words. \n",
    "\n",
    "![training conditional proportions](images/training_conditional_proportions.png)\n",
    "\n",
    "You can use DataFrame's `.melt` method to \"unpivot\" a DataFrame. See the following code cell for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:42.428419Z",
     "start_time": "2019-04-03T20:17:42.386697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word_1</th>\n",
       "      <th>word_2</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   word_1  word_2  type\n",
       "0       1       0  spam\n",
       "1       0       1   ham\n",
       "2       1       0   ham\n",
       "3       0       1   ham"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>word_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spam</td>\n",
       "      <td>word_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>word_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type variable  value\n",
       "0  spam   word_1      1\n",
       "1   ham   word_1      0\n",
       "2   ham   word_1      1\n",
       "3   ham   word_1      0\n",
       "4  spam   word_2      0\n",
       "5   ham   word_2      1\n",
       "6   ham   word_2      0\n",
       "7   ham   word_2      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "df = pd.DataFrame({\n",
    "    'word_1': [1, 0, 1, 0],\n",
    "    'word_2': [0, 1, 0, 1],\n",
    "    'type': ['spam', 'ham', 'ham', 'ham']\n",
    "})\n",
    "display(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\n",
    "display(df);\n",
    "display(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\n",
    "display(df.melt(\"type\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3a\n",
    "\n",
    "Create a bar chart like the one above comparing the proportion of spam and ham emails containing certain words. Choose a set of words that are different from the ones above, but also have different proportions for the two classes. Make sure to only consider emails from `train`.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3a\n",
    "manual: True\n",
    "format: image\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\n",
    "temp = words_in_texts(words, train[\"email\"]).T\n",
    "df = pd.DataFrame({\n",
    "    \"sale\":  temp[0],\n",
    "    \"credit\": temp[1],\n",
    "    \"link\": temp[2],\n",
    "    \"click\": temp[3],\n",
    "    \"off\": temp[4],\n",
    "    \"win\": temp[5],\n",
    "    'type': train[\"spam\"]\n",
    "})\n",
    "df = df.melt(\"type\")\n",
    "d = df.groupby([\"type\",\"variable\"]).mean()\n",
    "d = d.reset_index()\n",
    "d = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\n",
    "plt.figure(figsize=(8,8))\n",
    "sns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\n",
    "plt.ylim(0, 1)\n",
    "plt.xlabel(\"Words\")\n",
    "plt.ylabel(\"Proportion of Emails\")\n",
    "plt.legend(title = \"\")\n",
    "plt.title(\"Frequency of Words in Spam/Ham Emails\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q3b",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "When the feature is binary, it makes sense to compare its proportions across classes (as in the previous question). Otherwise, if the feature can take on numeric values, we can compare the distributions of these values for different classes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 3b\n",
    "\n",
    "![training conditional densities](images/training_conditional_densities.png)\n",
    "\n",
    "Create a *class conditional density plot* like the one above (using `sns.distplot`), comparing the distribution of the length of spam emails to the distribution of the length of ham emails in the training set. Set the x-axis limit from 0 to 50000.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q3b\n",
    "manual: True\n",
    "format: image\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.492661Z",
     "start_time": "2019-04-03T20:17:43.149431Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q3b-answer",
     "locked": false,
     "points": 2,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "c = train.copy()\n",
    "c[\"length\"] = [len(i) for i in c[\"email\"]]\n",
    "x1 = c[c[\"spam\"] == 0][\"length\"]\n",
    "x2 = c[c[\"spam\"] == 1][\"length\"]\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(x1, hist=False, label = \"Ham\")\n",
    "sns.distplot(x2, hist=False, label = \"Spam\")\n",
    "plt.legend()\n",
    "plt.xlim(0,50000)\n",
    "plt.ylabel(\"Distribution\")\n",
    "plt.xlabel(\"Length of email body\")\n",
    "plt.title(\"Distribution of Email Body Length\")\n",
    "plt.savefig('training_conditional_densities.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "classification",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# Basic Classification\n",
    "\n",
    "Notice that the output of `words_in_texts(words, train['email'])` is a numeric matrix containing features for each email. This means we can use it directly to train a classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q4",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 4\n",
    "\n",
    "We've given you 5 words that might be useful as features to distinguish spam/ham emails. Use these words as well as the `train` DataFrame to create two NumPy arrays: `X_train` and `Y_train`.\n",
    "\n",
    "`X_train` should be a matrix of 0s and 1s created by using your `words_in_texts` function on all the emails in the training set.\n",
    "\n",
    "`Y_train` should be a vector of the correct labels for each email in the training set.\n",
    "\n",
    "*The provided tests check that the dimensions of your feature matrix (X) are correct, and that your features and labels are binary (i.e. consists of only 0's and 1's). It does not check that your function is correct; that was verified in a previous question.*\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q4\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:43.726012Z",
     "start_time": "2019-04-03T20:17:43.498088Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q4-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0]]),\n",
       " array([0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n",
    "\n",
    "X_train = words_in_texts(some_words, train[\"email\"])\n",
    "Y_train = np.array(train[\"spam\"])\n",
    "\n",
    "X_train[:5], Y_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q5",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 5\n",
    "\n",
    "Now that we have matrices, we can build a model with `scikit-learn`! Using the [`LogisticRegression`](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) classifier, train a logistic regression model using `X_train` and `Y_train`. Then, output the model's training accuracy below. You should get an accuracy of around $0.75$\n",
    "\n",
    "*The provided test checks that you initialized your logistic regression model correctly.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q5\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:17:44.593918Z",
     "start_time": "2019-04-03T20:17:43.783872Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q5-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.7576201251164648\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "training_accuracy = model.score(X_train, Y_train)\n",
    "print(\"Training Accuracy: \", training_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That doesn't seem too shabby! But the classifier you made above isn't as good as the accuracy would make you believe. First, we are evaluating accuracy on the training set, which may provide a misleading accuracy measure. Accuracy on the training set doesn't always translate to accuracy in the real world (on the test set). In future parts of this analysis, we will hold out some of our data for model validation and comparison.\n",
    "\n",
    "Presumably, our classifier will be used for **filtering**, i.e. preventing messages labeled `spam` from reaching someone's inbox. There are two kinds of errors we can make:\n",
    "- False positive (FP): a ham email gets flagged as spam and filtered out of the inbox.\n",
    "- False negative (FN): a spam email gets mislabeled as ham and ends up in the inbox.\n",
    "\n",
    "To be clear, we label spam emails as 1 and ham emails as 0. These definitions depend both on the true labels and the predicted labels. False positives and false negatives may be of differing importance, leading us to consider more ways of evaluating a classifier, in addition to overall accuracy:\n",
    "\n",
    "**Precision** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FP}}$ of emails flagged as spam that are actually spam.\n",
    "\n",
    "**Recall** measures the proportion $\\frac{\\text{TP}}{\\text{TP} + \\text{FN}}$ of spam emails that were correctly flagged as spam. \n",
    "\n",
    "**False-alarm rate** measures the proportion $\\frac{\\text{FP}}{\\text{FP} + \\text{TN}}$ of ham emails that were incorrectly flagged as spam. \n",
    "\n",
    "The two graphics below may help you understand precision and recall visually:\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png\" width=\"500px\">\n",
    "\n",
    "Note that a true positive (TP) is a spam email that is classified as spam, and a true negative (TN) is a ham email that is classified as ham."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q6",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "### Question 6a\n",
    "\n",
    "Suppose we have a classifier `zero_predictor` that always predicts 0 (never predicts positive). How many false positives and false negatives would this classifier have if it were evaluated on the training set and its results were compared to `Y_train`? Fill in the variables below (feel free to hard code your answers for this part):\n",
    "\n",
    "*Tests in Question 6 only check that you have assigned appropriate types of values to each response variable, but do not check that your answers are correct.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6a\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:20:13.853633Z",
     "start_time": "2019-04-03T20:20:13.825724Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q6a-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1918)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_predictor_fp = 0\n",
    "zero_predictor_fn = np.sum(Y_train != 0)\n",
    "zero_predictor_fp, zero_predictor_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Question 6b\n",
    "\n",
    "What is the accuracy and recall of `zero_predictor` (classifies every email as ham) on the training set? Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6b\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:23:21.553134Z",
     "start_time": "2019-04-03T20:23:21.548219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7447091707706642, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\n",
    "zero_predictor_recall = 0\n",
    "zero_predictor_acc, zero_predictor_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6c\n",
    "\n",
    "Provide brief explanations of the results from 6a and 6b. Why do we observe each of these values (FP, FN, accuracy, recall)?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6c\n",
    "manual: True\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP is 0. Since we consider every email as ham, there is no spam in our prediction. \n",
    "\n",
    "FN is 1918. Since we predict every spam as ham, the number of FN is the number of spam in the training data. \n",
    "\n",
    "Accuracy is about 0.7447. Since TP is 0, we only need to count TN/n. \n",
    "\n",
    "Recall is 0. Since TP is 0 and Recall = TP/(TP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "### Question 6d\n",
    "\n",
    "Compute the precision, recall, and false-alarm rate of the `LogisticRegression` classifier created and trained in Question 5. Do **NOT** use any `sklearn` functions.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6d\n",
    "points: 2\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-03T20:37:54.875265Z",
     "start_time": "2019-04-03T20:37:54.720667Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_train)\n",
    "TP = np.sum((pred == Y_train) & (Y_train == 1))\n",
    "TN = np.sum((pred == Y_train) & (Y_train == 0))\n",
    "FP = np.sum((pred != Y_train) & (Y_train == 0))\n",
    "FN = np.sum((pred != Y_train) & (Y_train == 1))\n",
    "logistic_predictor_precision = TP/(TP+FP)\n",
    "logistic_predictor_recall = TP/(TP+FN)\n",
    "logistic_predictor_far = FP/(FP+TN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6e\n",
    "\n",
    "Are there more false positives or false negatives when using the logistic regression classifier from Question 5?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6e\n",
    "manual: True\n",
    "points: 1\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_There are more FN than FP when using the logistic regression classifier from Question 5._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 6f\n",
    "\n",
    "1. Our logistic regression classifier got 75.76% prediction accuracy (number of correct predictions / total). How does this compare with predicting 0 for every email?\n",
    "1. Given the word features we gave you above, name one reason this classifier is performing poorly. Hint: Think about how prevalent these words are in the email set.\n",
    "1. Which of these two classifiers would you prefer for a spam filter and why? Describe your reasoning and relate it to at least one of the evaluation metrics you have computed so far.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q6f\n",
    "manual: True\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Accuracy = 0.7447 when predicting 0 for every email. Logistic regression classifier has a slightly better prediction accuracy.\n",
    "\n",
    "2) The design matrix contains rows with all 0's and the words we picked do not appear in many emails, therefore, the classifer won't be able to classify spam correctly. \n",
    "\n",
    "3) Since the LogisticRegression ends up with a fairly high 2.2% false alarm rate, I won't trust this classifier. I prefer all email to come into my inbox without any filtering process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "p2",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "# Part II - Moving Forward\n",
    "\n",
    "With this in mind, it is now your task to make the spam filter more accurate. In order to get full credit on the accuracy part of this assignment, you must get at least **88%** accuracy on the test set. To see your accuracy on the test set, you will use your classifier to predict every email in the `test` DataFrame and upload your predictions to Gradescope.\n",
    "\n",
    "**Gradescope limits you to four submissions per day**. This means you should start early so you have time if needed to refine your model. You will be able to see your accuracy on 70% of the test set when submitting to Gradescope, but we will be evaluating your model on the entire test set so try to score slightly above 88% on gradescope if you can.\n",
    "\n",
    "Here are some ideas for improving your model:\n",
    "\n",
    "1. Finding better features based on the email text. Some example features are:\n",
    "    1. Number of characters in the subject / body\n",
    "    1. Number of words in the subject / body\n",
    "    1. Use of punctuation (e.g., how many '!'s were there?)\n",
    "    1. Number / percentage of capital letters \n",
    "    1. Whether the email is a reply to an earlier email or a forwarded email\n",
    "1. Finding better (and/or more) words to use as features. Which words are the best at distinguishing emails? This requires digging into the email text itself. \n",
    "1. Better data processing. For example, many emails contain HTML as well as text. You can consider extracting out the text from the HTML to help you find better words. Or, you can match HTML tags themselves, or even some combination of the two.\n",
    "1. Model selection. You can adjust parameters of your model (e.g. the regularization parameter) to achieve higher accuracy. Recall that you should use cross-validation to do feature and model selection properly! Otherwise, you will likely overfit to your training data.\n",
    "\n",
    "You may use whatever method you prefer in order to create features, but **you are not allowed to import any external feature extraction libraries**. In addition, **you are only allowed to train logistic regression models**. No random forests, k-nearest-neighbors, neural nets, etc.\n",
    "\n",
    "We have not provided any code to do this, so feel free to create as many cells as you need in order to tackle this task. However, answering questions 7, 8, and 9 should help guide you.\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** *You may want to use your **validation data** to evaluate your model and get a better sense of how it will perform on the test set.* Note, however, that you may overfit to your validation set if you try to optimize your validation accuracy too much.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q7",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 7: Feature/Model Selection Process\n",
    "\n",
    "In this following cell, describe the process of improving your model. You should use at least 2-3 sentences each to address the follow questions:\n",
    "\n",
    "1. How did you find better features for your model?\n",
    "2. What did you try that worked or didn't work?\n",
    "3. What was surprising in your search for good features?\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q7\n",
    "manual: True\n",
    "points: 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. I found the words that have relatively higher frequencies of appeareance in the spam emails. \n",
    "\n",
    "2. I tried to put more words with a high frequency appearence in the spam emails to determine whether an email is spam or ham, and it seems to work. \n",
    "\n",
    "3. It is surprsing to see that there are so many weird words in the spam emails that I even cannot read or recogonize those words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "q8",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "\n",
    "\n",
    "### Question 8: EDA\n",
    "\n",
    "In the cell below, show a visualization that you used to select features for your model. \n",
    "\n",
    "Include:\n",
    "\n",
    "1. A plot showing something meaningful about the data that helped you during feature selection, model selection, or both.\n",
    "2. Two or three sentences describing what you plotted and its implications with respect to your features.\n",
    "\n",
    "Feel free to create as many plots as you want in your process of feature selection, but select only one for the response cell below.\n",
    "\n",
    "**You should not just produce an identical visualization to question 3.** Specifically, don't show us a bar chart of proportions, or a one-dimensional class-conditional density plot. Any other plot is acceptable, **as long as it comes with thoughtful commentary.** Here are some ideas:\n",
    "\n",
    "1. Consider the correlation between multiple features (look up correlation plots and `sns.heatmap`). \n",
    "1. Try to show redundancy in a group of features (e.g. `body` and `html` might co-occur relatively frequently, or you might be able to design a feature that captures all html tags and compare it to these). \n",
    "1. Visualize which words have high or low values for some useful statistic.\n",
    "1. Visually depict whether spam emails tend to be wordier (in some sense) than ham emails."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Generate your visualization in the cell below and provide your description in a comment.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q8\n",
    "manual: True\n",
    "format: image\n",
    "points: 6\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>word</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>font</th>\n",
       "      <td>53116722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3d</th>\n",
       "      <td>37044057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>28436137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>23954172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>to</th>\n",
       "      <td>19952505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_nextpart_000_00c3_53c41c0d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreword</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_nextpart_000_00c3_00c72e6d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_nextpart_000_00c2_37c70c2d</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_nextpart_000_00a3_00e67d7e</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69342 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  num\n",
       "word                                 \n",
       "font                         53116722\n",
       "3d                           37044057\n",
       "the                          28436137\n",
       "a                            23954172\n",
       "to                           19952505\n",
       "...                               ...\n",
       "_nextpart_000_00c3_53c41c0d         0\n",
       "foreword                            0\n",
       "_nextpart_000_00c3_00c72e6d         0\n",
       "_nextpart_000_00c2_37c70c2d         0\n",
       "_nextpart_000_00a3_00e67d7e         0\n",
       "\n",
       "[69342 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parts of the code below come from hw4 - Trump Tweets\n",
    "# I counted words used in spam emails and sorted by their frequencies\n",
    "\n",
    "spam_email = train[train[\"spam\"] == 1][\"email\"]\n",
    "punct_re = r'[^\\w\\s]'\n",
    "spam_email = spam_email.str.replace(punct_re, \" \")\n",
    "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\n",
    "tidy_format.index.name = None\n",
    "cnt = tidy_format.groupby('word').sum().sort_values(by = 'num', ascending = False) \n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:36.170465Z",
     "start_time": "2019-04-02T00:27:36.167776Z"
    },
    "nbgrader": {
     "grade": true,
     "grade_id": "q8-eda",
     "locked": false,
     "points": 3,
     "schema_version": 2,
     "solution": true
    },
    "tags": [
     "student",
     "written",
     "q_eda1"
    ]
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Write your description (2-3 sentences) as a comment here:\n",
    "# I counted the most frequent words from spam emails\n",
    "# I started by using the first 50 most frequent words to determine spam emails\n",
    "# Then I used more words to increase the accuracy of determining spam emails\n",
    "\n",
    "# Write the code to generate your visualization here:\n",
    "def getAccuracy(words):\n",
    "    X_train_q8 = words_in_texts(words_q8, train['email'])\n",
    "    model_q8 = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "    model_q8.fit(X_train_q8, Y_train)\n",
    "    accuracy_q8 = model_q8.score(X_train_q8, Y_train)\n",
    "    return accuracy_q8\n",
    "\n",
    "# Store all the accuracy as adding more words into the word-list to train my model\n",
    "accuracyList = np.array([])\n",
    "\n",
    "# start with 50 words.\n",
    "words_q8 = np.array(cnt.reset_index()['word'][:50])\n",
    "accuracyList = np.append(accuracyList, getAccuracy(words_q8))\n",
    "\n",
    "# 100 words\n",
    "words_q8 = np.array(cnt.reset_index()['word'][:100])\n",
    "accuracyList = np.append(accuracyList, getAccuracy(words_q8))\n",
    "\n",
    "# 150 words\n",
    "words_q8 = np.array(cnt.reset_index()['word'][:150])\n",
    "accuracyList = np.append(accuracyList, getAccuracy(words_q8))\n",
    "\n",
    "# 200 words\n",
    "words_q8 = np.array(cnt.reset_index()['word'][:200])\n",
    "accuracyList = np.append(accuracyList, getAccuracy(words_q8))\n",
    "\n",
    "# 250 words\n",
    "words_q8 = np.array(cnt.reset_index()['word'][:250])\n",
    "accuracyList = np.append(accuracyList, getAccuracy(words_q8))\n",
    "\n",
    "# 300 words\n",
    "words_q8 = np.array(cnt.reset_index()['word'][:300])\n",
    "accuracyList = np.append(accuracyList, getAccuracy(words_q8))\n",
    "\n",
    "# 350 words\n",
    "words_q8 = np.array(cnt.reset_index()['word'][:350])\n",
    "accuracyList = np.append(accuracyList, getAccuracy(words_q8))\n",
    "\n",
    "# 400 words\n",
    "words_q8 = np.array(cnt.reset_index()['word'][:400])\n",
    "accuracyList = np.append(accuracyList, getAccuracy(words_q8))\n",
    "\n",
    "acc_df = pd.DataFrame({\"Number of Words\": [50, 100, 150, 200, 250, 300, 350, 400], \n",
    "                      \"Accuracy Probability\": accuracyList})\n",
    "sns.scatterplot(data=acc_df, x=\"Number of Words\", y=\"Accuracy Probability\");\n",
    "plt.xlim(0, 450)\n",
    "plt.ylim(0.5, 1);\n",
    "plt.title(\"Number of Words vs Accuracy Probability\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q9",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "### Question 9: ROC Curve\n",
    "\n",
    "In most cases we won't be able to get 0 false positives and 0 false negatives, so we have to compromise. For example, in the case of cancer screenings, false negatives are comparatively worse than false positives — a false negative means that a patient might not discover that they have cancer until it's too late, whereas a patient can just receive another screening for a false positive.\n",
    "\n",
    "Recall that logistic regression calculates the probability that an example belongs to a certain class. Then, to classify an example we say that an email is spam if our classifier gives it $\\ge 0.5$ probability of being spam. However, *we can adjust that cutoff*: we can say that an email is spam only if our classifier gives it $\\ge 0.7$ probability of being spam, for example. This is how we can trade off false positives and false negatives.\n",
    "\n",
    "The ROC curve shows this trade off for each possible cutoff probability. In the cell below, plot a ROC curve for your final classifier (the one you use to make predictions for Gradescope) on the training data. Refer to Lecture 19 or [Section 17.7](https://www.textbook.ds100.org/ch/17/classification_sensitivity_specificity.html) of the course text to see how to plot an ROC curve.\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q9\n",
    "manual: True\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# Note that you'll want to use the .predict_proba(...) method for your classifier\n",
    "# instead of .predict(...) so you get probabilities, not classes\n",
    "\n",
    "words2 = np.array(cnt.reset_index()['word'][:10000])\n",
    "\n",
    "X_train2 = words_in_texts(words2, train['email'])\n",
    "\n",
    "model2 = LogisticRegression(solver='lbfgs', max_iter=15000)\n",
    "model2.fit(X_train2, Y_train)\n",
    "\n",
    "accuracy2 = model2.score(X_train2, Y_train)\n",
    "print(accuracy2)\n",
    "\n",
    "pred2 = model2.predict_proba(X_train2)\n",
    "\n",
    "FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n",
    "\n",
    "plt.plot(FPR, TPR)\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "q10",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "# Question 10: Test Predictions\n",
    "\n",
    "The following code will write your predictions on the test dataset to a CSV file. **You will need to submit this file to the \"Project 2 Test Predictions\" assignment on Gradescope to get credit for this question.**\n",
    "\n",
    "Save your predictions in a 1-dimensional array called `test_predictions`. **Please make sure you've saved your predictions to `test_predictions` as this is how part of your score for this question will be determined.**\n",
    "\n",
    "Remember that if you've performed transformations or featurization on the training data, you must also perform the same transformations on the test data in order to make predictions. For example, if you've created features for the words \"drug\" and \"money\" on the training data, you must also extract the same features in order to use scikit-learn's `.predict(...)` method.\n",
    "\n",
    "**Note: You may submit up to 4 times a day. If you have submitted 4 times on a day, you will need to wait until the next day for more submissions.**\n",
    "\n",
    "Note that this question is graded on an absolute scale based on the accuracy your model achieves on the overall test set, and as such, your score does not depend on your ranking on Gradescope. Your public Gradescope results are based off of your classifier's accuracy on 70% of the test dataset and your score for this question will be based off of your classifier's accuracy on 100% of the test set.\n",
    "\n",
    "*The provided tests check that your predictions are in the correct format, but you must additionally submit to Gradescope to evaluate your classifier accuracy.*\n",
    "\n",
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: q10\n",
    "points: 3\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:38.650695Z",
     "start_time": "2019-04-02T00:27:38.469233Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "q10-answer",
     "locked": false,
     "schema_version": 2,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = model2.predict(words_in_texts(words2, test['email']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    "
      ],
      "text/plain": [
       "\n",
       "    All tests passed!\n",
       "    "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d15e30e2a961277d",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "source": [
    "The following cell generates a CSV file with your predictions. **You must submit this CSV file to the \"Project 2 Test Predictions\" assignment on Gradescope to get credit for this question.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-02T00:27:39.986326Z",
     "start_time": "2019-04-02T00:27:38.385Z"
    },
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8dd1bfadcbe08b00",
     "locked": true,
     "schema_version": 2,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a CSV file: submission_2020-11-30T17:26:38.csv.\n",
      "You may now upload this CSV file to Gradescope for scoring.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n",
    "# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n",
    "\n",
    "# Construct and save the submission:\n",
    "submission_df = pd.DataFrame({\n",
    "    \"Id\": test['id'], \n",
    "    \"Class\": test_predictions,\n",
    "}, columns=['Id', 'Class'])\n",
    "timestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\n",
    "submission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n",
    "\n",
    "print('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\n",
    "print('You may now upload this CSV file to Gradescope for scoring.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong>q10:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>q1a:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>q1b:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>q2:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>q4:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>q5:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>q6a:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>q6b:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n",
       "<p><strong>q6d:</strong></p>\n",
       "\n",
       "    \n",
       "    \n",
       "        <p>All tests passed!</p>\n",
       "    \n",
       "    \n",
       "\n"
      ],
      "text/plain": [
       "q10:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "q1a:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "q1b:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "q2:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "q4:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "q5:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "q6a:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "q6b:\n",
       "\n",
       "    All tests passed!\n",
       "    \n",
       "\n",
       "q6d:\n",
       "\n",
       "    All tests passed!\n",
       "    \n"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <p>Your submission has been exported. Click <a href=\"proj2.zip\" target=\"_blank\">here</a> \n",
       "                to download the zip file.</p>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(\"proj2.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "history": [
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\n# BEGIN SOLUTION\nsome_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\nPhi_train = words_in_texts(some_words, train['email'])\n\ndf = pd.DataFrame(data = Phi_train, columns = some_words)\ndf['label'] = train['spam']\n\nplt.figure(figsize=(12,8))\nsns.barplot(x = \"variable\", \n            y = \"value\", \n            hue = \"label\", \n            data = (df\n                    .replace({'label': \n                                {0 : 'Ham', \n                                 1 : 'Spam'}})\n                    .melt('label')\n                    .groupby(['label', 'variable'])\n                    .mean()\n                    .reset_index()))\n\nplt.xlabel('Words')\nplt.ylabel('Proportion of Emails')\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show()\n# END SOLUTION",
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "idx": 33,
    "time": "2020-11-13T17:39:00.446Z",
    "type": "execution"
   },
   {
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "time": "2020-11-13T17:39:00.597Z",
    "type": "completion"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "bf4059a762a047a6a8e4179dc2c11815",
    "idx": 5,
    "time": "2020-11-13T17:39:15.247Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "679de399389b410fbd1bd229389869ba",
    "idx": 8,
    "time": "2020-11-13T17:39:15.251Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "668f75f782c041508f9e0c8f82311ad1",
    "idx": 10,
    "time": "2020-11-13T17:39:15.256Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\nprint('Before imputation:')\nprint(original_training_data.isnull().sum())\noriginal_training_data = original_training_data.fillna('')\nprint('------------')\nprint('After imputation:')\nprint(original_training_data.isnull().sum())\n# END SOLUTION",
    "id": "68e38b511a2c4f5480d4eda2b0082a11",
    "idx": 12,
    "time": "2020-11-13T17:39:15.259Z",
    "type": "execution"
   },
   {
    "code": "# TEST\noriginal_training_data.isnull().sum().sum() == 0",
    "id": "7f4b00c62776443e817cd5a255aa14b9",
    "idx": 13,
    "time": "2020-11-13T17:39:15.261Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] # SOLUTION\nfirst_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] # SOLUTION\nprint(first_ham)\nprint(first_spam)",
    "id": "bfb55fdfdfb1456785bb78790aad426b",
    "idx": 15,
    "time": "2020-11-13T17:39:15.264Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlen(first_ham) > 0 and first_ham[:0] == ''",
    "id": "6345c5019a384a618017acbb080996d9",
    "idx": 16,
    "time": "2020-11-13T17:39:15.265Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlen(first_spam) > 0 and first_spam[:0] == ''",
    "id": "ee844f20ed0a41c4b81ff495fe482bdf",
    "idx": 17,
    "time": "2020-11-13T17:39:15.268Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] in first_ham",
    "id": "13a350f12fac4931be17235a1daf0a93",
    "idx": 18,
    "time": "2020-11-13T17:39:15.270Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] in first_spam",
    "id": "a90683e4a73346878a06d732d7101c87",
    "idx": 19,
    "time": "2020-11-13T17:39:15.272Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "7523257e508447369ca710ce27eba7b1",
    "idx": 23,
    "time": "2020-11-13T17:39:15.276Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = 1 * np.array([texts.str.contains(word) for word in words]).T # SOLUTION\n    return indicator_array",
    "id": "81aa3a295d054268acb33351ad567192",
    "idx": 26,
    "time": "2020-11-13T17:39:15.279Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['hello', 'bye', 'world'], \n                           pd.Series(['hello', 'hello worldhello'])),\n            np.array([[1, 0, 0], \n                      [1, 0, 1]]))",
    "id": "690ffc0aa5e446949b45a8b4ecd76f85",
    "idx": 27,
    "time": "2020-11-13T17:39:15.282Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['a', 'b', 'c', 'd', 'e', 'f', 'g'], \n                           pd.Series(['a b c d ef g', 'a', 'b', 'c', 'd e f g', 'h', 'a h'])),\n            np.array([[1,1,1,1,1,1,1], \n                      [1,0,0,0,0,0,0],\n                      [0,1,0,0,0,0,0],\n                      [0,0,1,0,0,0,0],\n                      [0,0,0,1,1,1,1],\n                      [0,0,0,0,0,0,0],\n                      [1,0,0,0,0,0,0]]))",
    "id": "c3fba6032da048efaf5bf9b349cfb4f8",
    "idx": 28,
    "time": "2020-11-13T17:39:15.284Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "c248bceea6bd440c870eb7f942fcf77e",
    "idx": 31,
    "time": "2020-11-13T17:39:15.289Z",
    "type": "execution"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\n# BEGIN SOLUTION\nsome_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\nPhi_train = words_in_texts(some_words, train['email'])\n\ndf = pd.DataFrame(data = Phi_train, columns = some_words)\ndf['label'] = train['spam']\n\nplt.figure(figsize=(12,8))\nsns.barplot(x = \"variable\", \n            y = \"value\", \n            hue = \"label\", \n            data = (df\n                    .replace({'label': \n                                {0 : 'Ham', \n                                 1 : 'Spam'}})\n                    .melt('label')\n                    .groupby(['label', 'variable'])\n                    .mean()\n                    .reset_index()))\n\nplt.xlabel('Words')\nplt.ylabel('Proportion of Emails')\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show()\n# END SOLUTION",
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "idx": 33,
    "time": "2020-11-13T17:39:15.291Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\ntmp = train.copy()\ntmp['length'] = tmp['email'].str.len()\nplt.figure(figsize=(10, 6))\nsns.distplot(tmp.loc[tmp['spam'] == 0, 'length'],hist=False, label='Ham')\nsns.distplot(tmp.loc[tmp['spam'] == 1, 'length'],hist=False, label='Spam')\nplt.title('Distribution of Email Body Length')\nplt.xlabel('Length of email body')\nplt.ylabel('Distribution')\nplt.xlim((0,50000))\nplt.tight_layout()\nplt.legend();\n# END SOLUTION",
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "idx": 36,
    "time": "2020-11-13T17:39:15.295Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train['email']) # SOLUTION\nY_train = np.array(train['spam']) # SOLUTION\n\nX_train[:5], Y_train[:5]",
    "id": "4228df6326c449d782e8471fb2f787fe",
    "idx": 39,
    "time": "2020-11-13T17:39:15.297Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nX_train.shape == (7513, 5)",
    "id": "16be536580a04248971c0fcb94bb3f0e",
    "idx": 40,
    "time": "2020-11-13T17:39:15.299Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(X_train), np.array([0, 1])) # X matrix should consist of only 0 or 1",
    "id": "dc0cb916fcc5470885a644448fa6684c",
    "idx": 41,
    "time": "2020-11-13T17:39:15.301Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(Y_train), np.array([0, 1])) # y vector should consist of only 0 or 1",
    "id": "7b8699ffc3414488a9d374ae3a762231",
    "idx": 42,
    "time": "2020-11-13T17:39:15.303Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver = 'lbfgs') # SOLUTION\nmodel.fit(X_train, Y_train) # SOLUTION\n\ntraining_accuracy = model.score(X_train, Y_train) # SOLUTION\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "6a1a859678394a819af601759e1b4c0d",
    "idx": 44,
    "time": "2020-11-13T17:39:15.305Z",
    "type": "execution"
   },
   {
    "code": "# TEST\ntraining_accuracy > 0.72",
    "id": "45afd18c3a604fd8825017255e72891e",
    "idx": 45,
    "time": "2020-11-13T17:39:15.307Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0 # SOLUTION\nzero_predictor_fn = sum(Y_train == 1) # SOLUTION\nzero_predictor_fp, zero_predictor_fn",
    "id": "30f5741e6f4742119d46340efe2e6a52",
    "idx": 49,
    "time": "2020-11-13T17:39:15.310Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nzero_predictor_fp >= 0",
    "id": "23064baca6924c4c9f2d7f478494c007",
    "idx": 50,
    "time": "2020-11-13T17:39:15.312Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nzero_predictor_fn >= 0",
    "id": "3475b02fb61a47839320a7c9edd5d518",
    "idx": 51,
    "time": "2020-11-13T17:39:15.314Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_fp, 0)",
    "id": "feef0e913db14b6b8101c4489462b487",
    "idx": 52,
    "time": "2020-11-13T17:39:15.316Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nzero_predictor_fn == 1918",
    "id": "8dde97c384214925a9c7f42f58f87aaf",
    "idx": 53,
    "time": "2020-11-13T17:39:15.318Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.mean(Y_train == 0) # SOLUTION\nzero_predictor_recall = 0 # SOLUTION\nzero_predictor_acc, zero_predictor_recall",
    "id": "933ef39465ec409e96b3a53f6203baab",
    "idx": 55,
    "time": "2020-11-13T17:39:15.321Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nzero_predictor_acc >= 0",
    "id": "2499a1d760f1441299b055adc8736e68",
    "idx": 56,
    "time": "2020-11-13T17:39:15.322Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nzero_predictor_recall >= 0",
    "id": "2de51ed2ec9f4e11be1000fb204774a3",
    "idx": 57,
    "time": "2020-11-13T17:39:15.324Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_acc, 0.7447091707706642)",
    "id": "ff5d5782535a42019b7eb5a8ec2753dc",
    "idx": 58,
    "time": "2020-11-13T17:39:15.325Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_recall, 0)",
    "id": "f0850a5e5e024d2d9f9bcafe925e1901",
    "idx": 59,
    "time": "2020-11-13T17:39:15.327Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION NO PROMPT\nY_train_hat = model.predict(X_train)\n\nTP = sum((Y_train_hat == Y_train) & (Y_train_hat == 1))\nTN = sum((Y_train_hat == Y_train) & (Y_train_hat == 0))\nFP = sum((Y_train_hat != Y_train) & (Y_train_hat == 1))\nFN = sum((Y_train_hat != Y_train) & (Y_train_hat == 0))\n# END SOLUTION\nlogistic_predictor_precision = TP / (TP + FP) # SOLUTION\nlogistic_predictor_recall = TP / (TP + FN) # SOLUTION\nlogistic_predictor_far = FP / (FP + TN) # SOLUTION",
    "id": "aa340a7e7443411fb115580a71b83b27",
    "idx": 63,
    "time": "2020-11-13T17:39:15.330Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlogistic_predictor_precision >= 0",
    "id": "2be7e72466a649f1822d8f8458cf3921",
    "idx": 64,
    "time": "2020-11-13T17:39:15.332Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlogistic_predictor_recall >= 0",
    "id": "70a7e749219e434092993513497dc589",
    "idx": 65,
    "time": "2020-11-13T17:39:15.335Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlogistic_predictor_far >= 0",
    "id": "c555cae2efe24a11960d966fee18793b",
    "idx": 66,
    "time": "2020-11-13T17:39:15.335Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_precision, 0.6422287390029325)",
    "id": "84339b96007044c18bb3370123e713d5",
    "idx": 67,
    "time": "2020-11-13T17:39:15.338Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_recall, 0.11418143899895725)",
    "id": "e9752dbea367428782b9be92a30dfd54",
    "idx": 68,
    "time": "2020-11-13T17:39:15.340Z",
    "type": "execution"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_far, 0.021805183199285077)",
    "id": "b7177c97cf0a4893a65e2229d24bddde",
    "idx": 69,
    "time": "2020-11-13T17:39:15.341Z",
    "type": "execution"
   },
   {
    "code": "# Write your description (2-3 sentences) as a comment here:\n# \n#\n#\n\n# Write the code to generate your visualization here:\n# BEGIN SOLUTION\nplt.plot([1, 3, 5]) # This is a dummy plot, not a real example of a solution\n# END SOLUTION",
    "id": "8c0c0ab98ec64e0f843fdaaa8287e1b3",
    "idx": 79,
    "time": "2020-11-13T17:39:15.347Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\n# BEGIN SOLUTION\nstaff_words = ['body', 'click', 'please', 'base64', '2002', 'html', 'subscribed',\n               'wrote', 'mortgage', 'align3dcenterfont', 'dear', 'br', 'width10img',\n               'divfont', 'im', 'receive', 'list', 'tags', 'web', 'base64', 'click',\n               'body', 'please', 'money', 'offer', 'receive', 'contact', 'free',\n               'tr', 'removed', 'remove', 'html', 'font', 'form',\n               'credit', 'business', 'div']\n\nX_train_2 = words_in_texts(staff_words, train['email'])\n\nstaff_model = LogisticRegression(solver = 'lbfgs')\nstaff_model.fit(X_train_2, Y_train)\n\nprint('accuracy: ', staff_model.score(X_train_2, Y_train))\n\nY_predict = staff_model.predict_proba(X_train_2)[:, 1]\nfpr, tpr, thresholds = roc_curve(Y_train, Y_predict)\nwith sns.axes_style(\"white\"):\n    plt.plot(fpr, tpr)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.show()\n# END SOLUTION",
    "id": "8059141c245f48d1843bcdba92a55cd9",
    "idx": 81,
    "time": "2020-11-13T17:39:15.349Z",
    "type": "execution"
   },
   {
    "code": "test_predictions = staff_model.predict(words_in_texts(staff_words, test['email'])) # SOLUTION",
    "id": "b3b715b7bbe440a29afc031436448f68",
    "idx": 83,
    "time": "2020-11-13T17:39:15.351Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nisinstance(test_predictions, np.ndarray) # must be ndarray of predictions",
    "id": "4b8c3b3000f8467d8e92f63713c5a948",
    "idx": 84,
    "time": "2020-11-13T17:39:15.353Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(test_predictions), np.array([0, 1])) # must be binary labels (0 or 1) and not probabilities",
    "id": "e49cb9eca4884f10bd54709c678f11c4",
    "idx": 85,
    "time": "2020-11-13T17:39:15.355Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlen(test_predictions) == 1000 # must be the right number of predictions",
    "id": "558f42cfe8c64125afce510c3b7d9647",
    "idx": 86,
    "time": "2020-11-13T17:39:15.357Z",
    "type": "execution"
   },
   {
    "code": "from datetime import datetime\n\n# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n\n# Construct and save the submission:\nsubmission_df = pd.DataFrame({\n    \"Id\": test['id'], \n    \"Class\": test_predictions,\n}, columns=['Id', 'Class'])\ntimestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\nsubmission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n\nprint('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\nprint('You may now upload this CSV file to Gradescope for scoring.')",
    "id": "951a8f66c9384b52b03fd07762ba6645",
    "idx": 88,
    "time": "2020-11-13T17:39:15.359Z",
    "type": "execution"
   },
   {
    "id": "bf4059a762a047a6a8e4179dc2c11815",
    "time": "2020-11-13T17:39:15.381Z",
    "type": "completion"
   },
   {
    "id": "679de399389b410fbd1bd229389869ba",
    "time": "2020-11-13T17:39:16.314Z",
    "type": "completion"
   },
   {
    "id": "668f75f782c041508f9e0c8f82311ad1",
    "time": "2020-11-13T17:39:17.398Z",
    "type": "completion"
   },
   {
    "id": "68e38b511a2c4f5480d4eda2b0082a11",
    "time": "2020-11-13T17:39:17.402Z",
    "type": "completion"
   },
   {
    "id": "7f4b00c62776443e817cd5a255aa14b9",
    "time": "2020-11-13T17:39:17.451Z",
    "type": "completion"
   },
   {
    "id": "bfb55fdfdfb1456785bb78790aad426b",
    "time": "2020-11-13T17:39:17.502Z",
    "type": "completion"
   },
   {
    "id": "6345c5019a384a618017acbb080996d9",
    "time": "2020-11-13T17:39:17.557Z",
    "type": "completion"
   },
   {
    "id": "ee844f20ed0a41c4b81ff495fe482bdf",
    "time": "2020-11-13T17:39:17.641Z",
    "type": "completion"
   },
   {
    "id": "13a350f12fac4931be17235a1daf0a93",
    "time": "2020-11-13T17:39:17.687Z",
    "type": "completion"
   },
   {
    "id": "a90683e4a73346878a06d732d7101c87",
    "time": "2020-11-13T17:39:17.724Z",
    "type": "completion"
   },
   {
    "id": "7523257e508447369ca710ce27eba7b1",
    "time": "2020-11-13T17:39:17.810Z",
    "type": "completion"
   },
   {
    "id": "81aa3a295d054268acb33351ad567192",
    "time": "2020-11-13T17:39:17.822Z",
    "type": "completion"
   },
   {
    "id": "690ffc0aa5e446949b45a8b4ecd76f85",
    "time": "2020-11-13T17:39:17.854Z",
    "type": "completion"
   },
   {
    "id": "c3fba6032da048efaf5bf9b349cfb4f8",
    "time": "2020-11-13T17:39:17.895Z",
    "type": "completion"
   },
   {
    "id": "c248bceea6bd440c870eb7f942fcf77e",
    "time": "2020-11-13T17:39:17.923Z",
    "type": "completion"
   },
   {
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "time": "2020-11-13T17:39:18.623Z",
    "type": "completion"
   },
   {
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "time": "2020-11-13T17:39:19.061Z",
    "type": "completion"
   },
   {
    "id": "4228df6326c449d782e8471fb2f787fe",
    "time": "2020-11-13T17:39:19.120Z",
    "type": "completion"
   },
   {
    "id": "16be536580a04248971c0fcb94bb3f0e",
    "time": "2020-11-13T17:39:19.127Z",
    "type": "completion"
   },
   {
    "id": "dc0cb916fcc5470885a644448fa6684c",
    "time": "2020-11-13T17:39:19.185Z",
    "type": "completion"
   },
   {
    "id": "7b8699ffc3414488a9d374ae3a762231",
    "time": "2020-11-13T17:39:19.247Z",
    "type": "completion"
   },
   {
    "id": "6a1a859678394a819af601759e1b4c0d",
    "time": "2020-11-13T17:39:19.371Z",
    "type": "completion"
   },
   {
    "id": "45afd18c3a604fd8825017255e72891e",
    "time": "2020-11-13T17:39:19.383Z",
    "type": "completion"
   },
   {
    "id": "30f5741e6f4742119d46340efe2e6a52",
    "time": "2020-11-13T17:39:19.485Z",
    "type": "completion"
   },
   {
    "id": "23064baca6924c4c9f2d7f478494c007",
    "time": "2020-11-13T17:39:19.536Z",
    "type": "completion"
   },
   {
    "id": "3475b02fb61a47839320a7c9edd5d518",
    "time": "2020-11-13T17:39:19.588Z",
    "type": "completion"
   },
   {
    "id": "feef0e913db14b6b8101c4489462b487",
    "time": "2020-11-13T17:39:19.642Z",
    "type": "completion"
   },
   {
    "id": "8dde97c384214925a9c7f42f58f87aaf",
    "time": "2020-11-13T17:39:19.709Z",
    "type": "completion"
   },
   {
    "id": "933ef39465ec409e96b3a53f6203baab",
    "time": "2020-11-13T17:39:19.769Z",
    "type": "completion"
   },
   {
    "id": "2499a1d760f1441299b055adc8736e68",
    "time": "2020-11-13T17:39:19.867Z",
    "type": "completion"
   },
   {
    "id": "2de51ed2ec9f4e11be1000fb204774a3",
    "time": "2020-11-13T17:39:20.000Z",
    "type": "completion"
   },
   {
    "id": "ff5d5782535a42019b7eb5a8ec2753dc",
    "time": "2020-11-13T17:39:20.086Z",
    "type": "completion"
   },
   {
    "id": "f0850a5e5e024d2d9f9bcafe925e1901",
    "time": "2020-11-13T17:39:20.167Z",
    "type": "completion"
   },
   {
    "id": "aa340a7e7443411fb115580a71b83b27",
    "time": "2020-11-13T17:39:20.390Z",
    "type": "completion"
   },
   {
    "id": "2be7e72466a649f1822d8f8458cf3921",
    "time": "2020-11-13T17:39:20.396Z",
    "type": "completion"
   },
   {
    "id": "70a7e749219e434092993513497dc589",
    "time": "2020-11-13T17:39:20.469Z",
    "type": "completion"
   },
   {
    "id": "c555cae2efe24a11960d966fee18793b",
    "time": "2020-11-13T17:39:20.553Z",
    "type": "completion"
   },
   {
    "id": "84339b96007044c18bb3370123e713d5",
    "time": "2020-11-13T17:39:20.650Z",
    "type": "completion"
   },
   {
    "id": "e9752dbea367428782b9be92a30dfd54",
    "time": "2020-11-13T17:39:20.717Z",
    "type": "completion"
   },
   {
    "id": "b7177c97cf0a4893a65e2229d24bddde",
    "time": "2020-11-13T17:39:20.772Z",
    "type": "completion"
   },
   {
    "id": "8c0c0ab98ec64e0f843fdaaa8287e1b3",
    "time": "2020-11-13T17:39:21.057Z",
    "type": "completion"
   },
   {
    "id": "8059141c245f48d1843bcdba92a55cd9",
    "time": "2020-11-13T17:39:22.358Z",
    "type": "completion"
   },
   {
    "id": "b3b715b7bbe440a29afc031436448f68",
    "time": "2020-11-13T17:39:22.422Z",
    "type": "completion"
   },
   {
    "id": "4b8c3b3000f8467d8e92f63713c5a948",
    "time": "2020-11-13T17:39:22.456Z",
    "type": "completion"
   },
   {
    "id": "e49cb9eca4884f10bd54709c678f11c4",
    "time": "2020-11-13T17:39:22.531Z",
    "type": "completion"
   },
   {
    "id": "558f42cfe8c64125afce510c3b7d9647",
    "time": "2020-11-13T17:39:22.633Z",
    "type": "completion"
   },
   {
    "id": "951a8f66c9384b52b03fd07762ba6645",
    "time": "2020-11-13T17:39:22.769Z",
    "type": "completion"
   },
   {
    "code": "sns.distplot(tmp[tmp['spam']==0].length)",
    "id": "7d23973917c7446e89e5254e568f0870",
    "idx": 37,
    "time": "2020-11-13T17:47:19.110Z",
    "type": "execution"
   },
   {
    "id": "7d23973917c7446e89e5254e568f0870",
    "time": "2020-11-13T17:47:19.599Z",
    "type": "completion"
   },
   {
    "code": "sns.distplot(tmp[tmp['spam']==1].length)",
    "id": "3fa95f246e09494289e5530c5b1afc30",
    "idx": 37,
    "time": "2020-11-13T17:47:27.053Z",
    "type": "execution"
   },
   {
    "id": "3fa95f246e09494289e5530c5b1afc30",
    "time": "2020-11-13T17:47:27.538Z",
    "type": "completion"
   },
   {
    "code": "sns.distplot(tmp[tmp['spam']==1].length)\nplt.xlim(0, 50000)",
    "id": "3fa95f246e09494289e5530c5b1afc30",
    "idx": 37,
    "time": "2020-11-13T17:47:41.149Z",
    "type": "execution"
   },
   {
    "id": "3fa95f246e09494289e5530c5b1afc30",
    "time": "2020-11-13T17:47:41.623Z",
    "type": "completion"
   },
   {
    "code": "sns.distplot(tmp[tmp['spam']==0].length)\nplt.xlim(0, 50000)",
    "id": "7d23973917c7446e89e5254e568f0870",
    "idx": 38,
    "time": "2020-11-13T17:47:45.930Z",
    "type": "execution"
   },
   {
    "id": "7d23973917c7446e89e5254e568f0870",
    "time": "2020-11-13T17:47:46.515Z",
    "type": "completion"
   },
   {
    "code": "# BEGIN SOLUTION\ntmp = train.copy()\ntmp['length'] = tmp['email'].str.len()\nplt.figure(figsize=(10, 6))\nsns.distplot(tmp.loc[tmp['spam'] == 0, 'length'],hist=False, label='Ham')\nsns.distplot(tmp.loc[tmp['spam'] == 1, 'length'],hist=False, label='Spam')\nplt.title('Distribution of Email Body Length')\nplt.xlabel('Length of email body')\nplt.ylabel('Distribution')\nplt.xlim((0,50000))\nplt.tight_layout()\nplt.legend();\n# END SOLUTION\nplt.savefig('training_conditional_densities.png')",
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "idx": 36,
    "time": "2020-11-13T17:48:23.568Z",
    "type": "execution"
   },
   {
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "time": "2020-11-13T17:48:24.403Z",
    "type": "completion"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "bf4059a762a047a6a8e4179dc2c11815",
    "idx": 5,
    "time": "2020-11-13T17:50:40.136Z",
    "type": "execution"
   },
   {
    "id": "bf4059a762a047a6a8e4179dc2c11815",
    "time": "2020-11-13T17:50:40.313Z",
    "type": "completion"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "679de399389b410fbd1bd229389869ba",
    "idx": 8,
    "time": "2020-11-13T17:50:40.821Z",
    "type": "execution"
   },
   {
    "id": "679de399389b410fbd1bd229389869ba",
    "time": "2020-11-13T17:50:40.897Z",
    "type": "completion"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "668f75f782c041508f9e0c8f82311ad1",
    "idx": 10,
    "time": "2020-11-13T17:50:41.062Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\nprint('Before imputation:')\nprint(original_training_data.isnull().sum())\noriginal_training_data = original_training_data.fillna('')\nprint('------------')\nprint('After imputation:')\nprint(original_training_data.isnull().sum())\n# END SOLUTION",
    "id": "68e38b511a2c4f5480d4eda2b0082a11",
    "idx": 12,
    "time": "2020-11-13T17:50:41.287Z",
    "type": "execution"
   },
   {
    "code": "# TEST\noriginal_training_data.isnull().sum().sum() == 0",
    "id": "7f4b00c62776443e817cd5a255aa14b9",
    "idx": 13,
    "time": "2020-11-13T17:50:41.411Z",
    "type": "execution"
   },
   {
    "id": "668f75f782c041508f9e0c8f82311ad1",
    "time": "2020-11-13T17:50:41.553Z",
    "type": "completion"
   },
   {
    "id": "68e38b511a2c4f5480d4eda2b0082a11",
    "time": "2020-11-13T17:50:41.562Z",
    "type": "completion"
   },
   {
    "id": "7f4b00c62776443e817cd5a255aa14b9",
    "time": "2020-11-13T17:50:41.606Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] # SOLUTION\nfirst_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] # SOLUTION\nprint(first_ham)\nprint(first_spam)",
    "id": "bfb55fdfdfb1456785bb78790aad426b",
    "idx": 15,
    "time": "2020-11-13T17:50:42.451Z",
    "type": "execution"
   },
   {
    "id": "bfb55fdfdfb1456785bb78790aad426b",
    "time": "2020-11-13T17:50:42.530Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlen(first_ham) > 0 and first_ham[:0] == ''",
    "id": "6345c5019a384a618017acbb080996d9",
    "idx": 16,
    "time": "2020-11-13T17:50:42.586Z",
    "type": "execution"
   },
   {
    "id": "6345c5019a384a618017acbb080996d9",
    "time": "2020-11-13T17:50:42.656Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlen(first_spam) > 0 and first_spam[:0] == ''",
    "id": "ee844f20ed0a41c4b81ff495fe482bdf",
    "idx": 17,
    "time": "2020-11-13T17:50:42.774Z",
    "type": "execution"
   },
   {
    "id": "ee844f20ed0a41c4b81ff495fe482bdf",
    "time": "2020-11-13T17:50:42.839Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] in first_ham",
    "id": "13a350f12fac4931be17235a1daf0a93",
    "idx": 18,
    "time": "2020-11-13T17:50:42.995Z",
    "type": "execution"
   },
   {
    "id": "13a350f12fac4931be17235a1daf0a93",
    "time": "2020-11-13T17:50:43.069Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] in first_spam",
    "id": "a90683e4a73346878a06d732d7101c87",
    "idx": 19,
    "time": "2020-11-13T17:50:43.103Z",
    "type": "execution"
   },
   {
    "id": "a90683e4a73346878a06d732d7101c87",
    "time": "2020-11-13T17:50:43.180Z",
    "type": "completion"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "7523257e508447369ca710ce27eba7b1",
    "idx": 23,
    "time": "2020-11-13T17:50:43.719Z",
    "type": "execution"
   },
   {
    "id": "7523257e508447369ca710ce27eba7b1",
    "time": "2020-11-13T17:50:43.793Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = 1 * np.array([texts.str.contains(word) for word in words]).T # SOLUTION\n    return indicator_array",
    "id": "81aa3a295d054268acb33351ad567192",
    "idx": 26,
    "time": "2020-11-13T17:50:44.197Z",
    "type": "execution"
   },
   {
    "id": "81aa3a295d054268acb33351ad567192",
    "time": "2020-11-13T17:50:44.266Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['hello', 'bye', 'world'], \n                           pd.Series(['hello', 'hello worldhello'])),\n            np.array([[1, 0, 0], \n                      [1, 0, 1]]))",
    "id": "690ffc0aa5e446949b45a8b4ecd76f85",
    "idx": 27,
    "time": "2020-11-13T17:50:44.320Z",
    "type": "execution"
   },
   {
    "id": "690ffc0aa5e446949b45a8b4ecd76f85",
    "time": "2020-11-13T17:50:44.392Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['a', 'b', 'c', 'd', 'e', 'f', 'g'], \n                           pd.Series(['a b c d ef g', 'a', 'b', 'c', 'd e f g', 'h', 'a h'])),\n            np.array([[1,1,1,1,1,1,1], \n                      [1,0,0,0,0,0,0],\n                      [0,1,0,0,0,0,0],\n                      [0,0,1,0,0,0,0],\n                      [0,0,0,1,1,1,1],\n                      [0,0,0,0,0,0,0],\n                      [1,0,0,0,0,0,0]]))",
    "id": "c3fba6032da048efaf5bf9b349cfb4f8",
    "idx": 28,
    "time": "2020-11-13T17:50:44.456Z",
    "type": "execution"
   },
   {
    "id": "c3fba6032da048efaf5bf9b349cfb4f8",
    "time": "2020-11-13T17:50:44.532Z",
    "type": "completion"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "c248bceea6bd440c870eb7f942fcf77e",
    "idx": 31,
    "time": "2020-11-13T17:50:44.843Z",
    "type": "execution"
   },
   {
    "id": "c248bceea6bd440c870eb7f942fcf77e",
    "time": "2020-11-13T17:50:44.938Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\n# BEGIN SOLUTION\nsome_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\nPhi_train = words_in_texts(some_words, train['email'])\n\ndf = pd.DataFrame(data = Phi_train, columns = some_words)\ndf['label'] = train['spam']\n\nplt.figure(figsize=(12,8))\nsns.barplot(x = \"variable\", \n            y = \"value\", \n            hue = \"label\", \n            data = (df\n                    .replace({'label': \n                                {0 : 'Ham', \n                                 1 : 'Spam'}})\n                    .melt('label')\n                    .groupby(['label', 'variable'])\n                    .mean()\n                    .reset_index()))\n\nplt.xlabel('Words')\nplt.ylabel('Proportion of Emails')\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show()\n# END SOLUTION",
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "idx": 33,
    "time": "2020-11-13T17:50:45.085Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\ntmp = train.copy()\ntmp['length'] = tmp['email'].str.len()\nplt.figure(figsize=(10, 6))\nsns.distplot(tmp.loc[tmp['spam'] == 0, 'length'],hist=False, label='Ham')\nsns.distplot(tmp.loc[tmp['spam'] == 1, 'length'],hist=False, label='Spam')\nplt.title('Distribution of Email Body Length')\nplt.xlabel('Length of email body')\nplt.ylabel('Distribution')\nplt.xlim((0,50000))\nplt.tight_layout()\nplt.legend();\n# END SOLUTION\nplt.savefig('training_conditional_densities.png')",
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "idx": 36,
    "time": "2020-11-13T17:50:45.529Z",
    "type": "execution"
   },
   {
    "id": "3da1bb8528f1420d8e4b01106abb0d1c",
    "time": "2020-11-13T17:50:45.785Z",
    "type": "completion"
   },
   {
    "id": "ccae3bbd17a7472584923d1fd81f0c4b",
    "time": "2020-11-13T17:50:46.397Z",
    "type": "completion"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "5717cb1fad9e4423882ebb7402a960d0",
    "idx": 5,
    "time": "2020-11-13T17:52:54.134Z",
    "type": "execution"
   },
   {
    "id": "5717cb1fad9e4423882ebb7402a960d0",
    "time": "2020-11-13T17:52:54.207Z",
    "type": "completion"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "922a4e60525f4eafb7a67d51618380a8",
    "idx": 8,
    "time": "2020-11-13T17:52:54.451Z",
    "type": "execution"
   },
   {
    "id": "922a4e60525f4eafb7a67d51618380a8",
    "time": "2020-11-13T17:52:54.611Z",
    "type": "completion"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "5b789cd4cf994c438c36c83a11f0883e",
    "idx": 10,
    "time": "2020-11-13T17:52:54.797Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\nprint('Before imputation:')\nprint(original_training_data.isnull().sum())\noriginal_training_data = original_training_data.fillna('')\nprint('------------')\nprint('After imputation:')\nprint(original_training_data.isnull().sum())\n# END SOLUTION",
    "id": "8cc51a7378104317923b12eb8010193c",
    "idx": 12,
    "time": "2020-11-13T17:52:55.069Z",
    "type": "execution"
   },
   {
    "code": "# TEST\noriginal_training_data.isnull().sum().sum() == 0",
    "id": "fd0fc36dcb3e465fa5de88357798251b",
    "idx": 13,
    "time": "2020-11-13T17:52:55.204Z",
    "type": "execution"
   },
   {
    "id": "5b789cd4cf994c438c36c83a11f0883e",
    "time": "2020-11-13T17:52:55.275Z",
    "type": "completion"
   },
   {
    "id": "8cc51a7378104317923b12eb8010193c",
    "time": "2020-11-13T17:52:55.285Z",
    "type": "completion"
   },
   {
    "id": "fd0fc36dcb3e465fa5de88357798251b",
    "time": "2020-11-13T17:52:55.362Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] # SOLUTION\nfirst_spam = original_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] # SOLUTION\nprint(first_ham)\nprint(first_spam)",
    "id": "ec38cd1676674d79a1f78850b2bdeade",
    "idx": 15,
    "time": "2020-11-13T17:52:55.469Z",
    "type": "execution"
   },
   {
    "id": "ec38cd1676674d79a1f78850b2bdeade",
    "time": "2020-11-13T17:52:55.543Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlen(first_ham) > 0 and first_ham[:0] == ''",
    "id": "91fb9a6b7c524dd1b4ebaf00adfee1e0",
    "idx": 16,
    "time": "2020-11-13T17:52:55.714Z",
    "type": "execution"
   },
   {
    "id": "91fb9a6b7c524dd1b4ebaf00adfee1e0",
    "time": "2020-11-13T17:52:55.787Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlen(first_spam) > 0 and first_spam[:0] == ''",
    "id": "bc8e6529a6634c3abc2fbbdeb59cf56a",
    "idx": 17,
    "time": "2020-11-13T17:52:55.830Z",
    "type": "execution"
   },
   {
    "id": "bc8e6529a6634c3abc2fbbdeb59cf56a",
    "time": "2020-11-13T17:52:55.908Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 0, 'email'].iloc[0] in first_ham",
    "id": "72db8567d04348308e6661ab83085607",
    "idx": 18,
    "time": "2020-11-13T17:52:55.952Z",
    "type": "execution"
   },
   {
    "id": "72db8567d04348308e6661ab83085607",
    "time": "2020-11-13T17:52:56.024Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\noriginal_training_data.loc[original_training_data['spam'] == 1, 'email'].iloc[0] in first_spam",
    "id": "3618a1ff098948808c2c917f942d36aa",
    "idx": 19,
    "time": "2020-11-13T17:52:56.076Z",
    "type": "execution"
   },
   {
    "id": "3618a1ff098948808c2c917f942d36aa",
    "time": "2020-11-13T17:52:56.147Z",
    "type": "completion"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "96c9ac16984747308f833d4c03e9ed53",
    "idx": 23,
    "time": "2020-11-13T17:52:56.678Z",
    "type": "execution"
   },
   {
    "id": "96c9ac16984747308f833d4c03e9ed53",
    "time": "2020-11-13T17:52:56.755Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = 1 * np.array([texts.str.contains(word) for word in words]).T # SOLUTION\n    return indicator_array",
    "id": "06639f97d5a240988a6d7dd1e0b48d8b",
    "idx": 26,
    "time": "2020-11-13T17:52:57.072Z",
    "type": "execution"
   },
   {
    "id": "06639f97d5a240988a6d7dd1e0b48d8b",
    "time": "2020-11-13T17:52:57.145Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['hello', 'bye', 'world'], \n                           pd.Series(['hello', 'hello worldhello'])),\n            np.array([[1, 0, 0], \n                      [1, 0, 1]]))",
    "id": "ffde5bde95224ba58486ad532fb5c28c",
    "idx": 27,
    "time": "2020-11-13T17:52:57.170Z",
    "type": "execution"
   },
   {
    "id": "ffde5bde95224ba58486ad532fb5c28c",
    "time": "2020-11-13T17:52:57.245Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.allclose(words_in_texts(['a', 'b', 'c', 'd', 'e', 'f', 'g'], \n                           pd.Series(['a b c d ef g', 'a', 'b', 'c', 'd e f g', 'h', 'a h'])),\n            np.array([[1,1,1,1,1,1,1], \n                      [1,0,0,0,0,0,0],\n                      [0,1,0,0,0,0,0],\n                      [0,0,1,0,0,0,0],\n                      [0,0,0,1,1,1,1],\n                      [0,0,0,0,0,0,0],\n                      [1,0,0,0,0,0,0]]))",
    "id": "e3e6cf9be8e743fba0049d314831aebf",
    "idx": 28,
    "time": "2020-11-13T17:52:57.405Z",
    "type": "execution"
   },
   {
    "id": "e3e6cf9be8e743fba0049d314831aebf",
    "time": "2020-11-13T17:52:57.482Z",
    "type": "completion"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "6dd5159205814d56b783b665571c9441",
    "idx": 31,
    "time": "2020-11-13T17:52:57.979Z",
    "type": "execution"
   },
   {
    "id": "6dd5159205814d56b783b665571c9441",
    "time": "2020-11-13T17:52:58.072Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\n# BEGIN SOLUTION\nsome_words = ['opportunity', 'bank', 'receive', 'dear', 'best', 'deal']\nPhi_train = words_in_texts(some_words, train['email'])\n\ndf = pd.DataFrame(data = Phi_train, columns = some_words)\ndf['label'] = train['spam']\n\nplt.figure(figsize=(12,8))\nsns.barplot(x = \"variable\", \n            y = \"value\", \n            hue = \"label\", \n            data = (df\n                    .replace({'label': \n                                {0 : 'Ham', \n                                 1 : 'Spam'}})\n                    .melt('label')\n                    .groupby(['label', 'variable'])\n                    .mean()\n                    .reset_index()))\n\nplt.xlabel('Words')\nplt.ylabel('Proportion of Emails')\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show()\n# END SOLUTION",
    "id": "cc68f68e069e48788281a1bc9531d83d",
    "idx": 33,
    "time": "2020-11-13T17:52:58.316Z",
    "type": "execution"
   },
   {
    "code": "# BEGIN SOLUTION\ntmp = train.copy()\ntmp['length'] = tmp['email'].str.len()\nplt.figure(figsize=(10, 6))\nsns.distplot(tmp.loc[tmp['spam'] == 0, 'length'],hist=False, label='Ham')\nsns.distplot(tmp.loc[tmp['spam'] == 1, 'length'],hist=False, label='Spam')\nplt.title('Distribution of Email Body Length')\nplt.xlabel('Length of email body')\nplt.ylabel('Distribution')\nplt.xlim((0,50000))\nplt.tight_layout()\nplt.legend();\n# END SOLUTION\nplt.savefig('training_conditional_densities.png')",
    "id": "26273859df904aecb41ec51ef7d9885e",
    "idx": 36,
    "time": "2020-11-13T17:52:58.861Z",
    "type": "execution"
   },
   {
    "id": "cc68f68e069e48788281a1bc9531d83d",
    "time": "2020-11-13T17:52:59.050Z",
    "type": "completion"
   },
   {
    "id": "26273859df904aecb41ec51ef7d9885e",
    "time": "2020-11-13T17:52:59.571Z",
    "type": "completion"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train['email']) # SOLUTION\nY_train = np.array(train['spam']) # SOLUTION\n\nX_train[:5], Y_train[:5]",
    "id": "62fb90ac758448c48db77978df497ae6",
    "idx": 39,
    "time": "2020-11-13T17:53:00.275Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nX_train.shape == (7513, 5)",
    "id": "b365b5d2dcef401a8defa85c6f598d02",
    "idx": 40,
    "time": "2020-11-13T17:53:00.406Z",
    "type": "execution"
   },
   {
    "id": "62fb90ac758448c48db77978df497ae6",
    "time": "2020-11-13T17:53:00.493Z",
    "type": "completion"
   },
   {
    "id": "b365b5d2dcef401a8defa85c6f598d02",
    "time": "2020-11-13T17:53:00.498Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(X_train), np.array([0, 1])) # X matrix should consist of only 0 or 1",
    "id": "47d34afb59514919ba683fa0c888bde4",
    "idx": 41,
    "time": "2020-11-13T17:53:00.534Z",
    "type": "execution"
   },
   {
    "id": "47d34afb59514919ba683fa0c888bde4",
    "time": "2020-11-13T17:53:00.605Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(Y_train), np.array([0, 1])) # y vector should consist of only 0 or 1",
    "id": "e8cd7ec14d974ad9b019227069f6145d",
    "idx": 42,
    "time": "2020-11-13T17:53:00.660Z",
    "type": "execution"
   },
   {
    "id": "e8cd7ec14d974ad9b019227069f6145d",
    "time": "2020-11-13T17:53:00.733Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression(solver = 'lbfgs') # SOLUTION\nmodel.fit(X_train, Y_train) # SOLUTION\n\ntraining_accuracy = model.score(X_train, Y_train) # SOLUTION\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "d499255244534699864b5465ce019b5d",
    "idx": 44,
    "time": "2020-11-13T17:53:00.942Z",
    "type": "execution"
   },
   {
    "id": "d499255244534699864b5465ce019b5d",
    "time": "2020-11-13T17:53:01.061Z",
    "type": "completion"
   },
   {
    "code": "# TEST\ntraining_accuracy > 0.72",
    "id": "fef1c6cf1e4a4d3c88f2b4953c55e80d",
    "idx": 45,
    "time": "2020-11-13T17:53:01.501Z",
    "type": "execution"
   },
   {
    "id": "fef1c6cf1e4a4d3c88f2b4953c55e80d",
    "time": "2020-11-13T17:53:01.569Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_fp = 0 # SOLUTION\nzero_predictor_fn = sum(Y_train == 1) # SOLUTION\nzero_predictor_fp, zero_predictor_fn",
    "id": "0cffaab89bf348f189d092a3bfa1ea4d",
    "idx": 49,
    "time": "2020-11-13T17:53:02.485Z",
    "type": "execution"
   },
   {
    "id": "0cffaab89bf348f189d092a3bfa1ea4d",
    "time": "2020-11-13T17:53:02.576Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nzero_predictor_fp >= 0",
    "id": "564c1eaebae947b69e6800e2ae98ba16",
    "idx": 50,
    "time": "2020-11-13T17:53:02.634Z",
    "type": "execution"
   },
   {
    "id": "564c1eaebae947b69e6800e2ae98ba16",
    "time": "2020-11-13T17:53:02.712Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nzero_predictor_fn >= 0",
    "id": "8a79d709c33749518cf44392623bb119",
    "idx": 51,
    "time": "2020-11-13T17:53:02.760Z",
    "type": "execution"
   },
   {
    "id": "8a79d709c33749518cf44392623bb119",
    "time": "2020-11-13T17:53:02.832Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_fp, 0)",
    "id": "d6ef40aabfde4fd9afc5e0ae8a2f9a56",
    "idx": 52,
    "time": "2020-11-13T17:53:02.881Z",
    "type": "execution"
   },
   {
    "id": "d6ef40aabfde4fd9afc5e0ae8a2f9a56",
    "time": "2020-11-13T17:53:02.953Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nzero_predictor_fn == 1918",
    "id": "dd9b240252164f86b72fb4a1a40682d4",
    "idx": 53,
    "time": "2020-11-13T17:53:03.012Z",
    "type": "execution"
   },
   {
    "id": "dd9b240252164f86b72fb4a1a40682d4",
    "time": "2020-11-13T17:53:03.092Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_acc = np.mean(Y_train == 0) # SOLUTION\nzero_predictor_recall = 0 # SOLUTION\nzero_predictor_acc, zero_predictor_recall",
    "id": "84771e6a5b2d4591884e110cd14df188",
    "idx": 55,
    "time": "2020-11-13T17:53:03.505Z",
    "type": "execution"
   },
   {
    "id": "84771e6a5b2d4591884e110cd14df188",
    "time": "2020-11-13T17:53:03.572Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nzero_predictor_acc >= 0",
    "id": "060a99ebe6ce4a5086717f109d2e7dca",
    "idx": 56,
    "time": "2020-11-13T17:53:03.631Z",
    "type": "execution"
   },
   {
    "id": "060a99ebe6ce4a5086717f109d2e7dca",
    "time": "2020-11-13T17:53:03.702Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nzero_predictor_recall >= 0",
    "id": "16d18caac2104e4caf93f13a65241938",
    "idx": 57,
    "time": "2020-11-13T17:53:03.762Z",
    "type": "execution"
   },
   {
    "id": "16d18caac2104e4caf93f13a65241938",
    "time": "2020-11-13T17:53:03.831Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_acc, 0.7447091707706642)",
    "id": "be360f140fc546fd8b086891e6614438",
    "idx": 58,
    "time": "2020-11-13T17:53:04.126Z",
    "type": "execution"
   },
   {
    "id": "be360f140fc546fd8b086891e6614438",
    "time": "2020-11-13T17:53:04.196Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(zero_predictor_recall, 0)",
    "id": "34130958f5e14ea2aa8627842fa37faf",
    "idx": 59,
    "time": "2020-11-13T17:53:04.243Z",
    "type": "execution"
   },
   {
    "id": "34130958f5e14ea2aa8627842fa37faf",
    "time": "2020-11-13T17:53:04.312Z",
    "type": "completion"
   },
   {
    "code": "# BEGIN SOLUTION NO PROMPT\nY_train_hat = model.predict(X_train)\n\nTP = sum((Y_train_hat == Y_train) & (Y_train_hat == 1))\nTN = sum((Y_train_hat == Y_train) & (Y_train_hat == 0))\nFP = sum((Y_train_hat != Y_train) & (Y_train_hat == 1))\nFN = sum((Y_train_hat != Y_train) & (Y_train_hat == 0))\n# END SOLUTION\nlogistic_predictor_precision = TP / (TP + FP) # SOLUTION\nlogistic_predictor_recall = TP / (TP + FN) # SOLUTION\nlogistic_predictor_far = FP / (FP + TN) # SOLUTION",
    "id": "69a4c98c4a1e45449c52800df7da21d9",
    "idx": 63,
    "time": "2020-11-13T17:53:04.794Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlogistic_predictor_precision >= 0",
    "id": "4fa2f8b900fa476f8ec08629fe9787aa",
    "idx": 64,
    "time": "2020-11-13T17:53:04.910Z",
    "type": "execution"
   },
   {
    "id": "69a4c98c4a1e45449c52800df7da21d9",
    "time": "2020-11-13T17:53:05.010Z",
    "type": "completion"
   },
   {
    "id": "4fa2f8b900fa476f8ec08629fe9787aa",
    "time": "2020-11-13T17:53:05.020Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlogistic_predictor_recall >= 0",
    "id": "f169fcb087ce4e1d87d7cada8bfc94a6",
    "idx": 65,
    "time": "2020-11-13T17:53:05.035Z",
    "type": "execution"
   },
   {
    "id": "f169fcb087ce4e1d87d7cada8bfc94a6",
    "time": "2020-11-13T17:53:05.111Z",
    "type": "completion"
   },
   {
    "code": "# TEST\nlogistic_predictor_far >= 0",
    "id": "ce0f25f5620849cc9a33d61b84e5caf6",
    "idx": 66,
    "time": "2020-11-13T17:53:05.173Z",
    "type": "execution"
   },
   {
    "id": "ce0f25f5620849cc9a33d61b84e5caf6",
    "time": "2020-11-13T17:53:05.250Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_precision, 0.6422287390029325)",
    "id": "2da6368a3815416ba07c4cbfaf0533d5",
    "idx": 67,
    "time": "2020-11-13T17:53:05.299Z",
    "type": "execution"
   },
   {
    "id": "2da6368a3815416ba07c4cbfaf0533d5",
    "time": "2020-11-13T17:53:05.379Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_recall, 0.11418143899895725)",
    "id": "1f49e01547f844499992699a3f8437d4",
    "idx": 68,
    "time": "2020-11-13T17:53:05.414Z",
    "type": "execution"
   },
   {
    "id": "1f49e01547f844499992699a3f8437d4",
    "time": "2020-11-13T17:53:05.484Z",
    "type": "completion"
   },
   {
    "code": "# HIDDEN TEST\nnp.isclose(logistic_predictor_far, 0.021805183199285077)",
    "id": "a86939b61fe7402b9bd562eda7adcb8a",
    "idx": 69,
    "time": "2020-11-13T17:53:05.535Z",
    "type": "execution"
   },
   {
    "id": "a86939b61fe7402b9bd562eda7adcb8a",
    "time": "2020-11-13T17:53:05.607Z",
    "type": "completion"
   },
   {
    "code": "# Write your description (2-3 sentences) as a comment here:\n# \n#\n#\n\n# Write the code to generate your visualization here:\n# BEGIN SOLUTION\nplt.plot([1, 3, 5]) # This is a dummy plot, not a real example of a solution\n# END SOLUTION",
    "id": "f9dd9c1872054b3aabcc6cde9965ad16",
    "idx": 79,
    "time": "2020-11-13T17:53:06.802Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\n# BEGIN SOLUTION\nstaff_words = ['body', 'click', 'please', 'base64', '2002', 'html', 'subscribed',\n               'wrote', 'mortgage', 'align3dcenterfont', 'dear', 'br', 'width10img',\n               'divfont', 'im', 'receive', 'list', 'tags', 'web', 'base64', 'click',\n               'body', 'please', 'money', 'offer', 'receive', 'contact', 'free',\n               'tr', 'removed', 'remove', 'html', 'font', 'form',\n               'credit', 'business', 'div']\n\nX_train_2 = words_in_texts(staff_words, train['email'])\n\nstaff_model = LogisticRegression(solver = 'lbfgs')\nstaff_model.fit(X_train_2, Y_train)\n\nprint('accuracy: ', staff_model.score(X_train_2, Y_train))\n\nY_predict = staff_model.predict_proba(X_train_2)[:, 1]\nfpr, tpr, thresholds = roc_curve(Y_train, Y_predict)\nwith sns.axes_style(\"white\"):\n    plt.plot(fpr, tpr)\nplt.xlabel(\"False Positive Rate\")\nplt.ylabel(\"True Positive Rate\")\nplt.xlim([0, 1])\nplt.ylim([0, 1])\nplt.show()\n# END SOLUTION",
    "id": "73428c5ed83743b199ed18dc26f18be3",
    "idx": 81,
    "time": "2020-11-13T17:53:07.068Z",
    "type": "execution"
   },
   {
    "id": "f9dd9c1872054b3aabcc6cde9965ad16",
    "time": "2020-11-13T17:53:07.170Z",
    "type": "completion"
   },
   {
    "code": "test_predictions = staff_model.predict(words_in_texts(staff_words, test['email'])) # SOLUTION",
    "id": "665d4320ee5a44fd8e5fc2cc55ecd777",
    "idx": 83,
    "time": "2020-11-13T17:53:07.542Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nisinstance(test_predictions, np.ndarray) # must be ndarray of predictions",
    "id": "0dd28fcc619746e4831ad536f8956532",
    "idx": 84,
    "time": "2020-11-13T17:53:07.669Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nnp.array_equal(np.unique(test_predictions), np.array([0, 1])) # must be binary labels (0 or 1) and not probabilities",
    "id": "6ccaddb5360c45609af4d3b6991ca741",
    "idx": 85,
    "time": "2020-11-13T17:53:07.805Z",
    "type": "execution"
   },
   {
    "code": "# TEST\nlen(test_predictions) == 1000 # must be the right number of predictions",
    "id": "e8c8f77a5758407293ae0b201063880f",
    "idx": 86,
    "time": "2020-11-13T17:53:07.949Z",
    "type": "execution"
   },
   {
    "code": "from datetime import datetime\n\n# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n\n# Construct and save the submission:\nsubmission_df = pd.DataFrame({\n    \"Id\": test['id'], \n    \"Class\": test_predictions,\n}, columns=['Id', 'Class'])\ntimestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\nsubmission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n\nprint('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\nprint('You may now upload this CSV file to Gradescope for scoring.')",
    "id": "aa5bacff8532404a8471d14006215349",
    "idx": 88,
    "time": "2020-11-13T17:53:08.231Z",
    "type": "execution"
   },
   {
    "id": "73428c5ed83743b199ed18dc26f18be3",
    "time": "2020-11-13T17:53:08.462Z",
    "type": "completion"
   },
   {
    "id": "665d4320ee5a44fd8e5fc2cc55ecd777",
    "time": "2020-11-13T17:53:08.523Z",
    "type": "completion"
   },
   {
    "id": "0dd28fcc619746e4831ad536f8956532",
    "time": "2020-11-13T17:53:08.540Z",
    "type": "completion"
   },
   {
    "id": "6ccaddb5360c45609af4d3b6991ca741",
    "time": "2020-11-13T17:53:08.558Z",
    "type": "completion"
   },
   {
    "id": "e8c8f77a5758407293ae0b201063880f",
    "time": "2020-11-13T17:53:08.585Z",
    "type": "completion"
   },
   {
    "id": "aa5bacff8532404a8471d14006215349",
    "time": "2020-11-13T17:53:08.632Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "8d92699bf7e0491e9daf8822790e9474",
    "idx": 0,
    "time": "2020-11-13T22:55:44.378Z",
    "type": "execution"
   },
   {
    "id": "8d92699bf7e0491e9daf8822790e9474",
    "time": "2020-11-13T22:55:45.038Z",
    "type": "completion"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "738b618383ac46c88818e98c53b9e4c0",
    "idx": 5,
    "time": "2020-11-13T23:00:32.434Z",
    "type": "execution"
   },
   {
    "id": "738b618383ac46c88818e98c53b9e4c0",
    "time": "2020-11-13T23:00:32.554Z",
    "type": "completion"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "7d8943a7ffe946dc8e0dcd444b871188",
    "idx": 8,
    "time": "2020-11-13T23:00:44.027Z",
    "type": "execution"
   },
   {
    "id": "7d8943a7ffe946dc8e0dcd444b871188",
    "time": "2020-11-13T23:00:44.851Z",
    "type": "completion"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "c7651e252a8945c1b901b2e9f2faca8a",
    "idx": 10,
    "time": "2020-11-13T23:02:17.157Z",
    "type": "execution"
   },
   {
    "id": "c7651e252a8945c1b901b2e9f2faca8a",
    "time": "2020-11-13T23:02:21.214Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().count_values",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:08:24.976Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:08:25.274Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().count_values()",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:08:32.778Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:08:32.913Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().size()",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:08:38.626Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:08:38.723Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:08:45.665Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:08:45.789Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().sum()\noriginal_training_data['subject'].replace(NaN, '')",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:09:17.313Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:09:17.424Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().sum()\noriginal_training_data['subject'].replace('NaN', '')",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:09:32.257Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:09:32.336Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "59ec1db92049437d8ed615209286f087",
    "idx": 13,
    "time": "2020-11-13T23:09:33.353Z",
    "type": "execution"
   },
   {
    "id": "59ec1db92049437d8ed615209286f087",
    "time": "2020-11-13T23:09:33.540Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().sum()\noriginal_training_data.replace('NaN', '')",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:09:45.706Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:09:45.814Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "59ec1db92049437d8ed615209286f087",
    "idx": 13,
    "time": "2020-11-13T23:09:49.106Z",
    "type": "execution"
   },
   {
    "id": "59ec1db92049437d8ed615209286f087",
    "time": "2020-11-13T23:09:49.242Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().sum()\noriginal_training_data['subject'].fillna('')",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:10:30.868Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:10:30.945Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "59ec1db92049437d8ed615209286f087",
    "idx": 13,
    "time": "2020-11-13T23:10:33.124Z",
    "type": "execution"
   },
   {
    "id": "59ec1db92049437d8ed615209286f087",
    "time": "2020-11-13T23:10:33.277Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().sum()\noriginal_training_data['subject'] = original_training_data['subject'].replace('NaN', '')",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:11:35.763Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:11:35.873Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "59ec1db92049437d8ed615209286f087",
    "idx": 13,
    "time": "2020-11-13T23:11:36.564Z",
    "type": "execution"
   },
   {
    "id": "59ec1db92049437d8ed615209286f087",
    "time": "2020-11-13T23:11:36.643Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "idx": 12,
    "time": "2020-11-13T23:13:56.124Z",
    "type": "execution"
   },
   {
    "id": "56e25ec2290c489e8ce98ba608ca2d28",
    "time": "2020-11-13T23:13:56.360Z",
    "type": "completion"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "9645f145bd454b1d828065b1e12a5ca8",
    "idx": 13,
    "time": "2020-11-13T23:14:02.612Z",
    "type": "execution"
   },
   {
    "id": "9645f145bd454b1d828065b1e12a5ca8",
    "time": "2020-11-13T23:14:02.681Z",
    "type": "completion"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "ac59cef9c82343c6aa48e801ee4adaa1",
    "idx": 14,
    "time": "2020-11-13T23:14:11.906Z",
    "type": "execution"
   },
   {
    "id": "ac59cef9c82343c6aa48e801ee4adaa1",
    "time": "2020-11-13T23:14:12.004Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "59ec1db92049437d8ed615209286f087",
    "idx": 15,
    "time": "2020-11-13T23:14:13.905Z",
    "type": "execution"
   },
   {
    "id": "59ec1db92049437d8ed615209286f087",
    "time": "2020-11-13T23:14:14.047Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0].first('email')\nfirst_spam = original_training_data[original_training_data['spam']==1].first('email')\nprint(first_ham)\nprint(first_spam)",
    "id": "11a9752e691342e5805fc2605af80571",
    "idx": 17,
    "time": "2020-11-13T23:18:22.342Z",
    "type": "execution"
   },
   {
    "id": "11a9752e691342e5805fc2605af80571",
    "time": "2020-11-13T23:18:22.476Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].first()\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].first()\nprint(first_ham)\nprint(first_spam)",
    "id": "11a9752e691342e5805fc2605af80571",
    "idx": 17,
    "time": "2020-11-13T23:19:17.809Z",
    "type": "execution"
   },
   {
    "id": "11a9752e691342e5805fc2605af80571",
    "time": "2020-11-13T23:19:17.912Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'][0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'][0]\nprint(first_ham)\nprint(first_spam)",
    "id": "11a9752e691342e5805fc2605af80571",
    "idx": 17,
    "time": "2020-11-13T23:19:52.552Z",
    "type": "execution"
   },
   {
    "id": "11a9752e691342e5805fc2605af80571",
    "time": "2020-11-13T23:19:52.819Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email']\nfirst_spam = original_training_data[original_training_data['spam']==1]['email']\nprint(first_ham)\nprint(first_spam)",
    "id": "11a9752e691342e5805fc2605af80571",
    "idx": 17,
    "time": "2020-11-13T23:20:14.082Z",
    "type": "execution"
   },
   {
    "id": "11a9752e691342e5805fc2605af80571",
    "time": "2020-11-13T23:20:14.201Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].first\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].first\nprint(first_ham)\nprint(first_spam)",
    "id": "11a9752e691342e5805fc2605af80571",
    "idx": 17,
    "time": "2020-11-13T23:21:04.266Z",
    "type": "execution"
   },
   {
    "id": "11a9752e691342e5805fc2605af80571",
    "time": "2020-11-13T23:21:04.341Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].first()\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].first()\nprint(first_ham)\nprint(first_spam)",
    "id": "11a9752e691342e5805fc2605af80571",
    "idx": 17,
    "time": "2020-11-13T23:21:25.345Z",
    "type": "execution"
   },
   {
    "id": "11a9752e691342e5805fc2605af80571",
    "time": "2020-11-13T23:21:25.455Z",
    "type": "completion"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "11a9752e691342e5805fc2605af80571",
    "idx": 17,
    "time": "2020-11-13T23:22:20.619Z",
    "type": "execution"
   },
   {
    "id": "11a9752e691342e5805fc2605af80571",
    "time": "2020-11-13T23:22:20.713Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "f7f0504873e149a184d4c57f123aa589",
    "idx": 18,
    "time": "2020-11-13T23:22:22.786Z",
    "type": "execution"
   },
   {
    "id": "f7f0504873e149a184d4c57f123aa589",
    "time": "2020-11-13T23:22:22.911Z",
    "type": "completion"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "ca0ded3ddf73452e85c6ee67f70787b8",
    "idx": 22,
    "time": "2020-11-13T23:36:00.488Z",
    "type": "execution"
   },
   {
    "id": "ca0ded3ddf73452e85c6ee67f70787b8",
    "time": "2020-11-13T23:36:00.817Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [texts.isin(words)]\n    return indicator_array",
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "idx": 25,
    "time": "2020-11-13T23:48:40.984Z",
    "type": "execution"
   },
   {
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "time": "2020-11-13T23:48:41.057Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "46b9e8afe0c74ad8acc28e85c6e527ce",
    "idx": 26,
    "time": "2020-11-13T23:48:42.008Z",
    "type": "execution"
   },
   {
    "id": "46b9e8afe0c74ad8acc28e85c6e527ce",
    "time": "2020-11-13T23:48:42.189Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [for i in texts i.isin(words)]\n    return indicator_array",
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "idx": 25,
    "time": "2020-11-13T23:49:27.100Z",
    "type": "execution"
   },
   {
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "time": "2020-11-13T23:49:27.174Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 for i in texts i.isin(words) else 0]\n    return indicator_array",
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "idx": 25,
    "time": "2020-11-13T23:50:04.223Z",
    "type": "execution"
   },
   {
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "time": "2020-11-13T23:50:04.316Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 for i in texts if i.isin(words) else 0]\n    return indicator_array",
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "idx": 25,
    "time": "2020-11-13T23:51:02.239Z",
    "type": "execution"
   },
   {
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "time": "2020-11-13T23:51:02.320Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 if texts.isin(words) else 0]\n    return indicator_array",
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "idx": 25,
    "time": "2020-11-13T23:52:12.175Z",
    "type": "execution"
   },
   {
    "id": "8aa22c2b3a7c455687a219d326ac29ca",
    "time": "2020-11-13T23:52:12.240Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "5c70ff2da2124d328ffea715219380d7",
    "idx": 0,
    "time": "2020-11-13T23:54:13.574Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "1a658029fb9941f2b9344bdf46c3f26f",
    "idx": 5,
    "time": "2020-11-13T23:54:13.584Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "70186e8e33b9400689f6de14cc89aeaf",
    "idx": 8,
    "time": "2020-11-13T23:54:13.589Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "1e51fdc1c98644a9921a6eb4e52489fd",
    "idx": 10,
    "time": "2020-11-13T23:54:13.592Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "dca892b85158489f87d035a891201bf7",
    "idx": 12,
    "time": "2020-11-13T23:54:13.595Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "12b8415174444219b73a291c5678621d",
    "idx": 13,
    "time": "2020-11-13T23:54:13.598Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "6c41978c12b24cef8f7f06f8b63c7ff6",
    "idx": 14,
    "time": "2020-11-13T23:54:13.601Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "7a16fad3777544ea8456205d5e4fc21e",
    "idx": 15,
    "time": "2020-11-13T23:54:13.604Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "d97b67d9c26e4d6683c8828ea837d27b",
    "idx": 17,
    "time": "2020-11-13T23:54:13.607Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "d6915305d9a44fc786391d806f2a3b43",
    "idx": 18,
    "time": "2020-11-13T23:54:13.609Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "6576c973f05842868253a0f47436247c",
    "idx": 22,
    "time": "2020-11-13T23:54:13.613Z",
    "type": "execution"
   },
   {
    "id": "5c70ff2da2124d328ffea715219380d7",
    "time": "2020-11-13T23:54:13.726Z",
    "type": "completion"
   },
   {
    "id": "1a658029fb9941f2b9344bdf46c3f26f",
    "time": "2020-11-13T23:54:13.729Z",
    "type": "completion"
   },
   {
    "id": "70186e8e33b9400689f6de14cc89aeaf",
    "time": "2020-11-13T23:54:13.749Z",
    "type": "completion"
   },
   {
    "id": "1e51fdc1c98644a9921a6eb4e52489fd",
    "time": "2020-11-13T23:54:14.260Z",
    "type": "completion"
   },
   {
    "id": "dca892b85158489f87d035a891201bf7",
    "time": "2020-11-13T23:54:14.269Z",
    "type": "completion"
   },
   {
    "id": "12b8415174444219b73a291c5678621d",
    "time": "2020-11-13T23:54:14.322Z",
    "type": "completion"
   },
   {
    "id": "6c41978c12b24cef8f7f06f8b63c7ff6",
    "time": "2020-11-13T23:54:14.326Z",
    "type": "completion"
   },
   {
    "id": "7a16fad3777544ea8456205d5e4fc21e",
    "time": "2020-11-13T23:54:14.404Z",
    "type": "completion"
   },
   {
    "id": "d97b67d9c26e4d6683c8828ea837d27b",
    "time": "2020-11-13T23:54:14.408Z",
    "type": "completion"
   },
   {
    "id": "d6915305d9a44fc786391d806f2a3b43",
    "time": "2020-11-13T23:54:14.482Z",
    "type": "completion"
   },
   {
    "id": "6576c973f05842868253a0f47436247c",
    "time": "2020-11-13T23:54:14.499Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 for i in texts if i in words else 0]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-13T23:54:53.364Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-13T23:54:53.445Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 for i in texts if (i in words) else 0]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-13T23:55:14.420Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-13T23:55:14.526Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 for i in texts if i.str.contains(words) else 0]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-13T23:57:36.564Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-13T23:57:36.640Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 if i.str.contains(words) else 0 for i in texts]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:00:01.348Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:00:02.859Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:00:03.911Z",
    "type": "completion"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:00:03.939Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 if i in words else 0 for i in texts]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:00:24.340Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:00:26.052Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:00:26.323Z",
    "type": "completion"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:00:33.202Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [[1 if i in words else 0 for i in texts]]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:01:07.033Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:01:07.106Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:01:08.792Z",
    "type": "execution"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:01:09.630Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [[1 if i in j for j in words else 0 for i in texts]]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:02:02.238Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:02:02.322Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [[1 if i in (j for j in words) else 0 for i in texts]]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:02:18.646Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:02:18.895Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:02:20.366Z",
    "type": "execution"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:02:20.497Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = [1 if i in (j for j in words) else 0 for i in texts]\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:02:41.592Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:02:41.685Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:02:42.111Z",
    "type": "execution"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:02:42.203Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([1 if i in (j for j in words) else 0 for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:03:03.246Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:03:03.321Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:03:05.087Z",
    "type": "execution"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:03:05.215Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([1 if i in (j for j in words) else 0] for i in texts)\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:03:31.969Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:03:32.049Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:03:33.753Z",
    "type": "execution"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:03:33.835Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i in (j for j in words) else 0] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:04:05.025Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:04:05.978Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:04:06.928Z",
    "type": "execution"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:04:07.011Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "5c70ff2da2124d328ffea715219380d7",
    "idx": 0,
    "time": "2020-11-14T00:04:51.371Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "1a658029fb9941f2b9344bdf46c3f26f",
    "idx": 5,
    "time": "2020-11-14T00:04:51.382Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "70186e8e33b9400689f6de14cc89aeaf",
    "idx": 8,
    "time": "2020-11-14T00:04:51.385Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "1e51fdc1c98644a9921a6eb4e52489fd",
    "idx": 10,
    "time": "2020-11-14T00:04:51.390Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "dca892b85158489f87d035a891201bf7",
    "idx": 12,
    "time": "2020-11-14T00:04:51.395Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "12b8415174444219b73a291c5678621d",
    "idx": 13,
    "time": "2020-11-14T00:04:51.398Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "6c41978c12b24cef8f7f06f8b63c7ff6",
    "idx": 14,
    "time": "2020-11-14T00:04:51.401Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "7a16fad3777544ea8456205d5e4fc21e",
    "idx": 15,
    "time": "2020-11-14T00:04:51.405Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "d97b67d9c26e4d6683c8828ea837d27b",
    "idx": 17,
    "time": "2020-11-14T00:04:51.409Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "d6915305d9a44fc786391d806f2a3b43",
    "idx": 18,
    "time": "2020-11-14T00:04:51.411Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "6576c973f05842868253a0f47436247c",
    "idx": 22,
    "time": "2020-11-14T00:04:51.416Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i in (j for j in words) else 0] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:04:51.420Z",
    "type": "execution"
   },
   {
    "id": "5c70ff2da2124d328ffea715219380d7",
    "time": "2020-11-14T00:04:51.494Z",
    "type": "completion"
   },
   {
    "id": "1a658029fb9941f2b9344bdf46c3f26f",
    "time": "2020-11-14T00:04:51.541Z",
    "type": "completion"
   },
   {
    "id": "70186e8e33b9400689f6de14cc89aeaf",
    "time": "2020-11-14T00:04:51.568Z",
    "type": "completion"
   },
   {
    "id": "1e51fdc1c98644a9921a6eb4e52489fd",
    "time": "2020-11-14T00:04:52.118Z",
    "type": "completion"
   },
   {
    "id": "dca892b85158489f87d035a891201bf7",
    "time": "2020-11-14T00:04:52.160Z",
    "type": "completion"
   },
   {
    "id": "12b8415174444219b73a291c5678621d",
    "time": "2020-11-14T00:04:52.176Z",
    "type": "completion"
   },
   {
    "id": "6c41978c12b24cef8f7f06f8b63c7ff6",
    "time": "2020-11-14T00:04:52.183Z",
    "type": "completion"
   },
   {
    "id": "7a16fad3777544ea8456205d5e4fc21e",
    "time": "2020-11-14T00:04:52.266Z",
    "type": "completion"
   },
   {
    "id": "d97b67d9c26e4d6683c8828ea837d27b",
    "time": "2020-11-14T00:04:52.283Z",
    "type": "completion"
   },
   {
    "id": "d6915305d9a44fc786391d806f2a3b43",
    "time": "2020-11-14T00:04:52.446Z",
    "type": "completion"
   },
   {
    "id": "6576c973f05842868253a0f47436247c",
    "time": "2020-11-14T00:04:52.454Z",
    "type": "completion"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:04:52.477Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:05:05.379Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:05:05.465Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i in (j for j in words) else 0 for i in texts]])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:05:44.904Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:05:44.975Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:05:45.679Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:05:45.788Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i in (j for j in words) else 0] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:06:09.470Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:06:09.552Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:06:10.767Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:06:10.849Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i in j for j in words else 0] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:08:21.779Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:08:22.169Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i in j else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:09:29.917Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:09:29.995Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:09:31.124Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:09:31.234Z",
    "type": "completion"
   },
   {
    "code": "np.allclose(words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello'])),\n                np.array([[1, 0, 0], \n                          [1, 0, 1]]))",
    "id": "a2b3becbfee842fa8cb25c64ad0d6555",
    "idx": 27,
    "time": "2020-11-14T00:09:32.612Z",
    "type": "execution"
   },
   {
    "id": "a2b3becbfee842fa8cb25c64ad0d6555",
    "time": "2020-11-14T00:09:32.695Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.str.contains(j) else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:11:30.939Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:11:31.019Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:11:32.400Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:11:32.541Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if texts.str.contains(j) else 0 for j in words]])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:12:19.234Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:12:19.320Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:12:20.370Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:12:20.493Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:13:20.379Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:13:20.851Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:13:22.891Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:13:22.978Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.index(j) else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:14:01.772Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:14:01.836Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:14:02.530Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:14:02.652Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i in j else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:15:22.565Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:15:22.677Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:15:23.263Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:15:23.365Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(\"is\") != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:16:19.862Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:16:19.943Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:16:20.508Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:16:20.582Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:16:27.501Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:16:27.583Z",
    "type": "completion"
   },
   {
    "code": "words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello']))",
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "idx": 26,
    "time": "2020-11-14T00:16:28.077Z",
    "type": "execution"
   },
   {
    "id": "ee3c6d7f3ae54a6c97b6c53daa73a571",
    "time": "2020-11-14T00:16:28.158Z",
    "type": "completion"
   },
   {
    "code": "np.allclose(words_in_texts(['hello', 'bye', 'world'], \n                               pd.Series(['hello', 'hello worldhello'])),\n                np.array([[1, 0, 0], \n                          [1, 0, 1]]))",
    "id": "a2b3becbfee842fa8cb25c64ad0d6555",
    "idx": 27,
    "time": "2020-11-14T00:16:29.398Z",
    "type": "execution"
   },
   {
    "id": "a2b3becbfee842fa8cb25c64ad0d6555",
    "time": "2020-11-14T00:16:29.533Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 28,
    "time": "2020-11-14T00:16:30.445Z",
    "type": "execution"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:16:30.618Z",
    "type": "completion"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "idx": 25,
    "time": "2020-11-14T00:17:36.439Z",
    "type": "execution"
   },
   {
    "id": "c26197fae25c4b6e812ad021dc576fe5",
    "time": "2020-11-14T00:17:36.513Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "02976012872247cdbad926f6d776b965",
    "idx": 26,
    "time": "2020-11-14T00:17:37.120Z",
    "type": "execution"
   },
   {
    "id": "02976012872247cdbad926f6d776b965",
    "time": "2020-11-14T00:17:37.228Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "8a015c2500d74d3d96d105c9f0bb51e6",
    "idx": 0,
    "time": "2020-11-14T04:09:41.466Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "8c844925f438460fac40cf8ac0501539",
    "idx": 5,
    "time": "2020-11-14T04:09:41.479Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "fde0328f8a544d11866c032a0efa3b98",
    "idx": 8,
    "time": "2020-11-14T04:09:41.491Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "a045b11294ed433080c4c84f61c99fa5",
    "idx": 10,
    "time": "2020-11-14T04:09:41.495Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "b299dee1479544a7874557c3f948f036",
    "idx": 12,
    "time": "2020-11-14T04:09:41.502Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "9d7ff90a5d864e18a34a1a4c0fb267c3",
    "idx": 13,
    "time": "2020-11-14T04:09:41.505Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "a02ef01a969f4ffd92a6d3c4746108be",
    "idx": 14,
    "time": "2020-11-14T04:09:41.510Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "e314b65ebcc94bbd866292e64543148c",
    "idx": 15,
    "time": "2020-11-14T04:09:41.513Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "015acb28d25147a5b6a09a79b5fab731",
    "idx": 17,
    "time": "2020-11-14T04:09:41.519Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "ecc1dcbd3ddc4d8c9976cc9c8db619a5",
    "idx": 18,
    "time": "2020-11-14T04:09:41.521Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "bcea18f9b19d458bb9aca218507ec150",
    "idx": 22,
    "time": "2020-11-14T04:09:41.527Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "96028e7a81b54d8a9ff3c98179db06d6",
    "idx": 25,
    "time": "2020-11-14T04:09:41.531Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "7f6ce99fbabf4e4193b0f53e020dcfa2",
    "idx": 26,
    "time": "2020-11-14T04:09:41.534Z",
    "type": "execution"
   },
   {
    "id": "8a015c2500d74d3d96d105c9f0bb51e6",
    "time": "2020-11-14T04:09:41.969Z",
    "type": "completion"
   },
   {
    "id": "8c844925f438460fac40cf8ac0501539",
    "time": "2020-11-14T04:09:41.972Z",
    "type": "completion"
   },
   {
    "id": "fde0328f8a544d11866c032a0efa3b98",
    "time": "2020-11-14T04:09:42.989Z",
    "type": "completion"
   },
   {
    "id": "a045b11294ed433080c4c84f61c99fa5",
    "time": "2020-11-14T04:09:43.495Z",
    "type": "completion"
   },
   {
    "id": "b299dee1479544a7874557c3f948f036",
    "time": "2020-11-14T04:09:43.530Z",
    "type": "completion"
   },
   {
    "id": "9d7ff90a5d864e18a34a1a4c0fb267c3",
    "time": "2020-11-14T04:09:43.534Z",
    "type": "completion"
   },
   {
    "id": "a02ef01a969f4ffd92a6d3c4746108be",
    "time": "2020-11-14T04:09:43.546Z",
    "type": "completion"
   },
   {
    "id": "e314b65ebcc94bbd866292e64543148c",
    "time": "2020-11-14T04:09:43.678Z",
    "type": "completion"
   },
   {
    "id": "015acb28d25147a5b6a09a79b5fab731",
    "time": "2020-11-14T04:09:43.697Z",
    "type": "completion"
   },
   {
    "id": "ecc1dcbd3ddc4d8c9976cc9c8db619a5",
    "time": "2020-11-14T04:09:43.745Z",
    "type": "completion"
   },
   {
    "id": "bcea18f9b19d458bb9aca218507ec150",
    "time": "2020-11-14T04:09:44.029Z",
    "type": "completion"
   },
   {
    "id": "96028e7a81b54d8a9ff3c98179db06d6",
    "time": "2020-11-14T04:09:44.036Z",
    "type": "completion"
   },
   {
    "id": "7f6ce99fbabf4e4193b0f53e020dcfa2",
    "time": "2020-11-14T04:09:44.040Z",
    "type": "completion"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "dffc40367aa448ea8c1881f9d28ec1ff",
    "idx": 29,
    "time": "2020-11-14T04:21:54.017Z",
    "type": "execution"
   },
   {
    "id": "dffc40367aa448ea8c1881f9d28ec1ff",
    "time": "2020-11-14T04:21:54.219Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\ntrain",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:23:04.057Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:23:04.377Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\n\ntrain.melt(\"spam\")",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:27:32.541Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:27:32.798Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nappear = words_in_texts([\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ], train[\"email\"]).T\nfrequancy = np.sum(appear)/len(appear)\nfrequancy",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:34:43.202Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:34:43.392Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nappear = words_in_texts([\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ], train[\"email\"]).T\n# frequancy = np.sum(appear)/len(appear)\n# frequancy\nappear",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:35:00.252Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:35:00.483Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nappear = words_in_texts([\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ], train[\"email\"]).T\nfrequancy = [sum(i) for i in appear]/len(appear)\nfrequancy",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:35:47.910Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:35:48.614Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nappear = words_in_texts([\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ], train[\"email\"]).T\nfrequancy = np.array([sum(i) for i in appear])/len(appear)\nfrequancy",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:36:04.630Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:36:04.849Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nappear1 = words_in_texts([\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ], ham).T\nappear2 = words_in_texts([\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ], spam).T\nfrequancy1 = np.array([sum(i) for i in appear1])/len(appear1)\nfrequancy2 = np.array([sum(i) for i in appear2])/len(appear2)\nfrequancy1",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:38:13.493Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:38:13.569Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nappear1 = words_in_texts([\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ], ham[\"email\"]).T\nappear2 = words_in_texts([\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ], spam[\"email\"]).T\nfrequancy1 = np.array([sum(i) for i in appear1])/len(appear1)\nfrequancy2 = np.array([sum(i) for i in appear2])/len(appear2)\nfrequancy1",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:38:41.604Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:38:41.815Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nwords = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\nappear1 = words_in_texts(words, ham[\"email\"]).T\nappear2 = words_in_texts(words, spam[\"email\"]).T\nproportion1 = np.array([sum(i)/len(i) for i in appear1])\n# proportion2 = np.array([sum(i) for i in appear2])/len(appear2)\n# sns.barplot(x=\"words\", y=\"proportion\", hue=\"spam\", data=tips)\nproportion1\n",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:44:12.244Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:44:12.679Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nwords = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\nappear1 = words_in_texts(words, ham[\"email\"]).T\nappear2 = words_in_texts(words, spam[\"email\"]).T\nproportion1 = np.array([sum(i)/len(i) for i in appear1])\nproportion2 = np.array([sum(i)/len(i) for i in appear2])\ndf = pd.DataFrame({\n    'word_1': proportion1.T,\n    'word_2': proportion2.T,\n    'type': ['ham', 'spam']\n})\ndf\n# sns.barplot(x=\"words\", y=\"proportion\", hue=\"spam\", data=tips)\n# proportion2\n",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:51:44.386Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:51:44.652Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nwords = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\nappear1 = words_in_texts(words, ham[\"email\"]).T\nappear2 = words_in_texts(words, spam[\"email\"]).T\nproportion1 = np.array([sum(i)/len(i) for i in appear1])\nproportion2 = np.array([sum(i)/len(i) for i in appear2])\ndf = pd.DataFrame({\n    'word_1': proportion1.T,\n    'word_2': proportion2.T,\n    'type': np.array('ham', 'spam')\n})\ndf\n# sns.barplot(x=\"words\", y=\"proportion\", hue=\"spam\", data=tips)\n# proportion2\n",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:52:28.937Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:52:29.178Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nwords = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\nappear1 = words_in_texts(words, ham[\"email\"]).T\nappear2 = words_in_texts(words, spam[\"email\"]).T\nproportion1 = np.array([sum(i)/len(i) for i in appear1])\nproportion2 = np.array([sum(i)/len(i) for i in appear2])\ndf = pd.DataFrame({\n    'word_1': proportion1.T,\n    'word_2': proportion2.T,\n    'type': np.array(['ham', 'spam'])*6\n})\ndf\n# sns.barplot(x=\"words\", y=\"proportion\", hue=\"spam\", data=tips)\n# proportion2\n",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:52:48.976Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:52:49.226Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nwords = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\nappear1 = words_in_texts(words, ham[\"email\"]).T\nappear2 = words_in_texts(words, spam[\"email\"]).T\nproportion1 = np.array([sum(i)/len(i) for i in appear1])\nproportion2 = np.array([sum(i)/len(i) for i in appear2])\ndf = pd.DataFrame({\n    'word_1': proportion1.T,\n    'word_2': proportion2.T,\n    'type': ['ham', 'spam']*6\n})\ndf\n# sns.barplot(x=\"words\", y=\"proportion\", hue=\"spam\", data=tips)\n# proportion2\n",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:53:06.507Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:53:06.797Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nwords = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\nappear1 = words_in_texts(words, ham[\"email\"]).T\nappear2 = words_in_texts(words, spam[\"email\"]).T\nproportion1 = np.array([sum(i)/len(i) for i in appear1])\nproportion2 = np.array([sum(i)/len(i) for i in appear2])\n# sns.barplot(x=\"words\", y=\"proportion\", hue=\"spam\", data=tips)\nproportion2\n",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T04:57:48.581Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T04:57:49.689Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\ndf = pd.DataFrame({\n    \"body\":  words_in_texts([\"body\"], train[\"email\"]),\n    \"business\": words_in_texts([\"business\"], train[\"email\"]),\n    \"html\": words_in_texts([\"html\"], train[\"email\"]),\n    \"money\": words_in_texts([\"money\"], train[\"email\"]),\n    \"offer\": words_in_texts([\"offer\"], train[\"email\"]),\n    \"please\": words_in_texts([\"please\"], train[\"email\"]),\n    'type': train[\"spam\"]\n})\ndf",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:01:30.798Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:01:31.721Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nwords = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\nappear1 = words_in_texts(words, ham[\"email\"]).T\nappear2 = words_in_texts(words, spam[\"email\"]).T\nproportion1 = np.array([sum(i)/len(i) for i in appear1])\nproportion2 = np.array([sum(i)/len(i) for i in appear2])\nsns.barplot(x=words, y=[proportion1,proportion2])\n# proportion2 \n",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T05:03:41.676Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T05:03:42.101Z",
    "type": "completion"
   },
   {
    "code": "train=train.reset_index(drop=True) # We must do this in order to preserve the ordering of emails to labels for words_in_texts\nham = train[train[\"spam\"] == 0]\nspam = train[train[\"spam\"] == 1]\nwords = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\" ]\nappear1 = words_in_texts(words, ham[\"email\"]).T\nappear2 = words_in_texts(words, spam[\"email\"]).T\nproportion1 = np.array([sum(i)/len(i) for i in appear1])\nproportion2 = np.array([sum(i)/len(i) for i in appear2])\n# sns.barplot(x=words, y=[proportion1,proportion2])\nproportion2 \n",
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "idx": 31,
    "time": "2020-11-14T05:04:12.291Z",
    "type": "execution"
   },
   {
    "id": "c85900277cdb459884cdbc859bfe09a7",
    "time": "2020-11-14T05:04:12.508Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"])\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:06:09.734Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:06:09.994Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"])\ntemp\n# df = pd.DataFrame({\n#     \"body\":  temp[0],\n#     \"business\": temp[1],\n#     \"html\": temp[2],\n#     \"money\": temp[3],\n#     \"offer\": temp[4],\n#     \"please\": temp[5],\n#     'type': train[\"spam\"]\n# })\n# df",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:06:36.508Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:06:36.717Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ntemp\n# df = pd.DataFrame({\n#     \"body\":  temp[0],\n#     \"business\": temp[1],\n#     \"html\": temp[2],\n#     \"money\": temp[3],\n#     \"offer\": temp[4],\n#     \"please\": temp[5],\n#     'type': train[\"spam\"]\n# })\n# df",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:06:50.698Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:06:50.898Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:06:59.899Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:07:00.158Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf.melt(\"type\")",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:07:21.717Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:07:21.989Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf.melt(\"type\")\nDF",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:07:50.082Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:07:50.321Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf.melt(\"type\")\ndf",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:07:55.019Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:07:55.253Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:08:12.760Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:08:12.945Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nde",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:08:16.090Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:08:16.413Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\ndf",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:08:19.169Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:08:19.396Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nspam = df[df[\"type\"] == 0]\nspam",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:10:07.406Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:10:08.002Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\ndf.groupby([\"type\",\"variable\"])",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:11:19.674Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:11:20.076Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\ndf.groupby([\"type\",\"variable\"]).display",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:11:29.435Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:11:29.662Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\ndf.groupby([\"type\",\"variable\"]).display()",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:11:33.594Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:11:33.825Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\ndf.groupby([[\"type\",\"variable\"]])",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:11:45.947Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:11:46.210Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"])\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:12:00.822Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:12:01.099Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"variable\"])\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:12:22.847Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:12:23.050Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby(\"variable\")\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:12:30.258Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:12:30.686Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby(\"variable\").sum()\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:13:56.032Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:13:56.304Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:14:32.708Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:14:33.102Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:15:57.817Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:15:58.325Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:17:59.873Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:18:00.308Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:18:36.898Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:18:37.137Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(train[\"email\"])\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:22:47.698Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:22:48.158Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd['type'] = df.index\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:24:04.158Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:24:04.452Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd['variable'] = df.index\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:24:38.414Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:24:38.675Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd['variable'] = d.index\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:24:42.517Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:24:42.754Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd['variable'] = d.index[1]\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:24:57.445Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:24:57.717Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd.reset_index(level=[\"type\",\"variable\"])\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:25:45.046Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:25:45.282Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd.reset_index()\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:26:29.545Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:26:29.889Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd = d.reset_index()\nd",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:26:37.624Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:26:37.896Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd = d.reset_index()\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:27:30.138Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:27:30.729Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).size()/len(temp[0])\nd\n# d = d.reset_index()\n# sns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:29:00.119Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:29:00.319Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\nd\n# d = d.reset_index()\n# sns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:29:06.693Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:29:06.914Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).sum()/len(temp[0])\ndf\n# d = d.reset_index()\n# sns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:31:35.481Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:31:35.812Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd\n# d = d.reset_index()\n# sns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:34:14.333Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:34:14.573Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:34:29.892Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:34:30.457Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nd\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:36:01.157Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:36:01.665Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:38:04.435Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:38:05.837Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\")\nplt.tight_layout()\nplt.show\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:38:21.643Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:38:22.759Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:39:34.146Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:39:35.153Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\naxes.set_ylim([0,0,1.0])\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:41:07.535Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:41:08.132Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\naxes.set_ylim([0,0,1.1])\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:41:11.897Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:41:12.599Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.set_ylim([0,0,1.1])\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:41:20.112Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:41:20.705Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim([0,0,1.1])\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:41:31.160Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:41:32.451Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:42:02.010Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:42:02.543Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.figure(figsize=(8,8))\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:43:40.248Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:43:41.402Z",
    "type": "completion"
   },
   {
    "code": "words = [\"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"body\":  temp[0],\n    \"business\": temp[1],\n    \"html\": temp[2],\n    \"money\": temp[3],\n    \"offer\": temp[4],\n    \"please\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");\n",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 32,
    "time": "2020-11-14T05:43:51.421Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:43:52.182Z",
    "type": "completion"
   },
   {
    "code": "words = [\"truly\",\"credit\",\"better\",\"happy\",\"bank\",\"hotel\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"truly\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"bank\": temp[4],\n    \"hotel\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T05:51:52.902Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:51:53.731Z",
    "type": "completion"
   },
   {
    "code": "words = [\"job\",\"credit\",\"better\",\"happy\",\"bank\",\"hotel\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"job\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"bank\": temp[4],\n    \"hotel\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T05:53:47.258Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:53:47.863Z",
    "type": "completion"
   },
   {
    "code": "words = [\"job\",\"credit\",\"better\",\"happy\",\"bank\",\"cash\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"job\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"bank\": temp[4],\n    \"cash\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T05:54:15.524Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:54:16.323Z",
    "type": "completion"
   },
   {
    "code": "words = [\"job\",\"credit\",\"better\",\"happy\",\"off\",\"cash\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"job\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"cash\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T05:56:16.568Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:56:17.189Z",
    "type": "completion"
   },
   {
    "code": "words = [\"job\",\"credit\",\"better\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"job\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T05:57:10.659Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:57:11.440Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"better\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T05:57:35.207Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:57:35.832Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"better\",\"review\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"review\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T05:58:32.248Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:58:32.941Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"better\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T05:58:39.737Z",
    "type": "execution"
   },
   {
    "id": "942da775988c47bd85300185c01d6c19",
    "time": "2020-11-14T05:58:40.415Z",
    "type": "completion"
   },
   {
    "code": "train[\"length\"] = train[np.sum(train[\"email\"])]\ntrain\n# plt.savefig('training_conditional_densities.png')",
    "id": "7725c16fd808470d975ae9e6b385b0c1",
    "idx": 34,
    "time": "2020-11-14T06:01:29.127Z",
    "type": "execution"
   },
   {
    "code": "train[\"length\"] = train[len(train[\"email\"])]\ntrain\n# plt.savefig('training_conditional_densities.png')",
    "id": "7725c16fd808470d975ae9e6b385b0c1",
    "idx": 34,
    "time": "2020-11-14T06:01:47.923Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"better\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "942da775988c47bd85300185c01d6c19",
    "idx": 31,
    "time": "2020-11-14T06:02:05.884Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "c04427052aa4459e95bb6fb55d549fc2",
    "idx": 0,
    "time": "2020-11-14T06:03:15.711Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "c1a2d3cd2d4c4b648a9d9b65b0a7b8dd",
    "idx": 5,
    "time": "2020-11-14T06:03:15.722Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "dde18e258a414b7b843b8f7a7f8f67cb",
    "idx": 8,
    "time": "2020-11-14T06:03:15.728Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "e161fe560aad418e8c8d5a78bb0d6cb8",
    "idx": 10,
    "time": "2020-11-14T06:03:15.733Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "2c74f347b43e43b987581a076829ff18",
    "idx": 12,
    "time": "2020-11-14T06:03:15.736Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "d8d3902e592f49ae8a9935ea0ed147d9",
    "idx": 13,
    "time": "2020-11-14T06:03:15.740Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "509400351c904dfb81bb266add5f3588",
    "idx": 14,
    "time": "2020-11-14T06:03:15.744Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "60ea4dad70e840bb87f1414c8d2888c5",
    "idx": 15,
    "time": "2020-11-14T06:03:15.748Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "60a63f15e7234e1caffcd26e4aee385e",
    "idx": 17,
    "time": "2020-11-14T06:03:15.751Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "1fa02334ef054c89a5f4e0a210023ee6",
    "idx": 18,
    "time": "2020-11-14T06:03:15.755Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "46d0fba5b727459084b3d623499ecbb5",
    "idx": 22,
    "time": "2020-11-14T06:03:15.759Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "1e0d4ad619de4bdfafb64116a298d329",
    "idx": 25,
    "time": "2020-11-14T06:03:15.763Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "08a63bb0a9aa4645a1dbc002a92b0f96",
    "idx": 26,
    "time": "2020-11-14T06:03:15.767Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "8374a4c632704075ae623fabcc1b2b20",
    "idx": 29,
    "time": "2020-11-14T06:03:15.771Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"better\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "f245b4d32e7e48208dbd6022c6b5ad0f",
    "idx": 31,
    "time": "2020-11-14T06:03:15.775Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "40eb8f36926843978246779557d7bbee",
    "idx": 0,
    "time": "2020-11-14T06:04:19.158Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "96131f3d9745403383158ef103255a82",
    "idx": 0,
    "time": "2020-11-14T06:08:37.101Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "11b1a1cb71e14dcea6a5dec9631d8815",
    "idx": 5,
    "time": "2020-11-14T06:08:37.116Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "a6255083fbdd40a78c301ae0fe3bc8ed",
    "idx": 8,
    "time": "2020-11-14T06:08:37.120Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "f2fef4c8f2ca4aa1891032b3b987b299",
    "idx": 10,
    "time": "2020-11-14T06:08:37.124Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "c73ac91fc83d4241802d94617163f49f",
    "idx": 12,
    "time": "2020-11-14T06:08:37.128Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "575654d4ec514a26ace5d26a221e84f0",
    "idx": 13,
    "time": "2020-11-14T06:08:37.130Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "f9957bb5d5df49d48458ce32b8fa75b5",
    "idx": 14,
    "time": "2020-11-14T06:08:37.133Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "2c5abccf3a404c0eb9d8bbbe8a2463e2",
    "idx": 15,
    "time": "2020-11-14T06:08:37.137Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "426d48dcc5f345f4a31b4301fd5f4de1",
    "idx": 17,
    "time": "2020-11-14T06:08:37.140Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "ca341fb76ee644b2869b720db9de3e69",
    "idx": 18,
    "time": "2020-11-14T06:08:37.143Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "43aaef3770c740d192761d5641388cca",
    "idx": 22,
    "time": "2020-11-14T06:08:37.146Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "3d25c30e68fd49848edb993b9bde9863",
    "idx": 25,
    "time": "2020-11-14T06:08:37.149Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "cc61131d7d18420c808550163e01589a",
    "idx": 26,
    "time": "2020-11-14T06:08:37.153Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "5bb46cf8cc744483a7972363be947899",
    "idx": 29,
    "time": "2020-11-14T06:08:37.157Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"better\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "c158a38d74fc4cc0820f4d0be1e64e3d",
    "idx": 31,
    "time": "2020-11-14T06:08:37.160Z",
    "type": "execution"
   },
   {
    "id": "96131f3d9745403383158ef103255a82",
    "time": "2020-11-14T06:08:37.965Z",
    "type": "completion"
   },
   {
    "id": "11b1a1cb71e14dcea6a5dec9631d8815",
    "time": "2020-11-14T06:08:37.966Z",
    "type": "completion"
   },
   {
    "id": "a6255083fbdd40a78c301ae0fe3bc8ed",
    "time": "2020-11-14T06:08:39.182Z",
    "type": "completion"
   },
   {
    "id": "f2fef4c8f2ca4aa1891032b3b987b299",
    "time": "2020-11-14T06:08:40.103Z",
    "type": "completion"
   },
   {
    "id": "c73ac91fc83d4241802d94617163f49f",
    "time": "2020-11-14T06:08:40.109Z",
    "type": "completion"
   },
   {
    "id": "575654d4ec514a26ace5d26a221e84f0",
    "time": "2020-11-14T06:08:40.138Z",
    "type": "completion"
   },
   {
    "id": "f9957bb5d5df49d48458ce32b8fa75b5",
    "time": "2020-11-14T06:08:40.147Z",
    "type": "completion"
   },
   {
    "id": "2c5abccf3a404c0eb9d8bbbe8a2463e2",
    "time": "2020-11-14T06:08:40.190Z",
    "type": "completion"
   },
   {
    "id": "426d48dcc5f345f4a31b4301fd5f4de1",
    "time": "2020-11-14T06:08:40.195Z",
    "type": "completion"
   },
   {
    "id": "ca341fb76ee644b2869b720db9de3e69",
    "time": "2020-11-14T06:08:40.247Z",
    "type": "completion"
   },
   {
    "id": "43aaef3770c740d192761d5641388cca",
    "time": "2020-11-14T06:08:40.312Z",
    "type": "completion"
   },
   {
    "id": "3d25c30e68fd49848edb993b9bde9863",
    "time": "2020-11-14T06:08:40.318Z",
    "type": "completion"
   },
   {
    "id": "cc61131d7d18420c808550163e01589a",
    "time": "2020-11-14T06:08:40.404Z",
    "type": "completion"
   },
   {
    "id": "5bb46cf8cc744483a7972363be947899",
    "time": "2020-11-14T06:08:40.515Z",
    "type": "completion"
   },
   {
    "id": "c158a38d74fc4cc0820f4d0be1e64e3d",
    "time": "2020-11-14T06:08:41.205Z",
    "type": "completion"
   },
   {
    "code": "train[\"length\"] = train[len(train[\"email\"])]\ntrain\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:08:54.591Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:08:54.993Z",
    "type": "completion"
   },
   {
    "code": "train[\"length\"] = [len(i) for i in train[\"email\"]]\ntrain\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:09:37.738Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:09:37.866Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nc\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:12:15.244Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:12:15.344Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nc = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:12:45.829Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:12:45.908Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nc = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nc\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:12:49.872Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:12:50.062Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nc = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nsns.distplot(x = \"length\", hue=\"spam\",data = c, )\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:13:56.230Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:13:56.463Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nc = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0]\nx2 = c[c[\"spam\"] == 1]\nsns.distplot(x = x1)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:15:47.930Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:15:48.578Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nc = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0]\nx2 = c[c[\"spam\"] == 1]\nsns.distplot(x1)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:16:23.257Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:16:23.826Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nc = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1]\nsns.distplot(x1)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:17:25.700Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:17:26.508Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nc = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1]\nx1\n# sns.distplot(x1)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:17:36.908Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:17:36.992Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1]\nx1\n# sns.distplot(x1)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:17:50.213Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:17:50.311Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1]\nsns.distplot(x1)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:17:56.955Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:17:57.512Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1)\nsns.distplot(x2)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:18:31.247Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:18:31.901Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1)\nsns.distplot(x2)\nplt.xlim(0,50000)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:18:53.138Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:18:54.162Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1,hist=False)\nsns.distplot(x2,hist=False)\nplt.xlim(0,50000)\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:19:11.512Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:19:12.017Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1,hist=False)\nsns.distplot(x2,hist=False)\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:20:17.440Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:20:18.140Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1,hist=False)\nsns.distplot(x2,hist=False)\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:20:52.299Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:20:52.765Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1, hist=False, name = \"Spam\")\nsns.distplot(x2, hist=False, name = \"Ham\")\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:21:28.613Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:21:28.741Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1, hist=False, label = \"Spam\")\nsns.distplot(x2, hist=False, label = \"Ham\")\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:21:38.836Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:21:39.426Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1, hist=False, label = \"Spam\")\nsns.distplot(x2, hist=False, label = \"Ham\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:22:03.034Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:22:03.515Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:22:19.380Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:22:19.866Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(8,8))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:22:54.309Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:22:55.176Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(8,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:23:02.117Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:23:02.787Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\n# plt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:23:09.200Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:23:09.929Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\n# c = c.replace({\"spam\":{0:\"Ham\", 1: \"Spam\"}})\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:23:43.846Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:23:44.621Z",
    "type": "completion"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:25:05.837Z",
    "type": "execution"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:25:06.630Z",
    "type": "completion"
   },
   {
    "code": "train",
    "id": "409197c248fe4c5fbbd95093d7178ff6",
    "idx": 34,
    "time": "2020-11-14T06:25:33.598Z",
    "type": "execution"
   },
   {
    "id": "409197c248fe4c5fbbd95093d7178ff6",
    "time": "2020-11-14T06:25:33.745Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "96131f3d9745403383158ef103255a82",
    "idx": 0,
    "time": "2020-11-14T06:25:50.503Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "11b1a1cb71e14dcea6a5dec9631d8815",
    "idx": 5,
    "time": "2020-11-14T06:25:50.508Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "a6255083fbdd40a78c301ae0fe3bc8ed",
    "idx": 8,
    "time": "2020-11-14T06:25:50.511Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "f2fef4c8f2ca4aa1891032b3b987b299",
    "idx": 10,
    "time": "2020-11-14T06:25:50.514Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "c73ac91fc83d4241802d94617163f49f",
    "idx": 12,
    "time": "2020-11-14T06:25:50.518Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "575654d4ec514a26ace5d26a221e84f0",
    "idx": 13,
    "time": "2020-11-14T06:25:50.520Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "f9957bb5d5df49d48458ce32b8fa75b5",
    "idx": 14,
    "time": "2020-11-14T06:25:50.523Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "2c5abccf3a404c0eb9d8bbbe8a2463e2",
    "idx": 15,
    "time": "2020-11-14T06:25:50.526Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "426d48dcc5f345f4a31b4301fd5f4de1",
    "idx": 17,
    "time": "2020-11-14T06:25:50.529Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "ca341fb76ee644b2869b720db9de3e69",
    "idx": 18,
    "time": "2020-11-14T06:25:50.531Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "43aaef3770c740d192761d5641388cca",
    "idx": 22,
    "time": "2020-11-14T06:25:50.534Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "3d25c30e68fd49848edb993b9bde9863",
    "idx": 25,
    "time": "2020-11-14T06:25:50.537Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "cc61131d7d18420c808550163e01589a",
    "idx": 26,
    "time": "2020-11-14T06:25:50.539Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "5bb46cf8cc744483a7972363be947899",
    "idx": 29,
    "time": "2020-11-14T06:25:50.544Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"better\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "c158a38d74fc4cc0820f4d0be1e64e3d",
    "idx": 31,
    "time": "2020-11-14T06:25:50.547Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "idx": 34,
    "time": "2020-11-14T06:25:50.550Z",
    "type": "execution"
   },
   {
    "id": "96131f3d9745403383158ef103255a82",
    "time": "2020-11-14T06:25:50.625Z",
    "type": "completion"
   },
   {
    "id": "11b1a1cb71e14dcea6a5dec9631d8815",
    "time": "2020-11-14T06:25:50.633Z",
    "type": "completion"
   },
   {
    "id": "a6255083fbdd40a78c301ae0fe3bc8ed",
    "time": "2020-11-14T06:25:50.681Z",
    "type": "completion"
   },
   {
    "id": "f2fef4c8f2ca4aa1891032b3b987b299",
    "time": "2020-11-14T06:25:51.135Z",
    "type": "completion"
   },
   {
    "id": "c73ac91fc83d4241802d94617163f49f",
    "time": "2020-11-14T06:25:51.185Z",
    "type": "completion"
   },
   {
    "id": "575654d4ec514a26ace5d26a221e84f0",
    "time": "2020-11-14T06:25:51.253Z",
    "type": "completion"
   },
   {
    "id": "f9957bb5d5df49d48458ce32b8fa75b5",
    "time": "2020-11-14T06:25:51.255Z",
    "type": "completion"
   },
   {
    "id": "2c5abccf3a404c0eb9d8bbbe8a2463e2",
    "time": "2020-11-14T06:25:51.340Z",
    "type": "completion"
   },
   {
    "id": "426d48dcc5f345f4a31b4301fd5f4de1",
    "time": "2020-11-14T06:25:51.380Z",
    "type": "completion"
   },
   {
    "id": "ca341fb76ee644b2869b720db9de3e69",
    "time": "2020-11-14T06:25:51.397Z",
    "type": "completion"
   },
   {
    "id": "43aaef3770c740d192761d5641388cca",
    "time": "2020-11-14T06:25:51.467Z",
    "type": "completion"
   },
   {
    "id": "3d25c30e68fd49848edb993b9bde9863",
    "time": "2020-11-14T06:25:51.498Z",
    "type": "completion"
   },
   {
    "id": "cc61131d7d18420c808550163e01589a",
    "time": "2020-11-14T06:25:51.589Z",
    "type": "completion"
   },
   {
    "id": "5bb46cf8cc744483a7972363be947899",
    "time": "2020-11-14T06:25:51.671Z",
    "type": "completion"
   },
   {
    "id": "c158a38d74fc4cc0820f4d0be1e64e3d",
    "time": "2020-11-14T06:25:52.145Z",
    "type": "completion"
   },
   {
    "id": "d707275f00764ccaba1b392e4ac05ac2",
    "time": "2020-11-14T06:25:52.684Z",
    "type": "completion"
   },
   {
    "code": "train",
    "id": "d6bcfb38424548638165ff8d6784b1e5",
    "idx": 34,
    "time": "2020-11-14T06:26:01.344Z",
    "type": "execution"
   },
   {
    "id": "d6bcfb38424548638165ff8d6784b1e5",
    "time": "2020-11-14T06:26:01.465Z",
    "type": "completion"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = train[\"spam\"]\n\nX_train[:5], Y_train[:5]",
    "id": "6d22c40fda984ca982364dafee400ee4",
    "idx": 37,
    "time": "2020-11-14T06:30:04.451Z",
    "type": "execution"
   },
   {
    "id": "6d22c40fda984ca982364dafee400ee4",
    "time": "2020-11-14T06:30:04.715Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "dad103702f0d491daa8a3e4ae5e5430c",
    "idx": 38,
    "time": "2020-11-14T06:30:06.698Z",
    "type": "execution"
   },
   {
    "id": "dad103702f0d491daa8a3e4ae5e5430c",
    "time": "2020-11-14T06:30:06.825Z",
    "type": "completion"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "6d22c40fda984ca982364dafee400ee4",
    "idx": 37,
    "time": "2020-11-14T06:32:13.335Z",
    "type": "execution"
   },
   {
    "id": "6d22c40fda984ca982364dafee400ee4",
    "time": "2020-11-14T06:32:13.556Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "dad103702f0d491daa8a3e4ae5e5430c",
    "idx": 38,
    "time": "2020-11-14T06:32:17.749Z",
    "type": "execution"
   },
   {
    "id": "dad103702f0d491daa8a3e4ae5e5430c",
    "time": "2020-11-14T06:32:17.840Z",
    "type": "completion"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = train[\"spam\"]\n\nX_train[:5], Y_train[:5]",
    "id": "6d22c40fda984ca982364dafee400ee4",
    "idx": 37,
    "time": "2020-11-14T06:33:01.222Z",
    "type": "execution"
   },
   {
    "id": "6d22c40fda984ca982364dafee400ee4",
    "time": "2020-11-14T06:33:01.542Z",
    "type": "completion"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "6d22c40fda984ca982364dafee400ee4",
    "idx": 37,
    "time": "2020-11-14T06:33:51.805Z",
    "type": "execution"
   },
   {
    "id": "6d22c40fda984ca982364dafee400ee4",
    "time": "2020-11-14T06:33:52.028Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "dad103702f0d491daa8a3e4ae5e5430c",
    "idx": 38,
    "time": "2020-11-14T06:33:53.490Z",
    "type": "execution"
   },
   {
    "id": "dad103702f0d491daa8a3e4ae5e5430c",
    "time": "2020-11-14T06:33:53.591Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "88dd154aea4041a095cd470de8b55e6a",
    "idx": 40,
    "time": "2020-11-14T06:38:08.672Z",
    "type": "execution"
   },
   {
    "id": "88dd154aea4041a095cd470de8b55e6a",
    "time": "2020-11-14T06:38:08.891Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "97b4cffcf6f945228e65481c34913d9f",
    "idx": 41,
    "time": "2020-11-14T06:38:09.631Z",
    "type": "execution"
   },
   {
    "id": "97b4cffcf6f945228e65481c34913d9f",
    "time": "2020-11-14T06:38:09.823Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "78a86ea2ecd64708b3cb463f57f931e1",
    "idx": 45,
    "time": "2020-11-14T06:51:28.050Z",
    "type": "execution"
   },
   {
    "id": "78a86ea2ecd64708b3cb463f57f931e1",
    "time": "2020-11-14T06:51:28.419Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "d42fba1b54f3478687b1338d00faad07",
    "idx": 46,
    "time": "2020-11-14T06:51:29.416Z",
    "type": "execution"
   },
   {
    "id": "d42fba1b54f3478687b1338d00faad07",
    "time": "2020-11-14T06:51:29.593Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "29c1f129b5cd463eb75ae90821895475",
    "idx": 48,
    "time": "2020-11-14T07:00:54.000Z",
    "type": "execution"
   },
   {
    "id": "29c1f129b5cd463eb75ae90821895475",
    "time": "2020-11-14T07:00:54.124Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "2bf9d5510c4448488a6aea190c48b164",
    "idx": 49,
    "time": "2020-11-14T07:00:55.879Z",
    "type": "execution"
   },
   {
    "id": "2bf9d5510c4448488a6aea190c48b164",
    "time": "2020-11-14T07:00:56.092Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_acc = (np.sum(Y_train == 0)+np.sum(Y_train != 0))/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "29c1f129b5cd463eb75ae90821895475",
    "idx": 48,
    "time": "2020-11-14T07:03:27.587Z",
    "type": "execution"
   },
   {
    "id": "29c1f129b5cd463eb75ae90821895475",
    "time": "2020-11-14T07:03:27.683Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_acc = (np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "29c1f129b5cd463eb75ae90821895475",
    "idx": 48,
    "time": "2020-11-14T07:03:56.374Z",
    "type": "execution"
   },
   {
    "id": "29c1f129b5cd463eb75ae90821895475",
    "time": "2020-11-14T07:03:56.524Z",
    "type": "completion"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "29c1f129b5cd463eb75ae90821895475",
    "idx": 48,
    "time": "2020-11-14T07:04:00.805Z",
    "type": "execution"
   },
   {
    "id": "29c1f129b5cd463eb75ae90821895475",
    "time": "2020-11-14T07:04:01.099Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "2bf9d5510c4448488a6aea190c48b164",
    "idx": 49,
    "time": "2020-11-14T07:04:01.815Z",
    "type": "execution"
   },
   {
    "id": "2bf9d5510c4448488a6aea190c48b164",
    "time": "2020-11-14T07:04:02.149Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = pred == Y_train == 1\nTN = pred == Y_train == 0\nFP = pred != Y_train == 1\nFN = pred != Y_train == 0\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T07:58:58.792Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T07:58:59.045Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = (pred == Y_train == 1)\nTN = (pred == Y_train == 0)\nFP = (pred != Y_train == 1)\nFN = (pred != Y_train == 0)\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T07:59:20.091Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T07:59:20.191Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = (pred == Y_train) & (Y_train == 1)\nTN = (pred == Y_train) & (Y_train == 0)\nFP = (pred != Y_train) & (Y_train == 1)\nFN = (pred != Y_train) & (Y_train == 0)\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T08:00:08.730Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T08:00:08.875Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = ((pred == Y_train) & (Y_train == 1))\nTN = ((pred == Y_train) & (Y_train == 0))\nFP = ((pred != Y_train) & (Y_train == 1))\nFN = ((pred != Y_train) & (Y_train == 0))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T08:00:38.962Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T08:00:39.064Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = ((Y_train == 1) & (pred == Y_train))\nTN = ((pred == Y_train) & (Y_train == 0))\nFP = ((pred != Y_train) & (Y_train == 1))\nFN = ((pred != Y_train) & (Y_train == 0))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T08:02:07.772Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T08:02:07.907Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = ((pred == Y_train) & (Y_train == 1))\nTN = ((pred == Y_train) & (Y_train == 0))\nFP = ((pred != Y_train) & (Y_train == 1))\nFN = ((pred != Y_train) & (Y_train == 0))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T08:02:27.564Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T08:02:27.668Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 1))\nFN = np.sum((pred != Y_train) & (Y_train == 0))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T08:03:06.199Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T08:03:06.280Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "7c80b0683b0147e380cc04de6db29eb6",
    "idx": 54,
    "time": "2020-11-14T08:03:07.840Z",
    "type": "execution"
   },
   {
    "id": "7c80b0683b0147e380cc04de6db29eb6",
    "time": "2020-11-14T08:03:08.056Z",
    "type": "completion"
   },
   {
    "code": "logistic_predictor_precision,\nlogistic_predictor_recall,\nlogistic_predictor_far",
    "id": "3244aa6553274d5eb2037c7c5cc85b83",
    "idx": 54,
    "time": "2020-11-14T08:03:30.369Z",
    "type": "execution"
   },
   {
    "id": "3244aa6553274d5eb2037c7c5cc85b83",
    "time": "2020-11-14T08:03:30.489Z",
    "type": "completion"
   },
   {
    "code": "[logistic_predictor_precision,\nlogistic_predictor_recall,\nlogistic_predictor_far]",
    "id": "3244aa6553274d5eb2037c7c5cc85b83",
    "idx": 54,
    "time": "2020-11-14T08:03:38.595Z",
    "type": "execution"
   },
   {
    "id": "3244aa6553274d5eb2037c7c5cc85b83",
    "time": "2020-11-14T08:03:38.687Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T08:07:00.967Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T08:07:01.039Z",
    "type": "completion"
   },
   {
    "code": "[logistic_predictor_precision,\nlogistic_predictor_recall,\nlogistic_predictor_far]",
    "id": "3244aa6553274d5eb2037c7c5cc85b83",
    "idx": 54,
    "time": "2020-11-14T08:07:01.384Z",
    "type": "execution"
   },
   {
    "id": "3244aa6553274d5eb2037c7c5cc85b83",
    "time": "2020-11-14T08:07:01.460Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "7c80b0683b0147e380cc04de6db29eb6",
    "idx": 54,
    "time": "2020-11-14T08:07:38.376Z",
    "type": "execution"
   },
   {
    "id": "7c80b0683b0147e380cc04de6db29eb6",
    "time": "2020-11-14T08:07:38.502Z",
    "type": "completion"
   },
   {
    "code": "[FP,FN]",
    "id": "e11dfa9fa3b348a58e46f247e54cd222",
    "idx": 54,
    "time": "2020-11-14T08:10:11.092Z",
    "type": "execution"
   },
   {
    "id": "e11dfa9fa3b348a58e46f247e54cd222",
    "time": "2020-11-14T08:10:11.166Z",
    "type": "completion"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "idx": 53,
    "time": "2020-11-14T08:12:16.137Z",
    "type": "execution"
   },
   {
    "id": "c67c25c1340740c08f627aae3a7e65d4",
    "time": "2020-11-14T08:12:16.213Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "7c80b0683b0147e380cc04de6db29eb6",
    "idx": 54,
    "time": "2020-11-14T08:12:16.683Z",
    "type": "execution"
   },
   {
    "id": "7c80b0683b0147e380cc04de6db29eb6",
    "time": "2020-11-14T08:12:16.782Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "d248d60d3ac842c6ae267d88fc1a5dfb",
    "idx": 0,
    "time": "2020-11-14T17:37:33.847Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "43fde3d454a54a8b89cba3fe64de01e5",
    "idx": 5,
    "time": "2020-11-14T17:37:33.859Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "82ffa52fd51d4ff6820a5d918b95b56b",
    "idx": 8,
    "time": "2020-11-14T17:37:33.864Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "68cbe85f5adb401290d905b8a43bb50d",
    "idx": 10,
    "time": "2020-11-14T17:37:33.868Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "2ca761aa9268452388f78b9088f9a938",
    "idx": 12,
    "time": "2020-11-14T17:37:33.873Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "9e0f2a0e66294ad28ee410d0bf37770c",
    "idx": 13,
    "time": "2020-11-14T17:37:33.877Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "8637f914f5af45ba809e072f8e2f4fe1",
    "idx": 14,
    "time": "2020-11-14T17:37:33.881Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "560cbc41ae15448e8e749ca8469f6567",
    "idx": 15,
    "time": "2020-11-14T17:37:33.885Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "2020224170134ab087eb996f3696e997",
    "idx": 17,
    "time": "2020-11-14T17:37:33.889Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "c7ab95c18af34d6185530e93bde766a5",
    "idx": 18,
    "time": "2020-11-14T17:37:33.892Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "a7e11a73aa80487a87195efbc09d3fcd",
    "idx": 22,
    "time": "2020-11-14T17:37:33.898Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "d28a786f2a8a47beb598a5615f38c84e",
    "idx": 25,
    "time": "2020-11-14T17:37:33.902Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "b5f6d3225f1c4811ab8e69909a084f21",
    "idx": 26,
    "time": "2020-11-14T17:37:33.905Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "bff2a1b349fd4dc387f62726f732efcb",
    "idx": 29,
    "time": "2020-11-14T17:37:33.911Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"better\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"better\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "62693a4053c8492e89064036435e46a7",
    "idx": 31,
    "time": "2020-11-14T17:37:33.915Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "13dc59a95c4f45b08b80588a646b7fd2",
    "idx": 34,
    "time": "2020-11-14T17:37:33.919Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "8e9ac829f466499184acfe9960a869fa",
    "idx": 37,
    "time": "2020-11-14T17:37:33.923Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "d6f76d2bfb364e338d41460b69ff057f",
    "idx": 38,
    "time": "2020-11-14T17:37:33.927Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "128f3bc4cc444b8689d0057a0432b247",
    "idx": 40,
    "time": "2020-11-14T17:37:33.932Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "da42c660eed84e3b813f2b3a63d8ccd7",
    "idx": 41,
    "time": "2020-11-14T17:37:33.935Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "ea74754159bb46088898725ab6c64f68",
    "idx": 45,
    "time": "2020-11-14T17:37:33.939Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "fccd76510e9e4ee6b2a9402f5831d0cb",
    "idx": 46,
    "time": "2020-11-14T17:37:33.944Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "43d07e2d16ca451e8a817c51639b7427",
    "idx": 48,
    "time": "2020-11-14T17:37:33.949Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "f8e4a7507cd34985bf62b769591d6e1b",
    "idx": 49,
    "time": "2020-11-14T17:37:33.952Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "f77b0fcd81f3467ca4a1770e1562c5f4",
    "idx": 53,
    "time": "2020-11-14T17:37:33.955Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "8303fcb04b3342749372cccd0b0d92f2",
    "idx": 54,
    "time": "2020-11-14T17:37:33.958Z",
    "type": "execution"
   },
   {
    "id": "d248d60d3ac842c6ae267d88fc1a5dfb",
    "time": "2020-11-14T17:37:34.378Z",
    "type": "completion"
   },
   {
    "id": "43fde3d454a54a8b89cba3fe64de01e5",
    "time": "2020-11-14T17:37:34.406Z",
    "type": "completion"
   },
   {
    "id": "82ffa52fd51d4ff6820a5d918b95b56b",
    "time": "2020-11-14T17:37:35.296Z",
    "type": "completion"
   },
   {
    "id": "68cbe85f5adb401290d905b8a43bb50d",
    "time": "2020-11-14T17:37:35.987Z",
    "type": "completion"
   },
   {
    "id": "2ca761aa9268452388f78b9088f9a938",
    "time": "2020-11-14T17:37:35.999Z",
    "type": "completion"
   },
   {
    "id": "9e0f2a0e66294ad28ee410d0bf37770c",
    "time": "2020-11-14T17:37:36.043Z",
    "type": "completion"
   },
   {
    "id": "8637f914f5af45ba809e072f8e2f4fe1",
    "time": "2020-11-14T17:37:36.048Z",
    "type": "completion"
   },
   {
    "id": "560cbc41ae15448e8e749ca8469f6567",
    "time": "2020-11-14T17:37:36.056Z",
    "type": "completion"
   },
   {
    "id": "2020224170134ab087eb996f3696e997",
    "time": "2020-11-14T17:37:36.088Z",
    "type": "completion"
   },
   {
    "id": "c7ab95c18af34d6185530e93bde766a5",
    "time": "2020-11-14T17:37:36.098Z",
    "type": "completion"
   },
   {
    "id": "a7e11a73aa80487a87195efbc09d3fcd",
    "time": "2020-11-14T17:37:36.166Z",
    "type": "completion"
   },
   {
    "id": "d28a786f2a8a47beb598a5615f38c84e",
    "time": "2020-11-14T17:37:36.167Z",
    "type": "completion"
   },
   {
    "id": "b5f6d3225f1c4811ab8e69909a084f21",
    "time": "2020-11-14T17:37:36.174Z",
    "type": "completion"
   },
   {
    "id": "bff2a1b349fd4dc387f62726f732efcb",
    "time": "2020-11-14T17:37:36.300Z",
    "type": "completion"
   },
   {
    "id": "62693a4053c8492e89064036435e46a7",
    "time": "2020-11-14T17:37:36.657Z",
    "type": "completion"
   },
   {
    "id": "13dc59a95c4f45b08b80588a646b7fd2",
    "time": "2020-11-14T17:37:37.183Z",
    "type": "completion"
   },
   {
    "id": "8e9ac829f466499184acfe9960a869fa",
    "time": "2020-11-14T17:37:37.331Z",
    "type": "completion"
   },
   {
    "id": "d6f76d2bfb364e338d41460b69ff057f",
    "time": "2020-11-14T17:37:37.344Z",
    "type": "completion"
   },
   {
    "id": "128f3bc4cc444b8689d0057a0432b247",
    "time": "2020-11-14T17:37:37.438Z",
    "type": "completion"
   },
   {
    "id": "da42c660eed84e3b813f2b3a63d8ccd7",
    "time": "2020-11-14T17:37:37.451Z",
    "type": "completion"
   },
   {
    "id": "ea74754159bb46088898725ab6c64f68",
    "time": "2020-11-14T17:37:37.456Z",
    "type": "completion"
   },
   {
    "id": "fccd76510e9e4ee6b2a9402f5831d0cb",
    "time": "2020-11-14T17:37:37.529Z",
    "type": "completion"
   },
   {
    "id": "43d07e2d16ca451e8a817c51639b7427",
    "time": "2020-11-14T17:37:37.537Z",
    "type": "completion"
   },
   {
    "id": "f8e4a7507cd34985bf62b769591d6e1b",
    "time": "2020-11-14T17:37:37.545Z",
    "type": "completion"
   },
   {
    "id": "f77b0fcd81f3467ca4a1770e1562c5f4",
    "time": "2020-11-14T17:37:37.547Z",
    "type": "completion"
   },
   {
    "id": "8303fcb04b3342749372cccd0b0d92f2",
    "time": "2020-11-14T17:37:37.590Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"list\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"list\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "62693a4053c8492e89064036435e46a7",
    "idx": 31,
    "time": "2020-11-14T18:02:36.355Z",
    "type": "execution"
   },
   {
    "id": "62693a4053c8492e89064036435e46a7",
    "time": "2020-11-14T18:02:36.940Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"prize\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"prize\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "62693a4053c8492e89064036435e46a7",
    "idx": 31,
    "time": "2020-11-14T18:03:11.643Z",
    "type": "execution"
   },
   {
    "id": "62693a4053c8492e89064036435e46a7",
    "time": "2020-11-14T18:03:12.206Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"happy\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "62693a4053c8492e89064036435e46a7",
    "idx": 31,
    "time": "2020-11-14T18:03:35.560Z",
    "type": "execution"
   },
   {
    "id": "62693a4053c8492e89064036435e46a7",
    "time": "2020-11-14T18:03:36.159Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"chance\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"happy\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "62693a4053c8492e89064036435e46a7",
    "idx": 31,
    "time": "2020-11-14T18:04:37.990Z",
    "type": "execution"
   },
   {
    "id": "62693a4053c8492e89064036435e46a7",
    "time": "2020-11-14T18:04:38.580Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"chance\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"chance\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "62693a4053c8492e89064036435e46a7",
    "idx": 31,
    "time": "2020-11-14T18:04:48.054Z",
    "type": "execution"
   },
   {
    "id": "62693a4053c8492e89064036435e46a7",
    "time": "2020-11-14T18:04:48.679Z",
    "type": "completion"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "62693a4053c8492e89064036435e46a7",
    "idx": 31,
    "time": "2020-11-14T18:05:11.903Z",
    "type": "execution"
   },
   {
    "id": "62693a4053c8492e89064036435e46a7",
    "time": "2020-11-14T18:05:12.468Z",
    "type": "completion"
   },
   {
    "code": "train[\"email\"]",
    "id": "cb043a337b0441c0a2b42a1a6d56236e",
    "idx": 61,
    "time": "2020-11-14T18:16:55.047Z",
    "type": "execution"
   },
   {
    "id": "cb043a337b0441c0a2b42a1a6d56236e",
    "time": "2020-11-14T18:16:55.224Z",
    "type": "completion"
   },
   {
    "code": "train[train[\"spam\"] == 1][\"email\"]",
    "id": "cb043a337b0441c0a2b42a1a6d56236e",
    "idx": 61,
    "time": "2020-11-14T18:17:31.503Z",
    "type": "execution"
   },
   {
    "id": "cb043a337b0441c0a2b42a1a6d56236e",
    "time": "2020-11-14T18:17:31.593Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\nspam_email",
    "id": "cb043a337b0441c0a2b42a1a6d56236e",
    "idx": 61,
    "time": "2020-11-14T18:25:12.247Z",
    "type": "execution"
   },
   {
    "id": "cb043a337b0441c0a2b42a1a6d56236e",
    "time": "2020-11-14T18:25:12.391Z",
    "type": "completion"
   },
   {
    "code": "punct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\nspam_email",
    "id": "7ac903dc2a814ef3bdb8abebc8490058",
    "idx": 62,
    "time": "2020-11-14T18:25:39.474Z",
    "type": "execution"
   },
   {
    "id": "7ac903dc2a814ef3bdb8abebc8490058",
    "time": "2020-11-14T18:25:40.001Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format",
    "id": "c324be68bf4143ba80640adf14250212",
    "idx": 63,
    "time": "2020-11-14T18:30:46.678Z",
    "type": "execution"
   },
   {
    "id": "c324be68bf4143ba80640adf14250212",
    "time": "2020-11-14T18:30:57.271Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.head(20)",
    "id": "c324be68bf4143ba80640adf14250212",
    "idx": 63,
    "time": "2020-11-14T18:31:15.073Z",
    "type": "execution"
   },
   {
    "id": "c324be68bf4143ba80640adf14250212",
    "time": "2020-11-14T18:31:24.791Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.tail(20)",
    "id": "c324be68bf4143ba80640adf14250212",
    "idx": 63,
    "time": "2020-11-14T18:31:33.945Z",
    "type": "execution"
   },
   {
    "id": "c324be68bf4143ba80640adf14250212",
    "time": "2020-11-14T18:31:42.658Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.tail(40)",
    "id": "c324be68bf4143ba80640adf14250212",
    "idx": 63,
    "time": "2020-11-14T18:34:43.288Z",
    "type": "execution"
   },
   {
    "id": "c324be68bf4143ba80640adf14250212",
    "time": "2020-11-14T18:34:52.499Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.tail(50)",
    "id": "c324be68bf4143ba80640adf14250212",
    "idx": 63,
    "time": "2020-11-14T18:36:50.347Z",
    "type": "execution"
   },
   {
    "id": "c324be68bf4143ba80640adf14250212",
    "time": "2020-11-14T18:36:59.294Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.tail(70)",
    "id": "c324be68bf4143ba80640adf14250212",
    "idx": 63,
    "time": "2020-11-14T18:37:38.620Z",
    "type": "execution"
   },
   {
    "id": "c324be68bf4143ba80640adf14250212",
    "time": "2020-11-14T18:37:47.200Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.tail(100).display()",
    "id": "c324be68bf4143ba80640adf14250212",
    "idx": 63,
    "time": "2020-11-14T18:38:45.768Z",
    "type": "execution"
   },
   {
    "id": "c324be68bf4143ba80640adf14250212",
    "time": "2020-11-14T18:38:54.476Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ndisplay(tidy_format.tail(100))",
    "id": "c324be68bf4143ba80640adf14250212",
    "idx": 63,
    "time": "2020-11-14T18:39:04.747Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "b9c7adf226834f2db2f0966fa81d21c5",
    "idx": 0,
    "time": "2020-11-14T18:40:50.862Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "6f1f55d3225a48cc861f0b3ac579d0c1",
    "idx": 5,
    "time": "2020-11-14T18:40:50.873Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "eff139fa9f7a4a3993e063f6b6c5084a",
    "idx": 8,
    "time": "2020-11-14T18:40:50.880Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "f8c6d8ba4d93494c8f754a7cc8d92bab",
    "idx": 10,
    "time": "2020-11-14T18:40:50.886Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "efd8c6d8113547dfa335c8798590b80f",
    "idx": 12,
    "time": "2020-11-14T18:40:50.889Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "179732439c2449078846f5236df85aa5",
    "idx": 13,
    "time": "2020-11-14T18:40:50.892Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "ad93490afa5143acb2b6e8fb346091f3",
    "idx": 14,
    "time": "2020-11-14T18:40:50.896Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "eaeef4e6eb534f148828282485643167",
    "idx": 15,
    "time": "2020-11-14T18:40:50.900Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "33940663ef1e4e51834e59e76a1f324a",
    "idx": 17,
    "time": "2020-11-14T18:40:50.904Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "84ad298417614e3382e6a8b145ec3642",
    "idx": 18,
    "time": "2020-11-14T18:40:50.908Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "6b2b00ea739747889ffd7ec98384a80c",
    "idx": 22,
    "time": "2020-11-14T18:40:50.913Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "0793f3f6c6914b2e82128313132fe972",
    "idx": 25,
    "time": "2020-11-14T18:40:50.917Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "b5d2fce9fd1f48548ef60cb33f018fd8",
    "idx": 26,
    "time": "2020-11-14T18:40:50.922Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "f2784ddfb13748a88ef26e9830e4f7ce",
    "idx": 29,
    "time": "2020-11-14T18:40:50.928Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "e2ddedf4c10143cd883991ba199270ce",
    "idx": 31,
    "time": "2020-11-14T18:40:50.932Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "17bf956a3612450b848d66126cebe373",
    "idx": 34,
    "time": "2020-11-14T18:40:50.937Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "a8ee028085dd47888ffabdda77089fde",
    "idx": 37,
    "time": "2020-11-14T18:40:50.944Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "35b758228cbe4fda80ab63718c865881",
    "idx": 38,
    "time": "2020-11-14T18:40:50.947Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "6104f192bc66459bb55f484136db6bc0",
    "idx": 40,
    "time": "2020-11-14T18:40:50.950Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "9887f60fd1c6485d92c99722046482ed",
    "idx": 41,
    "time": "2020-11-14T18:40:50.954Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "ea6992288868470b801732fe09f37fdb",
    "idx": 45,
    "time": "2020-11-14T18:40:50.959Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "414103e3b8a74be9939a1588a5d6ce67",
    "idx": 46,
    "time": "2020-11-14T18:40:50.962Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "f4d5f163ead649c889ccb15ceca378c1",
    "idx": 48,
    "time": "2020-11-14T18:40:50.967Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "23414c47a5ba451a8e35981010243601",
    "idx": 49,
    "time": "2020-11-14T18:40:50.970Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "97d3db2c7ceb481882e86baf598ba7ed",
    "idx": 53,
    "time": "2020-11-14T18:40:50.977Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "c4c2b903a07f4eae8882bad65c5974e9",
    "idx": 54,
    "time": "2020-11-14T18:40:50.981Z",
    "type": "execution"
   },
   {
    "id": "b9c7adf226834f2db2f0966fa81d21c5",
    "time": "2020-11-14T18:40:51.458Z",
    "type": "completion"
   },
   {
    "id": "6f1f55d3225a48cc861f0b3ac579d0c1",
    "time": "2020-11-14T18:40:51.476Z",
    "type": "completion"
   },
   {
    "id": "eff139fa9f7a4a3993e063f6b6c5084a",
    "time": "2020-11-14T18:40:52.101Z",
    "type": "completion"
   },
   {
    "id": "f8c6d8ba4d93494c8f754a7cc8d92bab",
    "time": "2020-11-14T18:40:52.680Z",
    "type": "completion"
   },
   {
    "id": "efd8c6d8113547dfa335c8798590b80f",
    "time": "2020-11-14T18:40:52.736Z",
    "type": "completion"
   },
   {
    "id": "179732439c2449078846f5236df85aa5",
    "time": "2020-11-14T18:40:52.799Z",
    "type": "completion"
   },
   {
    "id": "ad93490afa5143acb2b6e8fb346091f3",
    "time": "2020-11-14T18:40:52.843Z",
    "type": "completion"
   },
   {
    "id": "eaeef4e6eb534f148828282485643167",
    "time": "2020-11-14T18:40:52.854Z",
    "type": "completion"
   },
   {
    "id": "33940663ef1e4e51834e59e76a1f324a",
    "time": "2020-11-14T18:40:52.863Z",
    "type": "completion"
   },
   {
    "id": "84ad298417614e3382e6a8b145ec3642",
    "time": "2020-11-14T18:40:52.867Z",
    "type": "completion"
   },
   {
    "id": "6b2b00ea739747889ffd7ec98384a80c",
    "time": "2020-11-14T18:40:52.938Z",
    "type": "completion"
   },
   {
    "id": "0793f3f6c6914b2e82128313132fe972",
    "time": "2020-11-14T18:40:52.947Z",
    "type": "completion"
   },
   {
    "id": "b5d2fce9fd1f48548ef60cb33f018fd8",
    "time": "2020-11-14T18:40:53.052Z",
    "type": "completion"
   },
   {
    "id": "f2784ddfb13748a88ef26e9830e4f7ce",
    "time": "2020-11-14T18:40:53.109Z",
    "type": "completion"
   },
   {
    "id": "e2ddedf4c10143cd883991ba199270ce",
    "time": "2020-11-14T18:40:53.349Z",
    "type": "completion"
   },
   {
    "id": "17bf956a3612450b848d66126cebe373",
    "time": "2020-11-14T18:40:54.017Z",
    "type": "completion"
   },
   {
    "id": "a8ee028085dd47888ffabdda77089fde",
    "time": "2020-11-14T18:40:54.201Z",
    "type": "completion"
   },
   {
    "id": "35b758228cbe4fda80ab63718c865881",
    "time": "2020-11-14T18:40:54.214Z",
    "type": "completion"
   },
   {
    "id": "6104f192bc66459bb55f484136db6bc0",
    "time": "2020-11-14T18:40:54.264Z",
    "type": "completion"
   },
   {
    "id": "9887f60fd1c6485d92c99722046482ed",
    "time": "2020-11-14T18:40:54.331Z",
    "type": "completion"
   },
   {
    "id": "ea6992288868470b801732fe09f37fdb",
    "time": "2020-11-14T18:40:54.382Z",
    "type": "completion"
   },
   {
    "id": "414103e3b8a74be9939a1588a5d6ce67",
    "time": "2020-11-14T18:40:54.389Z",
    "type": "completion"
   },
   {
    "id": "f4d5f163ead649c889ccb15ceca378c1",
    "time": "2020-11-14T18:40:54.396Z",
    "type": "completion"
   },
   {
    "id": "23414c47a5ba451a8e35981010243601",
    "time": "2020-11-14T18:40:54.405Z",
    "type": "completion"
   },
   {
    "id": "97d3db2c7ceb481882e86baf598ba7ed",
    "time": "2020-11-14T18:40:54.414Z",
    "type": "completion"
   },
   {
    "id": "c4c2b903a07f4eae8882bad65c5974e9",
    "time": "2020-11-14T18:40:54.468Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\nspam_email",
    "id": "b710f57e82b9450dbced9c4c0b01776d",
    "idx": 61,
    "time": "2020-11-14T18:40:59.703Z",
    "type": "execution"
   },
   {
    "id": "b710f57e82b9450dbced9c4c0b01776d",
    "time": "2020-11-14T18:40:59.775Z",
    "type": "completion"
   },
   {
    "code": "punct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\nspam_email",
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "idx": 62,
    "time": "2020-11-14T18:41:01.629Z",
    "type": "execution"
   },
   {
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "time": "2020-11-14T18:41:02.149Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ndisplay(tidy_format.tail(100))",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:41:04.365Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:41:12.845Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False)\ntidy_format",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:43:19.915Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:43:28.952Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:44:11.660Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:44:20.179Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(20)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:44:39.432Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:44:48.018Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(40)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:48:41.438Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:48:50.334Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(50)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:53:37.299Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:53:46.182Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(60)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:56:32.785Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:56:43.770Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(70)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:56:57.391Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:57:06.667Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(60)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:57:21.219Z",
    "type": "execution"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(60)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:57:41.219Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:57:41.352Z",
    "type": "completion"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:57:41.352Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "b9c7adf226834f2db2f0966fa81d21c5",
    "idx": 0,
    "time": "2020-11-14T18:57:50.749Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "6f1f55d3225a48cc861f0b3ac579d0c1",
    "idx": 5,
    "time": "2020-11-14T18:57:50.754Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "eff139fa9f7a4a3993e063f6b6c5084a",
    "idx": 8,
    "time": "2020-11-14T18:57:50.757Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "f8c6d8ba4d93494c8f754a7cc8d92bab",
    "idx": 10,
    "time": "2020-11-14T18:57:50.760Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "efd8c6d8113547dfa335c8798590b80f",
    "idx": 12,
    "time": "2020-11-14T18:57:50.764Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "179732439c2449078846f5236df85aa5",
    "idx": 13,
    "time": "2020-11-14T18:57:50.767Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "ad93490afa5143acb2b6e8fb346091f3",
    "idx": 14,
    "time": "2020-11-14T18:57:50.770Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "eaeef4e6eb534f148828282485643167",
    "idx": 15,
    "time": "2020-11-14T18:57:50.773Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "33940663ef1e4e51834e59e76a1f324a",
    "idx": 17,
    "time": "2020-11-14T18:57:50.777Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "84ad298417614e3382e6a8b145ec3642",
    "idx": 18,
    "time": "2020-11-14T18:57:50.779Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "6b2b00ea739747889ffd7ec98384a80c",
    "idx": 22,
    "time": "2020-11-14T18:57:50.782Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "0793f3f6c6914b2e82128313132fe972",
    "idx": 25,
    "time": "2020-11-14T18:57:50.787Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "b5d2fce9fd1f48548ef60cb33f018fd8",
    "idx": 26,
    "time": "2020-11-14T18:57:50.790Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "f2784ddfb13748a88ef26e9830e4f7ce",
    "idx": 29,
    "time": "2020-11-14T18:57:50.794Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "e2ddedf4c10143cd883991ba199270ce",
    "idx": 31,
    "time": "2020-11-14T18:57:50.797Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "17bf956a3612450b848d66126cebe373",
    "idx": 34,
    "time": "2020-11-14T18:57:50.802Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "a8ee028085dd47888ffabdda77089fde",
    "idx": 37,
    "time": "2020-11-14T18:57:50.806Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "35b758228cbe4fda80ab63718c865881",
    "idx": 38,
    "time": "2020-11-14T18:57:50.809Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "6104f192bc66459bb55f484136db6bc0",
    "idx": 40,
    "time": "2020-11-14T18:57:50.811Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "9887f60fd1c6485d92c99722046482ed",
    "idx": 41,
    "time": "2020-11-14T18:57:50.814Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "ea6992288868470b801732fe09f37fdb",
    "idx": 45,
    "time": "2020-11-14T18:57:50.818Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "414103e3b8a74be9939a1588a5d6ce67",
    "idx": 46,
    "time": "2020-11-14T18:57:50.820Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "f4d5f163ead649c889ccb15ceca378c1",
    "idx": 48,
    "time": "2020-11-14T18:57:50.824Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "23414c47a5ba451a8e35981010243601",
    "idx": 49,
    "time": "2020-11-14T18:57:50.827Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "97d3db2c7ceb481882e86baf598ba7ed",
    "idx": 53,
    "time": "2020-11-14T18:57:50.831Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "c4c2b903a07f4eae8882bad65c5974e9",
    "idx": 54,
    "time": "2020-11-14T18:57:50.834Z",
    "type": "execution"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\nspam_email",
    "id": "b710f57e82b9450dbced9c4c0b01776d",
    "idx": 61,
    "time": "2020-11-14T18:57:50.839Z",
    "type": "execution"
   },
   {
    "code": "punct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\nspam_email",
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "idx": 62,
    "time": "2020-11-14T18:57:50.841Z",
    "type": "execution"
   },
   {
    "id": "b9c7adf226834f2db2f0966fa81d21c5",
    "time": "2020-11-14T18:57:51.309Z",
    "type": "completion"
   },
   {
    "id": "6f1f55d3225a48cc861f0b3ac579d0c1",
    "time": "2020-11-14T18:57:51.319Z",
    "type": "completion"
   },
   {
    "id": "eff139fa9f7a4a3993e063f6b6c5084a",
    "time": "2020-11-14T18:57:52.093Z",
    "type": "completion"
   },
   {
    "id": "f8c6d8ba4d93494c8f754a7cc8d92bab",
    "time": "2020-11-14T18:57:52.556Z",
    "type": "completion"
   },
   {
    "id": "efd8c6d8113547dfa335c8798590b80f",
    "time": "2020-11-14T18:57:52.562Z",
    "type": "completion"
   },
   {
    "id": "179732439c2449078846f5236df85aa5",
    "time": "2020-11-14T18:57:52.606Z",
    "type": "completion"
   },
   {
    "id": "ad93490afa5143acb2b6e8fb346091f3",
    "time": "2020-11-14T18:57:52.632Z",
    "type": "completion"
   },
   {
    "id": "eaeef4e6eb534f148828282485643167",
    "time": "2020-11-14T18:57:52.636Z",
    "type": "completion"
   },
   {
    "id": "33940663ef1e4e51834e59e76a1f324a",
    "time": "2020-11-14T18:57:52.686Z",
    "type": "completion"
   },
   {
    "id": "84ad298417614e3382e6a8b145ec3642",
    "time": "2020-11-14T18:57:52.691Z",
    "type": "completion"
   },
   {
    "id": "6b2b00ea739747889ffd7ec98384a80c",
    "time": "2020-11-14T18:57:52.737Z",
    "type": "completion"
   },
   {
    "id": "0793f3f6c6914b2e82128313132fe972",
    "time": "2020-11-14T18:57:52.739Z",
    "type": "completion"
   },
   {
    "id": "b5d2fce9fd1f48548ef60cb33f018fd8",
    "time": "2020-11-14T18:57:52.742Z",
    "type": "completion"
   },
   {
    "id": "f2784ddfb13748a88ef26e9830e4f7ce",
    "time": "2020-11-14T18:57:52.800Z",
    "type": "completion"
   },
   {
    "id": "e2ddedf4c10143cd883991ba199270ce",
    "time": "2020-11-14T18:57:53.271Z",
    "type": "completion"
   },
   {
    "id": "17bf956a3612450b848d66126cebe373",
    "time": "2020-11-14T18:57:53.813Z",
    "type": "completion"
   },
   {
    "id": "a8ee028085dd47888ffabdda77089fde",
    "time": "2020-11-14T18:57:53.948Z",
    "type": "completion"
   },
   {
    "id": "35b758228cbe4fda80ab63718c865881",
    "time": "2020-11-14T18:57:54.018Z",
    "type": "completion"
   },
   {
    "id": "6104f192bc66459bb55f484136db6bc0",
    "time": "2020-11-14T18:57:54.034Z",
    "type": "completion"
   },
   {
    "id": "9887f60fd1c6485d92c99722046482ed",
    "time": "2020-11-14T18:57:54.103Z",
    "type": "completion"
   },
   {
    "id": "ea6992288868470b801732fe09f37fdb",
    "time": "2020-11-14T18:57:54.119Z",
    "type": "completion"
   },
   {
    "id": "414103e3b8a74be9939a1588a5d6ce67",
    "time": "2020-11-14T18:57:54.154Z",
    "type": "completion"
   },
   {
    "id": "f4d5f163ead649c889ccb15ceca378c1",
    "time": "2020-11-14T18:57:54.161Z",
    "type": "completion"
   },
   {
    "id": "23414c47a5ba451a8e35981010243601",
    "time": "2020-11-14T18:57:54.168Z",
    "type": "completion"
   },
   {
    "id": "97d3db2c7ceb481882e86baf598ba7ed",
    "time": "2020-11-14T18:57:54.172Z",
    "type": "completion"
   },
   {
    "id": "c4c2b903a07f4eae8882bad65c5974e9",
    "time": "2020-11-14T18:57:54.177Z",
    "type": "completion"
   },
   {
    "id": "b710f57e82b9450dbced9c4c0b01776d",
    "time": "2020-11-14T18:57:54.207Z",
    "type": "completion"
   },
   {
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "time": "2020-11-14T18:57:54.711Z",
    "type": "completion"
   },
   {
    "code": "tidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(60)",
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "idx": 63,
    "time": "2020-11-14T18:57:57.707Z",
    "type": "execution"
   },
   {
    "id": "a7a2b8943e95499e8d78fa9e36e91772",
    "time": "2020-11-14T18:58:06.270Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(60)",
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "idx": 61,
    "time": "2020-11-14T19:35:40.096Z",
    "type": "execution"
   },
   {
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "time": "2020-11-14T19:35:49.997Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['sightings', 'spamassassin', 'listinfo', 'lists', 'net','deathtospamdeathtospamdeathtospam',\n         'sourceforge', 'xim', 'osdn', 'jabber', 'eleemosynary', 'enenkio']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:41:57.286Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:41:57.785Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['sightings', 'spamassassin', 'listinfo', 'lists', 'net','deathtospamdeathtospamdeathtospam',\n         'sourceforge', 'xim', 'osdn', 'jabber', 'eleemosynary', 'enenkio', \n         'message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001','reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:42:48.599Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:42:49.518Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['sightings', 'spamassassin', 'listinfo', 'lists', 'net','deathtospamdeathtospamdeathtospam',\n         'sourceforge', 'xim', 'osdn', 'jabber', 'eleemosynary', 'enenkio', \n         'message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001','reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:43:13.942Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:43:14.927Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['sightings', 'spamassassin', 'listinfo', 'lists', 'net','deathtospamdeathtospamdeathtospam',\n         'sourceforge', 'xim', 'osdn', 'jabber', 'eleemosynary', 'enenkio', \n         'message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001','reply',  'real', 'growing', 'fastest', 'org', 'trust',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:44:16.257Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:44:17.417Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['sightings', 'spamassassin', 'listinfo', 'lists', 'net','deathtospamdeathtospamdeathtospam',\n         'sourceforge', 'xim', 'osdn', 'jabber', 'eleemosynary', 'enenkio', \n         'message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001','reply',  'real', 'growing', 'fastest', 'org', 'trust',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'https', \n           'communications', 'draft', 'new', 'check', 'information', \n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\"]\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:45:11.010Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:45:12.215Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'growing', 'fastest', 'org', 'trust',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber', 'eleemosynary', 'enenkio']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:45:57.773Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:45:59.659Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'fastest', 'org', 'trust',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber', 'eleemosynary', 'enenkio']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:46:22.708Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:46:24.087Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber', 'eleemosynary', 'enenkio']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:46:34.082Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:46:35.414Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust',\n            'click', 'office', 'web','expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber', 'eleemosynary', 'enenkio']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:46:43.813Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:46:45.105Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber', 'eleemosynary', 'enenkio']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:46:52.758Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:46:54.074Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'org', 'trust', 'eleemosynary', 'enenkio',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:47:38.023Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:47:39.384Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:48:01.840Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:48:03.231Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'remios',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:48:18.775Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:48:20.157Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:48:27.242Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:48:28.619Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'majuro',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:49:19.241Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:49:20.684Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'marshall',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:49:35.498Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:49:36.918Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'islands',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:50:02.338Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:50:03.798Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:50:39.244Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:50:40.759Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'sponsored'\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:51:48.005Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:51:49.437Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'sponsored',\n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:51:58.588Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:52:01.201Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:52:08.358Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:52:09.787Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'jabber',\n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:52:36.773Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:52:38.287Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', \n         \"body\",\"business\",\"html\",\"money\",\"offer\",\"please\",'jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\n# Y_hat = model2.predict_proba(X_train2)\n# Y_hat\n\n# FPR, TPR, bound = roc_curve(Y_train, Y_hat[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:52:45.631Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:52:46.998Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', \n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\naccuracy2\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:54:21.564Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:54:23.268Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', \n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:54:34.531Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:54:36.874Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(70)",
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "idx": 61,
    "time": "2020-11-14T19:55:54.496Z",
    "type": "execution"
   },
   {
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "time": "2020-11-14T19:56:04.680Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:56:19.404Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:56:21.323Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'foreign',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:56:43.630Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:56:45.702Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:56:52.263Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:56:54.010Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(80)\n",
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "idx": 61,
    "time": "2020-11-14T19:58:11.435Z",
    "type": "execution"
   },
   {
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "time": "2020-11-14T19:58:21.781Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', 'page',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:58:37.052Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:58:38.916Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T19:58:49.224Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T19:58:50.973Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:01:10.610Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:01:12.368Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'top',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:01:40.564Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:01:42.279Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:01:49.373Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:01:51.181Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(90)\n",
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "idx": 61,
    "time": "2020-11-14T20:02:05.421Z",
    "type": "execution"
   },
   {
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "time": "2020-11-14T20:02:14.594Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:02:33.618Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:02:35.408Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(100)\n",
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "idx": 61,
    "time": "2020-11-14T20:02:52.429Z",
    "type": "execution"
   },
   {
    "id": "e2fb411f0ba54219b08a1a3567a38044",
    "time": "2020-11-14T20:03:01.476Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'descendants',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:03:16.652Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:03:18.458Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'marshallese',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:03:39.204Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:03:41.012Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:04:58.824Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:05:00.894Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:05:08.103Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:05:09.874Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n            'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:05:20.748Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:05:22.561Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information', 'marshallese',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:09:41.844Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:09:43.649Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:09:51.205Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:09:53.720Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(100)",
    "id": "24a22adc859e413394b3411fd1379b09",
    "idx": 65,
    "time": "2020-11-14T20:11:36.321Z",
    "type": "execution"
   },
   {
    "id": "24a22adc859e413394b3411fd1379b09",
    "time": "2020-11-14T20:11:45.970Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(95)",
    "id": "24a22adc859e413394b3411fd1379b09",
    "idx": 64,
    "time": "2020-11-14T20:12:35.189Z",
    "type": "execution"
   },
   {
    "id": "24a22adc859e413394b3411fd1379b09",
    "time": "2020-11-14T20:12:44.641Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(85)",
    "id": "24a22adc859e413394b3411fd1379b09",
    "idx": 64,
    "time": "2020-11-14T20:12:54.119Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "b9c7adf226834f2db2f0966fa81d21c5",
    "idx": 0,
    "time": "2020-11-14T20:13:10.108Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "6f1f55d3225a48cc861f0b3ac579d0c1",
    "idx": 5,
    "time": "2020-11-14T20:13:10.112Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "eff139fa9f7a4a3993e063f6b6c5084a",
    "idx": 8,
    "time": "2020-11-14T20:13:10.117Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "f8c6d8ba4d93494c8f754a7cc8d92bab",
    "idx": 10,
    "time": "2020-11-14T20:13:10.121Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "efd8c6d8113547dfa335c8798590b80f",
    "idx": 12,
    "time": "2020-11-14T20:13:10.123Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "179732439c2449078846f5236df85aa5",
    "idx": 13,
    "time": "2020-11-14T20:13:10.126Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "ad93490afa5143acb2b6e8fb346091f3",
    "idx": 14,
    "time": "2020-11-14T20:13:10.129Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "eaeef4e6eb534f148828282485643167",
    "idx": 15,
    "time": "2020-11-14T20:13:10.132Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "33940663ef1e4e51834e59e76a1f324a",
    "idx": 17,
    "time": "2020-11-14T20:13:10.135Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "84ad298417614e3382e6a8b145ec3642",
    "idx": 18,
    "time": "2020-11-14T20:13:10.139Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "6b2b00ea739747889ffd7ec98384a80c",
    "idx": 22,
    "time": "2020-11-14T20:13:10.143Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "0793f3f6c6914b2e82128313132fe972",
    "idx": 25,
    "time": "2020-11-14T20:13:10.145Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "b5d2fce9fd1f48548ef60cb33f018fd8",
    "idx": 26,
    "time": "2020-11-14T20:13:10.149Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "f2784ddfb13748a88ef26e9830e4f7ce",
    "idx": 29,
    "time": "2020-11-14T20:13:10.153Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "e2ddedf4c10143cd883991ba199270ce",
    "idx": 31,
    "time": "2020-11-14T20:13:10.155Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "17bf956a3612450b848d66126cebe373",
    "idx": 34,
    "time": "2020-11-14T20:13:10.159Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "a8ee028085dd47888ffabdda77089fde",
    "idx": 37,
    "time": "2020-11-14T20:13:10.162Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "35b758228cbe4fda80ab63718c865881",
    "idx": 38,
    "time": "2020-11-14T20:13:10.165Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "6104f192bc66459bb55f484136db6bc0",
    "idx": 40,
    "time": "2020-11-14T20:13:10.168Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "9887f60fd1c6485d92c99722046482ed",
    "idx": 41,
    "time": "2020-11-14T20:13:10.170Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "ea6992288868470b801732fe09f37fdb",
    "idx": 45,
    "time": "2020-11-14T20:13:10.174Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "414103e3b8a74be9939a1588a5d6ce67",
    "idx": 46,
    "time": "2020-11-14T20:13:10.177Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "f4d5f163ead649c889ccb15ceca378c1",
    "idx": 48,
    "time": "2020-11-14T20:13:10.180Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "23414c47a5ba451a8e35981010243601",
    "idx": 49,
    "time": "2020-11-14T20:13:10.183Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "97d3db2c7ceb481882e86baf598ba7ed",
    "idx": 53,
    "time": "2020-11-14T20:13:10.187Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "c4c2b903a07f4eae8882bad65c5974e9",
    "idx": 54,
    "time": "2020-11-14T20:13:10.189Z",
    "type": "execution"
   },
   {
    "id": "b9c7adf226834f2db2f0966fa81d21c5",
    "time": "2020-11-14T20:13:10.755Z",
    "type": "completion"
   },
   {
    "id": "6f1f55d3225a48cc861f0b3ac579d0c1",
    "time": "2020-11-14T20:13:10.759Z",
    "type": "completion"
   },
   {
    "id": "eff139fa9f7a4a3993e063f6b6c5084a",
    "time": "2020-11-14T20:13:11.566Z",
    "type": "completion"
   },
   {
    "id": "f8c6d8ba4d93494c8f754a7cc8d92bab",
    "time": "2020-11-14T20:13:12.106Z",
    "type": "completion"
   },
   {
    "id": "efd8c6d8113547dfa335c8798590b80f",
    "time": "2020-11-14T20:13:12.145Z",
    "type": "completion"
   },
   {
    "id": "179732439c2449078846f5236df85aa5",
    "time": "2020-11-14T20:13:12.298Z",
    "type": "completion"
   },
   {
    "id": "ad93490afa5143acb2b6e8fb346091f3",
    "time": "2020-11-14T20:13:12.311Z",
    "type": "completion"
   },
   {
    "id": "eaeef4e6eb534f148828282485643167",
    "time": "2020-11-14T20:13:12.316Z",
    "type": "completion"
   },
   {
    "id": "33940663ef1e4e51834e59e76a1f324a",
    "time": "2020-11-14T20:13:12.319Z",
    "type": "completion"
   },
   {
    "id": "84ad298417614e3382e6a8b145ec3642",
    "time": "2020-11-14T20:13:12.322Z",
    "type": "completion"
   },
   {
    "id": "6b2b00ea739747889ffd7ec98384a80c",
    "time": "2020-11-14T20:13:12.324Z",
    "type": "completion"
   },
   {
    "id": "0793f3f6c6914b2e82128313132fe972",
    "time": "2020-11-14T20:13:12.325Z",
    "type": "completion"
   },
   {
    "id": "b5d2fce9fd1f48548ef60cb33f018fd8",
    "time": "2020-11-14T20:13:12.370Z",
    "type": "completion"
   },
   {
    "id": "f2784ddfb13748a88ef26e9830e4f7ce",
    "time": "2020-11-14T20:13:12.381Z",
    "type": "completion"
   },
   {
    "id": "e2ddedf4c10143cd883991ba199270ce",
    "time": "2020-11-14T20:13:12.865Z",
    "type": "completion"
   },
   {
    "id": "17bf956a3612450b848d66126cebe373",
    "time": "2020-11-14T20:13:13.424Z",
    "type": "completion"
   },
   {
    "id": "a8ee028085dd47888ffabdda77089fde",
    "time": "2020-11-14T20:13:13.511Z",
    "type": "completion"
   },
   {
    "id": "35b758228cbe4fda80ab63718c865881",
    "time": "2020-11-14T20:13:13.555Z",
    "type": "completion"
   },
   {
    "id": "6104f192bc66459bb55f484136db6bc0",
    "time": "2020-11-14T20:13:13.628Z",
    "type": "completion"
   },
   {
    "id": "9887f60fd1c6485d92c99722046482ed",
    "time": "2020-11-14T20:13:13.639Z",
    "type": "completion"
   },
   {
    "id": "ea6992288868470b801732fe09f37fdb",
    "time": "2020-11-14T20:13:13.692Z",
    "type": "completion"
   },
   {
    "id": "414103e3b8a74be9939a1588a5d6ce67",
    "time": "2020-11-14T20:13:13.706Z",
    "type": "completion"
   },
   {
    "id": "f4d5f163ead649c889ccb15ceca378c1",
    "time": "2020-11-14T20:13:13.755Z",
    "type": "completion"
   },
   {
    "id": "23414c47a5ba451a8e35981010243601",
    "time": "2020-11-14T20:13:13.758Z",
    "type": "completion"
   },
   {
    "id": "97d3db2c7ceb481882e86baf598ba7ed",
    "time": "2020-11-14T20:13:13.771Z",
    "type": "completion"
   },
   {
    "id": "c4c2b903a07f4eae8882bad65c5974e9",
    "time": "2020-11-14T20:13:13.775Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(85)",
    "id": "24a22adc859e413394b3411fd1379b09",
    "idx": 64,
    "time": "2020-11-14T20:13:20.998Z",
    "type": "execution"
   },
   {
    "id": "24a22adc859e413394b3411fd1379b09",
    "time": "2020-11-14T20:13:29.928Z",
    "type": "completion"
   },
   {
    "id": "24a22adc859e413394b3411fd1379b09",
    "time": "2020-11-14T20:13:29.928Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', 'journal',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:13:51.544Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:13:53.346Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:14:06.536Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:14:08.331Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(75)",
    "id": "24a22adc859e413394b3411fd1379b09",
    "idx": 64,
    "time": "2020-11-14T20:14:21.569Z",
    "type": "execution"
   },
   {
    "id": "24a22adc859e413394b3411fd1379b09",
    "time": "2020-11-14T20:14:30.494Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', 'plenipotentiary',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:14:51.033Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:14:52.907Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', 'robert',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:15:19.932Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:15:21.759Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:15:29.606Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:15:31.486Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', 'moore',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'web', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:15:57.436Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:15:59.300Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:16:19.539Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:16:21.371Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:16:37.645Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:16:39.415Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:16:59.455Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:17:01.186Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'trust', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'office', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:17:17.846Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:17:20.028Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:17:41.937Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:17:43.760Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:17:56.718Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:17:58.600Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:18:26.009Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:18:27.850Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:18:45.328Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:18:47.044Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:18:52.353Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:18:54.273Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:19:37.504Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:19:39.593Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:20:01.994Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:20:03.757Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:20:29.811Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:20:31.756Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:21:01.573Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:21:03.425Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:21:32.701Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:21:34.710Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'sellers',\n         'communications', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:21:53.646Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:21:55.352Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'maillings', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:22:11.310Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:22:12.997Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'mail', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:22:33.064Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:22:34.988Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:22:41.856Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:22:43.556Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:23:07.707Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:23:09.509Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'checks', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:23:17.231Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:23:19.212Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'build', 'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:23:28.601Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:23:30.320Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:23:53.226Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:23:55.723Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:25:32.937Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:25:34.583Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:25:46.683Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:25:48.619Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:26:01.396Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:26:03.099Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:26:16.536Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:26:18.136Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'net', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:26:29.725Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:26:31.409Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:26:59.357Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:27:00.948Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:27:10.878Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:27:12.500Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:27:17.501Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:27:19.183Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:27:33.439Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:27:35.082Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:28:16.645Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:28:18.281Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:28:49.564Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:28:51.194Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', \n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\npred2\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "idx": 67,
    "time": "2020-11-14T20:29:04.483Z",
    "type": "execution"
   },
   {
    "id": "1cb4afd554cb40f985d66ebc14690954",
    "time": "2020-11-14T20:29:06.474Z",
    "type": "completion"
   },
   {
    "code": "test_predictions = model2.predict(words_in_texts(words2, test['email']))",
    "id": "1a247d7345fe486497a10d441cb03bc7",
    "idx": 69,
    "time": "2020-11-14T20:31:10.691Z",
    "type": "execution"
   },
   {
    "id": "1a247d7345fe486497a10d441cb03bc7",
    "time": "2020-11-14T20:31:10.996Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q10\")",
    "id": "b5705d815104423a840223433a955f04",
    "idx": 70,
    "time": "2020-11-14T20:31:11.536Z",
    "type": "execution"
   },
   {
    "id": "b5705d815104423a840223433a955f04",
    "time": "2020-11-14T20:31:12.030Z",
    "type": "completion"
   },
   {
    "code": "from datetime import datetime\n\n# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n\n# Construct and save the submission:\nsubmission_df = pd.DataFrame({\n    \"Id\": test['id'], \n    \"Class\": test_predictions,\n}, columns=['Id', 'Class'])\ntimestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\nsubmission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n\nprint('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\nprint('You may now upload this CSV file to Gradescope for scoring.')",
    "id": "fc38ce4018ab48f285f878029a83a4d9",
    "idx": 72,
    "time": "2020-11-14T20:31:14.547Z",
    "type": "execution"
   },
   {
    "id": "fc38ce4018ab48f285f878029a83a4d9",
    "time": "2020-11-14T20:31:14.680Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "5a2afe5e1f7a4ec68a084146980698aa",
    "idx": 0,
    "time": "2020-11-16T06:06:16.721Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "512bdd7b4ee44dbc85af5c568173819d",
    "idx": 5,
    "time": "2020-11-16T06:06:16.735Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "badac90605254b96959cd8dc68b39b0b",
    "idx": 8,
    "time": "2020-11-16T06:06:16.739Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "d2c30124681e420b82ce890e283a4bf5",
    "idx": 10,
    "time": "2020-11-16T06:06:16.744Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "f7cab35fe2af46b28569f56d6a86b40c",
    "idx": 12,
    "time": "2020-11-16T06:06:16.748Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "5731d41a649c4f3e98769a25b7559c1f",
    "idx": 13,
    "time": "2020-11-16T06:06:16.751Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "2eee71e5413748da8dd75b99af7561bc",
    "idx": 14,
    "time": "2020-11-16T06:06:16.755Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "7b91016f28fa46c582baf25dda08eb4e",
    "idx": 15,
    "time": "2020-11-16T06:06:16.758Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "d93cf3e706914b10acbd9ef70727a97e",
    "idx": 17,
    "time": "2020-11-16T06:06:16.762Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "8a31d6b3619c45b98cc3930bf401644b",
    "idx": 18,
    "time": "2020-11-16T06:06:16.767Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "4cecea7b0716499082aa255b417fad3e",
    "idx": 22,
    "time": "2020-11-16T06:06:16.771Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "5bd47b99c8204fbc90fbeae6512906ae",
    "idx": 25,
    "time": "2020-11-16T06:06:16.775Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "83e341a0b75245ae8e28f4ff6c25045e",
    "idx": 26,
    "time": "2020-11-16T06:06:16.779Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "a64f4f1efabf4927905b983d196f7ed8",
    "idx": 29,
    "time": "2020-11-16T06:06:16.784Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "84f4a132b0ef447baf3d33a546af8a7d",
    "idx": 31,
    "time": "2020-11-16T06:06:16.788Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "163b1b05266b463c87acf87ab4a16300",
    "idx": 34,
    "time": "2020-11-16T06:06:16.792Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "d77ab79015a54f5a89d66440d688fec9",
    "idx": 37,
    "time": "2020-11-16T06:06:16.795Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "24fc54e981514d2696b05682a60c4ad8",
    "idx": 38,
    "time": "2020-11-16T06:06:16.799Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "ec370474779449ab809a2fb7b6141c91",
    "idx": 40,
    "time": "2020-11-16T06:06:16.802Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "a655344bbe7b42f286da988e58a57b04",
    "idx": 41,
    "time": "2020-11-16T06:06:16.805Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "8c5fdcff579444bc8c7179d59c58f331",
    "idx": 45,
    "time": "2020-11-16T06:06:16.810Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "8e97d1fd1d74408189ccb21f08fb6d57",
    "idx": 46,
    "time": "2020-11-16T06:06:16.813Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "a803e5a59d304bb18598e43d3be36b75",
    "idx": 48,
    "time": "2020-11-16T06:06:16.816Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "6ff633a13ae64167864a36ebe91f1ef4",
    "idx": 49,
    "time": "2020-11-16T06:06:16.819Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "1764899a38c54dc08290c63ebd79201f",
    "idx": 53,
    "time": "2020-11-16T06:06:16.822Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "5cd096e3403c4c998508fd152aa17b8f",
    "idx": 54,
    "time": "2020-11-16T06:06:16.825Z",
    "type": "execution"
   },
   {
    "id": "5a2afe5e1f7a4ec68a084146980698aa",
    "time": "2020-11-16T06:06:17.272Z",
    "type": "completion"
   },
   {
    "id": "512bdd7b4ee44dbc85af5c568173819d",
    "time": "2020-11-16T06:06:17.275Z",
    "type": "completion"
   },
   {
    "id": "badac90605254b96959cd8dc68b39b0b",
    "time": "2020-11-16T06:06:18.323Z",
    "type": "completion"
   },
   {
    "id": "d2c30124681e420b82ce890e283a4bf5",
    "time": "2020-11-16T06:06:19.167Z",
    "type": "completion"
   },
   {
    "id": "f7cab35fe2af46b28569f56d6a86b40c",
    "time": "2020-11-16T06:06:19.203Z",
    "type": "completion"
   },
   {
    "id": "5731d41a649c4f3e98769a25b7559c1f",
    "time": "2020-11-16T06:06:19.215Z",
    "type": "completion"
   },
   {
    "id": "2eee71e5413748da8dd75b99af7561bc",
    "time": "2020-11-16T06:06:19.223Z",
    "type": "completion"
   },
   {
    "id": "7b91016f28fa46c582baf25dda08eb4e",
    "time": "2020-11-16T06:06:19.226Z",
    "type": "completion"
   },
   {
    "id": "d93cf3e706914b10acbd9ef70727a97e",
    "time": "2020-11-16T06:06:19.229Z",
    "type": "completion"
   },
   {
    "id": "8a31d6b3619c45b98cc3930bf401644b",
    "time": "2020-11-16T06:06:19.235Z",
    "type": "completion"
   },
   {
    "id": "4cecea7b0716499082aa255b417fad3e",
    "time": "2020-11-16T06:06:19.275Z",
    "type": "completion"
   },
   {
    "id": "5bd47b99c8204fbc90fbeae6512906ae",
    "time": "2020-11-16T06:06:19.283Z",
    "type": "completion"
   },
   {
    "id": "83e341a0b75245ae8e28f4ff6c25045e",
    "time": "2020-11-16T06:06:19.290Z",
    "type": "completion"
   },
   {
    "id": "a64f4f1efabf4927905b983d196f7ed8",
    "time": "2020-11-16T06:06:19.350Z",
    "type": "completion"
   },
   {
    "id": "84f4a132b0ef447baf3d33a546af8a7d",
    "time": "2020-11-16T06:06:19.955Z",
    "type": "completion"
   },
   {
    "id": "163b1b05266b463c87acf87ab4a16300",
    "time": "2020-11-16T06:06:20.463Z",
    "type": "completion"
   },
   {
    "id": "d77ab79015a54f5a89d66440d688fec9",
    "time": "2020-11-16T06:06:20.478Z",
    "type": "completion"
   },
   {
    "id": "24fc54e981514d2696b05682a60c4ad8",
    "time": "2020-11-16T06:06:20.515Z",
    "type": "completion"
   },
   {
    "id": "ec370474779449ab809a2fb7b6141c91",
    "time": "2020-11-16T06:06:20.607Z",
    "type": "completion"
   },
   {
    "id": "a655344bbe7b42f286da988e58a57b04",
    "time": "2020-11-16T06:06:20.617Z",
    "type": "completion"
   },
   {
    "id": "8c5fdcff579444bc8c7179d59c58f331",
    "time": "2020-11-16T06:06:20.622Z",
    "type": "completion"
   },
   {
    "id": "8e97d1fd1d74408189ccb21f08fb6d57",
    "time": "2020-11-16T06:06:20.660Z",
    "type": "completion"
   },
   {
    "id": "a803e5a59d304bb18598e43d3be36b75",
    "time": "2020-11-16T06:06:20.664Z",
    "type": "completion"
   },
   {
    "id": "6ff633a13ae64167864a36ebe91f1ef4",
    "time": "2020-11-16T06:06:20.738Z",
    "type": "completion"
   },
   {
    "id": "1764899a38c54dc08290c63ebd79201f",
    "time": "2020-11-16T06:06:20.740Z",
    "type": "completion"
   },
   {
    "id": "5cd096e3403c4c998508fd152aa17b8f",
    "time": "2020-11-16T06:06:20.751Z",
    "type": "completion"
   },
   {
    "code": "ham_email = train[train[\"spam\"] == 0][\"email\"]\npunct_re = r'[^\\w\\s]'\nham_email = ham_email.str.replace(punct_re, \" \")\ntidy_format2 = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format2.index.name = None",
    "id": "734d7fce9c7349a190411af6ae6b1208",
    "idx": 65,
    "time": "2020-11-16T06:07:30.073Z",
    "type": "execution"
   },
   {
    "id": "734d7fce9c7349a190411af6ae6b1208",
    "time": "2020-11-16T06:07:31.359Z",
    "type": "completion"
   },
   {
    "code": "ham_email = train[train[\"spam\"] == 0][\"email\"]\npunct_re = r'[^\\w\\s]'\nham_email = ham_email.str.replace(punct_re, \" \")\ntidy_format2 = ham_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format2.index.name = None",
    "id": "734d7fce9c7349a190411af6ae6b1208",
    "idx": 65,
    "time": "2020-11-16T06:07:45.179Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "5a2afe5e1f7a4ec68a084146980698aa",
    "idx": 0,
    "time": "2020-11-16T06:08:21.589Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "512bdd7b4ee44dbc85af5c568173819d",
    "idx": 5,
    "time": "2020-11-16T06:08:21.594Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "badac90605254b96959cd8dc68b39b0b",
    "idx": 8,
    "time": "2020-11-16T06:08:21.598Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "d2c30124681e420b82ce890e283a4bf5",
    "idx": 10,
    "time": "2020-11-16T06:08:21.602Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "f7cab35fe2af46b28569f56d6a86b40c",
    "idx": 12,
    "time": "2020-11-16T06:08:21.604Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "5731d41a649c4f3e98769a25b7559c1f",
    "idx": 13,
    "time": "2020-11-16T06:08:21.607Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "2eee71e5413748da8dd75b99af7561bc",
    "idx": 14,
    "time": "2020-11-16T06:08:21.609Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "7b91016f28fa46c582baf25dda08eb4e",
    "idx": 15,
    "time": "2020-11-16T06:08:21.612Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "d93cf3e706914b10acbd9ef70727a97e",
    "idx": 17,
    "time": "2020-11-16T06:08:21.615Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "8a31d6b3619c45b98cc3930bf401644b",
    "idx": 18,
    "time": "2020-11-16T06:08:21.618Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "4cecea7b0716499082aa255b417fad3e",
    "idx": 22,
    "time": "2020-11-16T06:08:21.621Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "5bd47b99c8204fbc90fbeae6512906ae",
    "idx": 25,
    "time": "2020-11-16T06:08:21.627Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "83e341a0b75245ae8e28f4ff6c25045e",
    "idx": 26,
    "time": "2020-11-16T06:08:21.629Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "a64f4f1efabf4927905b983d196f7ed8",
    "idx": 29,
    "time": "2020-11-16T06:08:21.633Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "84f4a132b0ef447baf3d33a546af8a7d",
    "idx": 31,
    "time": "2020-11-16T06:08:21.637Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "163b1b05266b463c87acf87ab4a16300",
    "idx": 34,
    "time": "2020-11-16T06:08:21.640Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "d77ab79015a54f5a89d66440d688fec9",
    "idx": 37,
    "time": "2020-11-16T06:08:21.643Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "24fc54e981514d2696b05682a60c4ad8",
    "idx": 38,
    "time": "2020-11-16T06:08:21.646Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "ec370474779449ab809a2fb7b6141c91",
    "idx": 40,
    "time": "2020-11-16T06:08:21.649Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "a655344bbe7b42f286da988e58a57b04",
    "idx": 41,
    "time": "2020-11-16T06:08:21.651Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "8c5fdcff579444bc8c7179d59c58f331",
    "idx": 45,
    "time": "2020-11-16T06:08:21.655Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "8e97d1fd1d74408189ccb21f08fb6d57",
    "idx": 46,
    "time": "2020-11-16T06:08:21.657Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "a803e5a59d304bb18598e43d3be36b75",
    "idx": 48,
    "time": "2020-11-16T06:08:21.660Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "6ff633a13ae64167864a36ebe91f1ef4",
    "idx": 49,
    "time": "2020-11-16T06:08:21.662Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "1764899a38c54dc08290c63ebd79201f",
    "idx": 53,
    "time": "2020-11-16T06:08:21.666Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "5cd096e3403c4c998508fd152aa17b8f",
    "idx": 54,
    "time": "2020-11-16T06:08:21.669Z",
    "type": "execution"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(75)",
    "id": "3bb6840b73d04732898a6fa552ace4cd",
    "idx": 64,
    "time": "2020-11-16T06:08:21.675Z",
    "type": "execution"
   },
   {
    "id": "5a2afe5e1f7a4ec68a084146980698aa",
    "time": "2020-11-16T06:08:22.228Z",
    "type": "completion"
   },
   {
    "id": "512bdd7b4ee44dbc85af5c568173819d",
    "time": "2020-11-16T06:08:22.244Z",
    "type": "completion"
   },
   {
    "id": "badac90605254b96959cd8dc68b39b0b",
    "time": "2020-11-16T06:08:23.078Z",
    "type": "completion"
   },
   {
    "id": "d2c30124681e420b82ce890e283a4bf5",
    "time": "2020-11-16T06:08:23.271Z",
    "type": "completion"
   },
   {
    "id": "f7cab35fe2af46b28569f56d6a86b40c",
    "time": "2020-11-16T06:08:23.284Z",
    "type": "completion"
   },
   {
    "id": "5731d41a649c4f3e98769a25b7559c1f",
    "time": "2020-11-16T06:08:23.335Z",
    "type": "completion"
   },
   {
    "id": "2eee71e5413748da8dd75b99af7561bc",
    "time": "2020-11-16T06:08:23.340Z",
    "type": "completion"
   },
   {
    "id": "7b91016f28fa46c582baf25dda08eb4e",
    "time": "2020-11-16T06:08:23.391Z",
    "type": "completion"
   },
   {
    "id": "d93cf3e706914b10acbd9ef70727a97e",
    "time": "2020-11-16T06:08:23.397Z",
    "type": "completion"
   },
   {
    "id": "8a31d6b3619c45b98cc3930bf401644b",
    "time": "2020-11-16T06:08:23.404Z",
    "type": "completion"
   },
   {
    "id": "4cecea7b0716499082aa255b417fad3e",
    "time": "2020-11-16T06:08:23.459Z",
    "type": "completion"
   },
   {
    "id": "5bd47b99c8204fbc90fbeae6512906ae",
    "time": "2020-11-16T06:08:23.463Z",
    "type": "completion"
   },
   {
    "id": "83e341a0b75245ae8e28f4ff6c25045e",
    "time": "2020-11-16T06:08:23.479Z",
    "type": "completion"
   },
   {
    "id": "a64f4f1efabf4927905b983d196f7ed8",
    "time": "2020-11-16T06:08:23.547Z",
    "type": "completion"
   },
   {
    "id": "84f4a132b0ef447baf3d33a546af8a7d",
    "time": "2020-11-16T06:08:24.102Z",
    "type": "completion"
   },
   {
    "id": "163b1b05266b463c87acf87ab4a16300",
    "time": "2020-11-16T06:08:24.555Z",
    "type": "completion"
   },
   {
    "id": "d77ab79015a54f5a89d66440d688fec9",
    "time": "2020-11-16T06:08:24.692Z",
    "type": "completion"
   },
   {
    "id": "24fc54e981514d2696b05682a60c4ad8",
    "time": "2020-11-16T06:08:24.706Z",
    "type": "completion"
   },
   {
    "id": "ec370474779449ab809a2fb7b6141c91",
    "time": "2020-11-16T06:08:24.781Z",
    "type": "completion"
   },
   {
    "id": "a655344bbe7b42f286da988e58a57b04",
    "time": "2020-11-16T06:08:24.828Z",
    "type": "completion"
   },
   {
    "id": "8c5fdcff579444bc8c7179d59c58f331",
    "time": "2020-11-16T06:08:24.866Z",
    "type": "completion"
   },
   {
    "id": "8e97d1fd1d74408189ccb21f08fb6d57",
    "time": "2020-11-16T06:08:24.870Z",
    "type": "completion"
   },
   {
    "id": "a803e5a59d304bb18598e43d3be36b75",
    "time": "2020-11-16T06:08:24.876Z",
    "type": "completion"
   },
   {
    "id": "6ff633a13ae64167864a36ebe91f1ef4",
    "time": "2020-11-16T06:08:24.881Z",
    "type": "completion"
   },
   {
    "id": "1764899a38c54dc08290c63ebd79201f",
    "time": "2020-11-16T06:08:24.908Z",
    "type": "completion"
   },
   {
    "id": "5cd096e3403c4c998508fd152aa17b8f",
    "time": "2020-11-16T06:08:24.920Z",
    "type": "completion"
   },
   {
    "id": "3bb6840b73d04732898a6fa552ace4cd",
    "time": "2020-11-16T06:08:33.694Z",
    "type": "completion"
   },
   {
    "code": "ham_email = train[train[\"spam\"] == 0][\"email\"]\npunct_re = r'[^\\w\\s]'\nham_email = ham_email.str.replace(punct_re, \" \")\ntidy_format2 = ham_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format2.index.name = None\ntidy_format2.sort_values(by='num', ascending=False).head(75)",
    "id": "734d7fce9c7349a190411af6ae6b1208",
    "idx": 65,
    "time": "2020-11-16T06:08:50.109Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "5a2afe5e1f7a4ec68a084146980698aa",
    "idx": 0,
    "time": "2020-11-16T06:09:24.247Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "512bdd7b4ee44dbc85af5c568173819d",
    "idx": 5,
    "time": "2020-11-16T06:09:24.251Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "badac90605254b96959cd8dc68b39b0b",
    "idx": 8,
    "time": "2020-11-16T06:09:24.254Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "d2c30124681e420b82ce890e283a4bf5",
    "idx": 10,
    "time": "2020-11-16T06:09:24.257Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "f7cab35fe2af46b28569f56d6a86b40c",
    "idx": 12,
    "time": "2020-11-16T06:09:24.260Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "5731d41a649c4f3e98769a25b7559c1f",
    "idx": 13,
    "time": "2020-11-16T06:09:24.262Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "2eee71e5413748da8dd75b99af7561bc",
    "idx": 14,
    "time": "2020-11-16T06:09:24.264Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "7b91016f28fa46c582baf25dda08eb4e",
    "idx": 15,
    "time": "2020-11-16T06:09:24.267Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "d93cf3e706914b10acbd9ef70727a97e",
    "idx": 17,
    "time": "2020-11-16T06:09:24.270Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "8a31d6b3619c45b98cc3930bf401644b",
    "idx": 18,
    "time": "2020-11-16T06:09:24.272Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "4cecea7b0716499082aa255b417fad3e",
    "idx": 22,
    "time": "2020-11-16T06:09:24.276Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "5bd47b99c8204fbc90fbeae6512906ae",
    "idx": 25,
    "time": "2020-11-16T06:09:24.279Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "83e341a0b75245ae8e28f4ff6c25045e",
    "idx": 26,
    "time": "2020-11-16T06:09:24.281Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "a64f4f1efabf4927905b983d196f7ed8",
    "idx": 29,
    "time": "2020-11-16T06:09:24.285Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "84f4a132b0ef447baf3d33a546af8a7d",
    "idx": 31,
    "time": "2020-11-16T06:09:24.288Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "163b1b05266b463c87acf87ab4a16300",
    "idx": 34,
    "time": "2020-11-16T06:09:24.291Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "d77ab79015a54f5a89d66440d688fec9",
    "idx": 37,
    "time": "2020-11-16T06:09:24.294Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "24fc54e981514d2696b05682a60c4ad8",
    "idx": 38,
    "time": "2020-11-16T06:09:24.296Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "ec370474779449ab809a2fb7b6141c91",
    "idx": 40,
    "time": "2020-11-16T06:09:24.299Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "a655344bbe7b42f286da988e58a57b04",
    "idx": 41,
    "time": "2020-11-16T06:09:24.302Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "8c5fdcff579444bc8c7179d59c58f331",
    "idx": 45,
    "time": "2020-11-16T06:09:24.305Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "8e97d1fd1d74408189ccb21f08fb6d57",
    "idx": 46,
    "time": "2020-11-16T06:09:24.308Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "a803e5a59d304bb18598e43d3be36b75",
    "idx": 48,
    "time": "2020-11-16T06:09:24.311Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "6ff633a13ae64167864a36ebe91f1ef4",
    "idx": 49,
    "time": "2020-11-16T06:09:24.313Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "1764899a38c54dc08290c63ebd79201f",
    "idx": 53,
    "time": "2020-11-16T06:09:24.317Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "5cd096e3403c4c998508fd152aa17b8f",
    "idx": 54,
    "time": "2020-11-16T06:09:24.319Z",
    "type": "execution"
   },
   {
    "id": "5a2afe5e1f7a4ec68a084146980698aa",
    "time": "2020-11-16T06:09:24.896Z",
    "type": "completion"
   },
   {
    "id": "512bdd7b4ee44dbc85af5c568173819d",
    "time": "2020-11-16T06:09:24.898Z",
    "type": "completion"
   },
   {
    "id": "badac90605254b96959cd8dc68b39b0b",
    "time": "2020-11-16T06:09:25.715Z",
    "type": "completion"
   },
   {
    "id": "d2c30124681e420b82ce890e283a4bf5",
    "time": "2020-11-16T06:09:26.027Z",
    "type": "completion"
   },
   {
    "id": "f7cab35fe2af46b28569f56d6a86b40c",
    "time": "2020-11-16T06:09:26.032Z",
    "type": "completion"
   },
   {
    "id": "5731d41a649c4f3e98769a25b7559c1f",
    "time": "2020-11-16T06:09:26.067Z",
    "type": "completion"
   },
   {
    "id": "2eee71e5413748da8dd75b99af7561bc",
    "time": "2020-11-16T06:09:26.074Z",
    "type": "completion"
   },
   {
    "id": "7b91016f28fa46c582baf25dda08eb4e",
    "time": "2020-11-16T06:09:26.084Z",
    "type": "completion"
   },
   {
    "id": "d93cf3e706914b10acbd9ef70727a97e",
    "time": "2020-11-16T06:09:26.125Z",
    "type": "completion"
   },
   {
    "id": "8a31d6b3619c45b98cc3930bf401644b",
    "time": "2020-11-16T06:09:26.135Z",
    "type": "completion"
   },
   {
    "id": "4cecea7b0716499082aa255b417fad3e",
    "time": "2020-11-16T06:09:26.171Z",
    "type": "completion"
   },
   {
    "id": "5bd47b99c8204fbc90fbeae6512906ae",
    "time": "2020-11-16T06:09:26.176Z",
    "type": "completion"
   },
   {
    "id": "83e341a0b75245ae8e28f4ff6c25045e",
    "time": "2020-11-16T06:09:26.192Z",
    "type": "completion"
   },
   {
    "id": "a64f4f1efabf4927905b983d196f7ed8",
    "time": "2020-11-16T06:09:26.283Z",
    "type": "completion"
   },
   {
    "id": "84f4a132b0ef447baf3d33a546af8a7d",
    "time": "2020-11-16T06:09:26.814Z",
    "type": "completion"
   },
   {
    "id": "163b1b05266b463c87acf87ab4a16300",
    "time": "2020-11-16T06:09:27.477Z",
    "type": "completion"
   },
   {
    "id": "d77ab79015a54f5a89d66440d688fec9",
    "time": "2020-11-16T06:09:27.483Z",
    "type": "completion"
   },
   {
    "id": "24fc54e981514d2696b05682a60c4ad8",
    "time": "2020-11-16T06:09:27.486Z",
    "type": "completion"
   },
   {
    "id": "ec370474779449ab809a2fb7b6141c91",
    "time": "2020-11-16T06:09:27.520Z",
    "type": "completion"
   },
   {
    "id": "a655344bbe7b42f286da988e58a57b04",
    "time": "2020-11-16T06:09:27.553Z",
    "type": "completion"
   },
   {
    "id": "8c5fdcff579444bc8c7179d59c58f331",
    "time": "2020-11-16T06:09:27.559Z",
    "type": "completion"
   },
   {
    "id": "8e97d1fd1d74408189ccb21f08fb6d57",
    "time": "2020-11-16T06:09:27.574Z",
    "type": "completion"
   },
   {
    "id": "a803e5a59d304bb18598e43d3be36b75",
    "time": "2020-11-16T06:09:27.606Z",
    "type": "completion"
   },
   {
    "id": "6ff633a13ae64167864a36ebe91f1ef4",
    "time": "2020-11-16T06:09:27.610Z",
    "type": "completion"
   },
   {
    "id": "1764899a38c54dc08290c63ebd79201f",
    "time": "2020-11-16T06:09:27.650Z",
    "type": "completion"
   },
   {
    "id": "5cd096e3403c4c998508fd152aa17b8f",
    "time": "2020-11-16T06:09:27.654Z",
    "type": "completion"
   },
   {
    "code": "ham_email = train[train[\"spam\"] == 0][\"email\"]\npunct_re = r'[^\\w\\s]'\nham_email = ham_email.str.replace(punct_re, \" \")\ntidy_format2 = ham_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format2.index.name = None\ntidy_format[tidy_format['word'] != tidy_format2['word']]['word']",
    "id": "734d7fce9c7349a190411af6ae6b1208",
    "idx": 65,
    "time": "2020-11-16T06:10:57.205Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "5a2afe5e1f7a4ec68a084146980698aa",
    "idx": 0,
    "time": "2020-11-16T06:15:02.521Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "512bdd7b4ee44dbc85af5c568173819d",
    "idx": 5,
    "time": "2020-11-16T06:15:02.533Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "badac90605254b96959cd8dc68b39b0b",
    "idx": 8,
    "time": "2020-11-16T06:15:02.536Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "d2c30124681e420b82ce890e283a4bf5",
    "idx": 10,
    "time": "2020-11-16T06:15:02.549Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "f7cab35fe2af46b28569f56d6a86b40c",
    "idx": 12,
    "time": "2020-11-16T06:15:02.552Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "5731d41a649c4f3e98769a25b7559c1f",
    "idx": 13,
    "time": "2020-11-16T06:15:02.555Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "2eee71e5413748da8dd75b99af7561bc",
    "idx": 14,
    "time": "2020-11-16T06:15:02.558Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "7b91016f28fa46c582baf25dda08eb4e",
    "idx": 15,
    "time": "2020-11-16T06:15:02.561Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "d93cf3e706914b10acbd9ef70727a97e",
    "idx": 17,
    "time": "2020-11-16T06:15:02.564Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "8a31d6b3619c45b98cc3930bf401644b",
    "idx": 18,
    "time": "2020-11-16T06:15:02.567Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "4cecea7b0716499082aa255b417fad3e",
    "idx": 22,
    "time": "2020-11-16T06:15:02.570Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "5bd47b99c8204fbc90fbeae6512906ae",
    "idx": 25,
    "time": "2020-11-16T06:15:02.573Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "83e341a0b75245ae8e28f4ff6c25045e",
    "idx": 26,
    "time": "2020-11-16T06:15:02.577Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "a64f4f1efabf4927905b983d196f7ed8",
    "idx": 29,
    "time": "2020-11-16T06:15:02.582Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "84f4a132b0ef447baf3d33a546af8a7d",
    "idx": 31,
    "time": "2020-11-16T06:15:02.586Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "163b1b05266b463c87acf87ab4a16300",
    "idx": 34,
    "time": "2020-11-16T06:15:02.589Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "d77ab79015a54f5a89d66440d688fec9",
    "idx": 37,
    "time": "2020-11-16T06:15:02.596Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "24fc54e981514d2696b05682a60c4ad8",
    "idx": 38,
    "time": "2020-11-16T06:15:02.599Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "ec370474779449ab809a2fb7b6141c91",
    "idx": 40,
    "time": "2020-11-16T06:15:02.602Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "a655344bbe7b42f286da988e58a57b04",
    "idx": 41,
    "time": "2020-11-16T06:15:02.604Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "8c5fdcff579444bc8c7179d59c58f331",
    "idx": 45,
    "time": "2020-11-16T06:15:02.609Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "8e97d1fd1d74408189ccb21f08fb6d57",
    "idx": 46,
    "time": "2020-11-16T06:15:02.612Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "a803e5a59d304bb18598e43d3be36b75",
    "idx": 48,
    "time": "2020-11-16T06:15:02.615Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "6ff633a13ae64167864a36ebe91f1ef4",
    "idx": 49,
    "time": "2020-11-16T06:15:02.618Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "1764899a38c54dc08290c63ebd79201f",
    "idx": 53,
    "time": "2020-11-16T06:15:02.622Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "5cd096e3403c4c998508fd152aa17b8f",
    "idx": 54,
    "time": "2020-11-16T06:15:02.624Z",
    "type": "execution"
   },
   {
    "id": "5a2afe5e1f7a4ec68a084146980698aa",
    "time": "2020-11-16T06:15:03.131Z",
    "type": "completion"
   },
   {
    "id": "512bdd7b4ee44dbc85af5c568173819d",
    "time": "2020-11-16T06:15:03.159Z",
    "type": "completion"
   },
   {
    "id": "badac90605254b96959cd8dc68b39b0b",
    "time": "2020-11-16T06:15:03.845Z",
    "type": "completion"
   },
   {
    "id": "d2c30124681e420b82ce890e283a4bf5",
    "time": "2020-11-16T06:15:04.512Z",
    "type": "completion"
   },
   {
    "id": "f7cab35fe2af46b28569f56d6a86b40c",
    "time": "2020-11-16T06:15:04.517Z",
    "type": "completion"
   },
   {
    "id": "5731d41a649c4f3e98769a25b7559c1f",
    "time": "2020-11-16T06:15:04.557Z",
    "type": "completion"
   },
   {
    "id": "2eee71e5413748da8dd75b99af7561bc",
    "time": "2020-11-16T06:15:04.570Z",
    "type": "completion"
   },
   {
    "id": "7b91016f28fa46c582baf25dda08eb4e",
    "time": "2020-11-16T06:15:04.574Z",
    "type": "completion"
   },
   {
    "id": "d93cf3e706914b10acbd9ef70727a97e",
    "time": "2020-11-16T06:15:04.577Z",
    "type": "completion"
   },
   {
    "id": "8a31d6b3619c45b98cc3930bf401644b",
    "time": "2020-11-16T06:15:04.582Z",
    "type": "completion"
   },
   {
    "id": "4cecea7b0716499082aa255b417fad3e",
    "time": "2020-11-16T06:15:04.583Z",
    "type": "completion"
   },
   {
    "id": "5bd47b99c8204fbc90fbeae6512906ae",
    "time": "2020-11-16T06:15:04.584Z",
    "type": "completion"
   },
   {
    "id": "83e341a0b75245ae8e28f4ff6c25045e",
    "time": "2020-11-16T06:15:04.627Z",
    "type": "completion"
   },
   {
    "id": "a64f4f1efabf4927905b983d196f7ed8",
    "time": "2020-11-16T06:15:04.645Z",
    "type": "completion"
   },
   {
    "id": "84f4a132b0ef447baf3d33a546af8a7d",
    "time": "2020-11-16T06:15:05.109Z",
    "type": "completion"
   },
   {
    "id": "163b1b05266b463c87acf87ab4a16300",
    "time": "2020-11-16T06:15:05.764Z",
    "type": "completion"
   },
   {
    "id": "d77ab79015a54f5a89d66440d688fec9",
    "time": "2020-11-16T06:15:05.825Z",
    "type": "completion"
   },
   {
    "id": "24fc54e981514d2696b05682a60c4ad8",
    "time": "2020-11-16T06:15:05.837Z",
    "type": "completion"
   },
   {
    "id": "ec370474779449ab809a2fb7b6141c91",
    "time": "2020-11-16T06:15:05.939Z",
    "type": "completion"
   },
   {
    "id": "a655344bbe7b42f286da988e58a57b04",
    "time": "2020-11-16T06:15:05.976Z",
    "type": "completion"
   },
   {
    "id": "8c5fdcff579444bc8c7179d59c58f331",
    "time": "2020-11-16T06:15:05.981Z",
    "type": "completion"
   },
   {
    "id": "8e97d1fd1d74408189ccb21f08fb6d57",
    "time": "2020-11-16T06:15:05.994Z",
    "type": "completion"
   },
   {
    "id": "a803e5a59d304bb18598e43d3be36b75",
    "time": "2020-11-16T06:15:06.030Z",
    "type": "completion"
   },
   {
    "id": "6ff633a13ae64167864a36ebe91f1ef4",
    "time": "2020-11-16T06:15:06.045Z",
    "type": "completion"
   },
   {
    "id": "1764899a38c54dc08290c63ebd79201f",
    "time": "2020-11-16T06:15:06.046Z",
    "type": "completion"
   },
   {
    "id": "5cd096e3403c4c998508fd152aa17b8f",
    "time": "2020-11-16T06:15:06.088Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "d619bd76ba004d298e6d7d9d623013e3",
    "idx": 0,
    "time": "2020-11-16T06:15:26.975Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "b804e1d55a02482c989b78bed6ce2a4a",
    "idx": 5,
    "time": "2020-11-16T06:15:26.990Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "38d407e273034240b919d579faaba3ff",
    "idx": 8,
    "time": "2020-11-16T06:15:26.994Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "e19fad9da5e941db8bbde0836e06c8ef",
    "idx": 10,
    "time": "2020-11-16T06:15:26.998Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "92f2c9f609fe430d81720dc77fb20ee6",
    "idx": 12,
    "time": "2020-11-16T06:15:27.001Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "25e8d4bef8a14cc7aa85b8c2643179de",
    "idx": 13,
    "time": "2020-11-16T06:15:27.004Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "6d92146dad1148e182afc964d87665ee",
    "idx": 14,
    "time": "2020-11-16T06:15:27.007Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "c884952550a14cb0874ee85bdf9cfafa",
    "idx": 15,
    "time": "2020-11-16T06:15:27.012Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "a88792c9c6384c3b91383d1eda0a3be5",
    "idx": 17,
    "time": "2020-11-16T06:15:27.016Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "a9e67a680a67486280b432cbe1b6b610",
    "idx": 18,
    "time": "2020-11-16T06:15:27.018Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "93d63e91da8b43a58c35e32943c9aa1b",
    "idx": 22,
    "time": "2020-11-16T06:15:27.023Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "2ef5e737109b47ba874b8a7fb752c392",
    "idx": 25,
    "time": "2020-11-16T06:15:27.026Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "d1c534b07468451e824e7b80f52fb70f",
    "idx": 26,
    "time": "2020-11-16T06:15:27.029Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "86a6913dd6fb4185a193d7df00f5a297",
    "idx": 29,
    "time": "2020-11-16T06:15:27.033Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "7dfc86cf6a62427d849e0c086b04b560",
    "idx": 31,
    "time": "2020-11-16T06:15:27.036Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "cd937080e33e4c628160900e27624cc8",
    "idx": 34,
    "time": "2020-11-16T06:15:27.040Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "37d6fd54149846c3ac09d16fb2da17a9",
    "idx": 37,
    "time": "2020-11-16T06:15:27.044Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "c489b03c2bb54d5483faa77f25914dfe",
    "idx": 38,
    "time": "2020-11-16T06:15:27.048Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "40c27591e6d24929b1bed0ba884935b0",
    "idx": 40,
    "time": "2020-11-16T06:15:27.050Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "5bd0490c799746ba8a512272769af41f",
    "idx": 41,
    "time": "2020-11-16T06:15:27.053Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "47ec41dd092a47d4b643c6a790ab9813",
    "idx": 45,
    "time": "2020-11-16T06:15:27.057Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "debe0f3b24f94c7085daac983292d151",
    "idx": 46,
    "time": "2020-11-16T06:15:27.061Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "5ebdc928dc5e4287ada5aea313da6e24",
    "idx": 48,
    "time": "2020-11-16T06:15:27.064Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "3ae32ac9c7014b6d8c345b07ce9b198e",
    "idx": 49,
    "time": "2020-11-16T06:15:27.067Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "f4fede40ff254bea8ec349efada36835",
    "idx": 53,
    "time": "2020-11-16T06:15:27.071Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "40c5cec225f14c448c18018e24ac40dc",
    "idx": 54,
    "time": "2020-11-16T06:15:27.074Z",
    "type": "execution"
   },
   {
    "id": "d619bd76ba004d298e6d7d9d623013e3",
    "time": "2020-11-16T06:15:27.144Z",
    "type": "completion"
   },
   {
    "id": "b804e1d55a02482c989b78bed6ce2a4a",
    "time": "2020-11-16T06:15:27.153Z",
    "type": "completion"
   },
   {
    "id": "38d407e273034240b919d579faaba3ff",
    "time": "2020-11-16T06:15:27.166Z",
    "type": "completion"
   },
   {
    "id": "e19fad9da5e941db8bbde0836e06c8ef",
    "time": "2020-11-16T06:15:27.657Z",
    "type": "completion"
   },
   {
    "id": "92f2c9f609fe430d81720dc77fb20ee6",
    "time": "2020-11-16T06:15:27.700Z",
    "type": "completion"
   },
   {
    "id": "25e8d4bef8a14cc7aa85b8c2643179de",
    "time": "2020-11-16T06:15:27.703Z",
    "type": "completion"
   },
   {
    "id": "6d92146dad1148e182afc964d87665ee",
    "time": "2020-11-16T06:15:27.710Z",
    "type": "completion"
   },
   {
    "id": "c884952550a14cb0874ee85bdf9cfafa",
    "time": "2020-11-16T06:15:27.755Z",
    "type": "completion"
   },
   {
    "id": "a88792c9c6384c3b91383d1eda0a3be5",
    "time": "2020-11-16T06:15:27.761Z",
    "type": "completion"
   },
   {
    "id": "a9e67a680a67486280b432cbe1b6b610",
    "time": "2020-11-16T06:15:27.808Z",
    "type": "completion"
   },
   {
    "id": "93d63e91da8b43a58c35e32943c9aa1b",
    "time": "2020-11-16T06:15:27.815Z",
    "type": "completion"
   },
   {
    "id": "2ef5e737109b47ba874b8a7fb752c392",
    "time": "2020-11-16T06:15:27.821Z",
    "type": "completion"
   },
   {
    "id": "d1c534b07468451e824e7b80f52fb70f",
    "time": "2020-11-16T06:15:27.827Z",
    "type": "completion"
   },
   {
    "id": "86a6913dd6fb4185a193d7df00f5a297",
    "time": "2020-11-16T06:15:27.881Z",
    "type": "completion"
   },
   {
    "id": "7dfc86cf6a62427d849e0c086b04b560",
    "time": "2020-11-16T06:15:28.492Z",
    "type": "completion"
   },
   {
    "id": "cd937080e33e4c628160900e27624cc8",
    "time": "2020-11-16T06:15:28.975Z",
    "type": "completion"
   },
   {
    "id": "37d6fd54149846c3ac09d16fb2da17a9",
    "time": "2020-11-16T06:15:28.984Z",
    "type": "completion"
   },
   {
    "id": "c489b03c2bb54d5483faa77f25914dfe",
    "time": "2020-11-16T06:15:29.018Z",
    "type": "completion"
   },
   {
    "id": "40c27591e6d24929b1bed0ba884935b0",
    "time": "2020-11-16T06:15:29.044Z",
    "type": "completion"
   },
   {
    "id": "5bd0490c799746ba8a512272769af41f",
    "time": "2020-11-16T06:15:29.085Z",
    "type": "completion"
   },
   {
    "id": "47ec41dd092a47d4b643c6a790ab9813",
    "time": "2020-11-16T06:15:29.098Z",
    "type": "completion"
   },
   {
    "id": "debe0f3b24f94c7085daac983292d151",
    "time": "2020-11-16T06:15:29.105Z",
    "type": "completion"
   },
   {
    "id": "5ebdc928dc5e4287ada5aea313da6e24",
    "time": "2020-11-16T06:15:29.143Z",
    "type": "completion"
   },
   {
    "id": "3ae32ac9c7014b6d8c345b07ce9b198e",
    "time": "2020-11-16T06:15:29.187Z",
    "type": "completion"
   },
   {
    "id": "f4fede40ff254bea8ec349efada36835",
    "time": "2020-11-16T06:15:29.192Z",
    "type": "completion"
   },
   {
    "id": "40c5cec225f14c448c18018e24ac40dc",
    "time": "2020-11-16T06:15:29.219Z",
    "type": "completion"
   },
   {
    "code": "ham_email = train[train[\"spam\"] == 0][\"email\"]\npunct_re = r'[^\\w\\s]'\nham_email = ham_email.str.replace(punct_re, \" \")\ntidy_format2 = ham_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format2.index.name = None\ntidy_format2\n# tidy_format[tidy_format['word'] != tidy_format2['word']]['word']",
    "id": "1870d235f4504b00a5ddc7172906fdc2",
    "idx": 65,
    "time": "2020-11-16T06:15:48.522Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "d619bd76ba004d298e6d7d9d623013e3",
    "idx": 0,
    "time": "2020-11-16T06:16:48.429Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "b804e1d55a02482c989b78bed6ce2a4a",
    "idx": 5,
    "time": "2020-11-16T06:16:48.440Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "38d407e273034240b919d579faaba3ff",
    "idx": 8,
    "time": "2020-11-16T06:16:48.444Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "e19fad9da5e941db8bbde0836e06c8ef",
    "idx": 10,
    "time": "2020-11-16T06:16:48.448Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "92f2c9f609fe430d81720dc77fb20ee6",
    "idx": 12,
    "time": "2020-11-16T06:16:48.451Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "25e8d4bef8a14cc7aa85b8c2643179de",
    "idx": 13,
    "time": "2020-11-16T06:16:48.453Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "6d92146dad1148e182afc964d87665ee",
    "idx": 14,
    "time": "2020-11-16T06:16:48.455Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "c884952550a14cb0874ee85bdf9cfafa",
    "idx": 15,
    "time": "2020-11-16T06:16:48.458Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "a88792c9c6384c3b91383d1eda0a3be5",
    "idx": 17,
    "time": "2020-11-16T06:16:48.461Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "a9e67a680a67486280b432cbe1b6b610",
    "idx": 18,
    "time": "2020-11-16T06:16:48.464Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "93d63e91da8b43a58c35e32943c9aa1b",
    "idx": 22,
    "time": "2020-11-16T06:16:48.468Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "2ef5e737109b47ba874b8a7fb752c392",
    "idx": 25,
    "time": "2020-11-16T06:16:48.472Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "d1c534b07468451e824e7b80f52fb70f",
    "idx": 26,
    "time": "2020-11-16T06:16:48.474Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "86a6913dd6fb4185a193d7df00f5a297",
    "idx": 29,
    "time": "2020-11-16T06:16:48.478Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "7dfc86cf6a62427d849e0c086b04b560",
    "idx": 31,
    "time": "2020-11-16T06:16:48.481Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "cd937080e33e4c628160900e27624cc8",
    "idx": 34,
    "time": "2020-11-16T06:16:48.484Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "37d6fd54149846c3ac09d16fb2da17a9",
    "idx": 37,
    "time": "2020-11-16T06:16:48.490Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "c489b03c2bb54d5483faa77f25914dfe",
    "idx": 38,
    "time": "2020-11-16T06:16:48.492Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "40c27591e6d24929b1bed0ba884935b0",
    "idx": 40,
    "time": "2020-11-16T06:16:48.496Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "5bd0490c799746ba8a512272769af41f",
    "idx": 41,
    "time": "2020-11-16T06:16:48.498Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "47ec41dd092a47d4b643c6a790ab9813",
    "idx": 45,
    "time": "2020-11-16T06:16:48.502Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "debe0f3b24f94c7085daac983292d151",
    "idx": 46,
    "time": "2020-11-16T06:16:48.505Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "5ebdc928dc5e4287ada5aea313da6e24",
    "idx": 48,
    "time": "2020-11-16T06:16:48.508Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "3ae32ac9c7014b6d8c345b07ce9b198e",
    "idx": 49,
    "time": "2020-11-16T06:16:48.512Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "f4fede40ff254bea8ec349efada36835",
    "idx": 53,
    "time": "2020-11-16T06:16:48.516Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "40c5cec225f14c448c18018e24ac40dc",
    "idx": 54,
    "time": "2020-11-16T06:16:48.518Z",
    "type": "execution"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(75)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:16:48.526Z",
    "type": "execution"
   },
   {
    "id": "d619bd76ba004d298e6d7d9d623013e3",
    "time": "2020-11-16T06:16:48.971Z",
    "type": "completion"
   },
   {
    "id": "b804e1d55a02482c989b78bed6ce2a4a",
    "time": "2020-11-16T06:16:48.973Z",
    "type": "completion"
   },
   {
    "id": "38d407e273034240b919d579faaba3ff",
    "time": "2020-11-16T06:16:49.918Z",
    "type": "completion"
   },
   {
    "id": "e19fad9da5e941db8bbde0836e06c8ef",
    "time": "2020-11-16T06:16:50.373Z",
    "type": "completion"
   },
   {
    "id": "92f2c9f609fe430d81720dc77fb20ee6",
    "time": "2020-11-16T06:16:50.380Z",
    "type": "completion"
   },
   {
    "id": "25e8d4bef8a14cc7aa85b8c2643179de",
    "time": "2020-11-16T06:16:50.391Z",
    "type": "completion"
   },
   {
    "id": "6d92146dad1148e182afc964d87665ee",
    "time": "2020-11-16T06:16:50.430Z",
    "type": "completion"
   },
   {
    "id": "c884952550a14cb0874ee85bdf9cfafa",
    "time": "2020-11-16T06:16:50.442Z",
    "type": "completion"
   },
   {
    "id": "a88792c9c6384c3b91383d1eda0a3be5",
    "time": "2020-11-16T06:16:50.449Z",
    "type": "completion"
   },
   {
    "id": "a9e67a680a67486280b432cbe1b6b610",
    "time": "2020-11-16T06:16:50.452Z",
    "type": "completion"
   },
   {
    "id": "93d63e91da8b43a58c35e32943c9aa1b",
    "time": "2020-11-16T06:16:50.455Z",
    "type": "completion"
   },
   {
    "id": "2ef5e737109b47ba874b8a7fb752c392",
    "time": "2020-11-16T06:16:50.458Z",
    "type": "completion"
   },
   {
    "id": "d1c534b07468451e824e7b80f52fb70f",
    "time": "2020-11-16T06:16:50.477Z",
    "type": "completion"
   },
   {
    "id": "86a6913dd6fb4185a193d7df00f5a297",
    "time": "2020-11-16T06:16:50.497Z",
    "type": "completion"
   },
   {
    "id": "7dfc86cf6a62427d849e0c086b04b560",
    "time": "2020-11-16T06:16:51.027Z",
    "type": "completion"
   },
   {
    "id": "cd937080e33e4c628160900e27624cc8",
    "time": "2020-11-16T06:16:51.482Z",
    "type": "completion"
   },
   {
    "id": "37d6fd54149846c3ac09d16fb2da17a9",
    "time": "2020-11-16T06:16:51.613Z",
    "type": "completion"
   },
   {
    "id": "c489b03c2bb54d5483faa77f25914dfe",
    "time": "2020-11-16T06:16:51.622Z",
    "type": "completion"
   },
   {
    "id": "40c27591e6d24929b1bed0ba884935b0",
    "time": "2020-11-16T06:16:51.694Z",
    "type": "completion"
   },
   {
    "id": "5bd0490c799746ba8a512272769af41f",
    "time": "2020-11-16T06:16:51.744Z",
    "type": "completion"
   },
   {
    "id": "47ec41dd092a47d4b643c6a790ab9813",
    "time": "2020-11-16T06:16:51.778Z",
    "type": "completion"
   },
   {
    "id": "debe0f3b24f94c7085daac983292d151",
    "time": "2020-11-16T06:16:51.828Z",
    "type": "completion"
   },
   {
    "id": "5ebdc928dc5e4287ada5aea313da6e24",
    "time": "2020-11-16T06:16:51.844Z",
    "type": "completion"
   },
   {
    "id": "3ae32ac9c7014b6d8c345b07ce9b198e",
    "time": "2020-11-16T06:16:51.852Z",
    "type": "completion"
   },
   {
    "id": "f4fede40ff254bea8ec349efada36835",
    "time": "2020-11-16T06:16:51.854Z",
    "type": "completion"
   },
   {
    "id": "40c5cec225f14c448c18018e24ac40dc",
    "time": "2020-11-16T06:16:51.892Z",
    "type": "completion"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:17:00.430Z",
    "type": "completion"
   },
   {
    "code": "ham_email = train[train[\"spam\"] == 0][\"email\"]\npunct_re = r'[^\\w\\s]'\nham_email = ham_email.str.replace(punct_re, \" \")",
    "id": "1870d235f4504b00a5ddc7172906fdc2",
    "idx": 65,
    "time": "2020-11-16T06:17:06.383Z",
    "type": "execution"
   },
   {
    "id": "1870d235f4504b00a5ddc7172906fdc2",
    "time": "2020-11-16T06:17:07.329Z",
    "type": "completion"
   },
   {
    "id": "1870d235f4504b00a5ddc7172906fdc2",
    "time": "2020-11-16T06:17:07.329Z",
    "type": "completion"
   },
   {
    "code": "tidy_format2 = ham_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format2.index.name = None\ntidy_format2\n# tidy_format[tidy_format['word'] != tidy_format2['word']]['word']",
    "id": "7a882597e3bb4e7d8a073c4676d58751",
    "idx": 66,
    "time": "2020-11-16T06:17:11.934Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "d619bd76ba004d298e6d7d9d623013e3",
    "idx": 0,
    "time": "2020-11-16T06:18:54.520Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "b804e1d55a02482c989b78bed6ce2a4a",
    "idx": 5,
    "time": "2020-11-16T06:18:54.531Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "38d407e273034240b919d579faaba3ff",
    "idx": 8,
    "time": "2020-11-16T06:18:54.535Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "e19fad9da5e941db8bbde0836e06c8ef",
    "idx": 10,
    "time": "2020-11-16T06:18:54.539Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "92f2c9f609fe430d81720dc77fb20ee6",
    "idx": 12,
    "time": "2020-11-16T06:18:54.542Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "25e8d4bef8a14cc7aa85b8c2643179de",
    "idx": 13,
    "time": "2020-11-16T06:18:54.544Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "6d92146dad1148e182afc964d87665ee",
    "idx": 14,
    "time": "2020-11-16T06:18:54.546Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "c884952550a14cb0874ee85bdf9cfafa",
    "idx": 15,
    "time": "2020-11-16T06:18:54.549Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "a88792c9c6384c3b91383d1eda0a3be5",
    "idx": 17,
    "time": "2020-11-16T06:18:54.551Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "a9e67a680a67486280b432cbe1b6b610",
    "idx": 18,
    "time": "2020-11-16T06:18:54.554Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "93d63e91da8b43a58c35e32943c9aa1b",
    "idx": 22,
    "time": "2020-11-16T06:18:54.558Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "2ef5e737109b47ba874b8a7fb752c392",
    "idx": 25,
    "time": "2020-11-16T06:18:54.561Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "d1c534b07468451e824e7b80f52fb70f",
    "idx": 26,
    "time": "2020-11-16T06:18:54.563Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "86a6913dd6fb4185a193d7df00f5a297",
    "idx": 29,
    "time": "2020-11-16T06:18:54.567Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "7dfc86cf6a62427d849e0c086b04b560",
    "idx": 31,
    "time": "2020-11-16T06:18:54.570Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "cd937080e33e4c628160900e27624cc8",
    "idx": 34,
    "time": "2020-11-16T06:18:54.573Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "37d6fd54149846c3ac09d16fb2da17a9",
    "idx": 37,
    "time": "2020-11-16T06:18:54.576Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "c489b03c2bb54d5483faa77f25914dfe",
    "idx": 38,
    "time": "2020-11-16T06:18:54.578Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "40c27591e6d24929b1bed0ba884935b0",
    "idx": 40,
    "time": "2020-11-16T06:18:54.581Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "5bd0490c799746ba8a512272769af41f",
    "idx": 41,
    "time": "2020-11-16T06:18:54.584Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "47ec41dd092a47d4b643c6a790ab9813",
    "idx": 45,
    "time": "2020-11-16T06:18:54.588Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "debe0f3b24f94c7085daac983292d151",
    "idx": 46,
    "time": "2020-11-16T06:18:54.590Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "5ebdc928dc5e4287ada5aea313da6e24",
    "idx": 48,
    "time": "2020-11-16T06:18:54.595Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "3ae32ac9c7014b6d8c345b07ce9b198e",
    "idx": 49,
    "time": "2020-11-16T06:18:54.597Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "f4fede40ff254bea8ec349efada36835",
    "idx": 53,
    "time": "2020-11-16T06:18:54.602Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "40c5cec225f14c448c18018e24ac40dc",
    "idx": 54,
    "time": "2020-11-16T06:18:54.605Z",
    "type": "execution"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).head(75)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:18:54.615Z",
    "type": "execution"
   },
   {
    "code": "ham_email = train[train[\"spam\"] == 0][\"email\"]\npunct_re = r'[^\\w\\s]'\nham_email = ham_email.str.replace(punct_re, \" \")",
    "id": "1870d235f4504b00a5ddc7172906fdc2",
    "idx": 65,
    "time": "2020-11-16T06:18:54.617Z",
    "type": "execution"
   },
   {
    "id": "d619bd76ba004d298e6d7d9d623013e3",
    "time": "2020-11-16T06:18:55.083Z",
    "type": "completion"
   },
   {
    "id": "b804e1d55a02482c989b78bed6ce2a4a",
    "time": "2020-11-16T06:18:55.084Z",
    "type": "completion"
   },
   {
    "id": "38d407e273034240b919d579faaba3ff",
    "time": "2020-11-16T06:18:55.883Z",
    "type": "completion"
   },
   {
    "id": "e19fad9da5e941db8bbde0836e06c8ef",
    "time": "2020-11-16T06:18:56.399Z",
    "type": "completion"
   },
   {
    "id": "92f2c9f609fe430d81720dc77fb20ee6",
    "time": "2020-11-16T06:18:56.516Z",
    "type": "completion"
   },
   {
    "id": "25e8d4bef8a14cc7aa85b8c2643179de",
    "time": "2020-11-16T06:18:56.523Z",
    "type": "completion"
   },
   {
    "id": "6d92146dad1148e182afc964d87665ee",
    "time": "2020-11-16T06:18:56.530Z",
    "type": "completion"
   },
   {
    "id": "c884952550a14cb0874ee85bdf9cfafa",
    "time": "2020-11-16T06:18:56.534Z",
    "type": "completion"
   },
   {
    "id": "a88792c9c6384c3b91383d1eda0a3be5",
    "time": "2020-11-16T06:18:56.536Z",
    "type": "completion"
   },
   {
    "id": "a9e67a680a67486280b432cbe1b6b610",
    "time": "2020-11-16T06:18:56.539Z",
    "type": "completion"
   },
   {
    "id": "93d63e91da8b43a58c35e32943c9aa1b",
    "time": "2020-11-16T06:18:56.550Z",
    "type": "completion"
   },
   {
    "id": "2ef5e737109b47ba874b8a7fb752c392",
    "time": "2020-11-16T06:18:56.558Z",
    "type": "completion"
   },
   {
    "id": "d1c534b07468451e824e7b80f52fb70f",
    "time": "2020-11-16T06:18:56.612Z",
    "type": "completion"
   },
   {
    "id": "86a6913dd6fb4185a193d7df00f5a297",
    "time": "2020-11-16T06:18:56.638Z",
    "type": "completion"
   },
   {
    "id": "7dfc86cf6a62427d849e0c086b04b560",
    "time": "2020-11-16T06:18:57.073Z",
    "type": "completion"
   },
   {
    "id": "cd937080e33e4c628160900e27624cc8",
    "time": "2020-11-16T06:18:57.709Z",
    "type": "completion"
   },
   {
    "id": "37d6fd54149846c3ac09d16fb2da17a9",
    "time": "2020-11-16T06:18:57.746Z",
    "type": "completion"
   },
   {
    "id": "c489b03c2bb54d5483faa77f25914dfe",
    "time": "2020-11-16T06:18:57.795Z",
    "type": "completion"
   },
   {
    "id": "40c27591e6d24929b1bed0ba884935b0",
    "time": "2020-11-16T06:18:57.893Z",
    "type": "completion"
   },
   {
    "id": "5bd0490c799746ba8a512272769af41f",
    "time": "2020-11-16T06:18:57.897Z",
    "type": "completion"
   },
   {
    "id": "47ec41dd092a47d4b643c6a790ab9813",
    "time": "2020-11-16T06:18:57.901Z",
    "type": "completion"
   },
   {
    "id": "debe0f3b24f94c7085daac983292d151",
    "time": "2020-11-16T06:18:57.935Z",
    "type": "completion"
   },
   {
    "id": "5ebdc928dc5e4287ada5aea313da6e24",
    "time": "2020-11-16T06:18:57.946Z",
    "type": "completion"
   },
   {
    "id": "3ae32ac9c7014b6d8c345b07ce9b198e",
    "time": "2020-11-16T06:18:57.951Z",
    "type": "completion"
   },
   {
    "id": "f4fede40ff254bea8ec349efada36835",
    "time": "2020-11-16T06:18:57.953Z",
    "type": "completion"
   },
   {
    "id": "40c5cec225f14c448c18018e24ac40dc",
    "time": "2020-11-16T06:18:57.988Z",
    "type": "completion"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:19:06.754Z",
    "type": "completion"
   },
   {
    "id": "1870d235f4504b00a5ddc7172906fdc2",
    "time": "2020-11-16T06:19:07.342Z",
    "type": "completion"
   },
   {
    "code": "tidy_format2 = ham_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\n",
    "id": "7a882597e3bb4e7d8a073c4676d58751",
    "idx": 66,
    "time": "2020-11-16T06:20:01.618Z",
    "type": "execution"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "d619bd76ba004d298e6d7d9d623013e3",
    "idx": 0,
    "time": "2020-11-16T06:20:49.990Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "b804e1d55a02482c989b78bed6ce2a4a",
    "idx": 5,
    "time": "2020-11-16T06:20:49.994Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "38d407e273034240b919d579faaba3ff",
    "idx": 8,
    "time": "2020-11-16T06:20:49.997Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "e19fad9da5e941db8bbde0836e06c8ef",
    "idx": 10,
    "time": "2020-11-16T06:20:50.000Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "92f2c9f609fe430d81720dc77fb20ee6",
    "idx": 12,
    "time": "2020-11-16T06:20:50.003Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "25e8d4bef8a14cc7aa85b8c2643179de",
    "idx": 13,
    "time": "2020-11-16T06:20:50.005Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "6d92146dad1148e182afc964d87665ee",
    "idx": 14,
    "time": "2020-11-16T06:20:50.007Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "c884952550a14cb0874ee85bdf9cfafa",
    "idx": 15,
    "time": "2020-11-16T06:20:50.010Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "a88792c9c6384c3b91383d1eda0a3be5",
    "idx": 17,
    "time": "2020-11-16T06:20:50.013Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "a9e67a680a67486280b432cbe1b6b610",
    "idx": 18,
    "time": "2020-11-16T06:20:50.015Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "93d63e91da8b43a58c35e32943c9aa1b",
    "idx": 22,
    "time": "2020-11-16T06:20:50.019Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "2ef5e737109b47ba874b8a7fb752c392",
    "idx": 25,
    "time": "2020-11-16T06:20:50.023Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "d1c534b07468451e824e7b80f52fb70f",
    "idx": 26,
    "time": "2020-11-16T06:20:50.025Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "86a6913dd6fb4185a193d7df00f5a297",
    "idx": 29,
    "time": "2020-11-16T06:20:50.029Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "7dfc86cf6a62427d849e0c086b04b560",
    "idx": 31,
    "time": "2020-11-16T06:20:50.032Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "cd937080e33e4c628160900e27624cc8",
    "idx": 34,
    "time": "2020-11-16T06:20:50.035Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "37d6fd54149846c3ac09d16fb2da17a9",
    "idx": 37,
    "time": "2020-11-16T06:20:50.039Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "c489b03c2bb54d5483faa77f25914dfe",
    "idx": 38,
    "time": "2020-11-16T06:20:50.041Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "40c27591e6d24929b1bed0ba884935b0",
    "idx": 40,
    "time": "2020-11-16T06:20:50.044Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "5bd0490c799746ba8a512272769af41f",
    "idx": 41,
    "time": "2020-11-16T06:20:50.046Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "47ec41dd092a47d4b643c6a790ab9813",
    "idx": 45,
    "time": "2020-11-16T06:20:50.050Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "debe0f3b24f94c7085daac983292d151",
    "idx": 46,
    "time": "2020-11-16T06:20:50.052Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "5ebdc928dc5e4287ada5aea313da6e24",
    "idx": 48,
    "time": "2020-11-16T06:20:50.055Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "3ae32ac9c7014b6d8c345b07ce9b198e",
    "idx": 49,
    "time": "2020-11-16T06:20:50.058Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "f4fede40ff254bea8ec349efada36835",
    "idx": 53,
    "time": "2020-11-16T06:20:50.061Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "40c5cec225f14c448c18018e24ac40dc",
    "idx": 54,
    "time": "2020-11-16T06:20:50.064Z",
    "type": "execution"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:20:50.070Z",
    "type": "execution"
   },
   {
    "id": "d619bd76ba004d298e6d7d9d623013e3",
    "time": "2020-11-16T06:20:50.592Z",
    "type": "completion"
   },
   {
    "id": "b804e1d55a02482c989b78bed6ce2a4a",
    "time": "2020-11-16T06:20:50.593Z",
    "type": "completion"
   },
   {
    "id": "38d407e273034240b919d579faaba3ff",
    "time": "2020-11-16T06:20:51.380Z",
    "type": "completion"
   },
   {
    "id": "e19fad9da5e941db8bbde0836e06c8ef",
    "time": "2020-11-16T06:20:51.824Z",
    "type": "completion"
   },
   {
    "id": "92f2c9f609fe430d81720dc77fb20ee6",
    "time": "2020-11-16T06:20:51.881Z",
    "type": "completion"
   },
   {
    "id": "25e8d4bef8a14cc7aa85b8c2643179de",
    "time": "2020-11-16T06:20:51.883Z",
    "type": "completion"
   },
   {
    "id": "6d92146dad1148e182afc964d87665ee",
    "time": "2020-11-16T06:20:51.895Z",
    "type": "completion"
   },
   {
    "id": "c884952550a14cb0874ee85bdf9cfafa",
    "time": "2020-11-16T06:20:51.936Z",
    "type": "completion"
   },
   {
    "id": "a88792c9c6384c3b91383d1eda0a3be5",
    "time": "2020-11-16T06:20:51.982Z",
    "type": "completion"
   },
   {
    "id": "a9e67a680a67486280b432cbe1b6b610",
    "time": "2020-11-16T06:20:51.989Z",
    "type": "completion"
   },
   {
    "id": "93d63e91da8b43a58c35e32943c9aa1b",
    "time": "2020-11-16T06:20:52.054Z",
    "type": "completion"
   },
   {
    "id": "2ef5e737109b47ba874b8a7fb752c392",
    "time": "2020-11-16T06:20:52.055Z",
    "type": "completion"
   },
   {
    "id": "d1c534b07468451e824e7b80f52fb70f",
    "time": "2020-11-16T06:20:52.122Z",
    "type": "completion"
   },
   {
    "id": "86a6913dd6fb4185a193d7df00f5a297",
    "time": "2020-11-16T06:20:52.146Z",
    "type": "completion"
   },
   {
    "id": "7dfc86cf6a62427d849e0c086b04b560",
    "time": "2020-11-16T06:20:52.633Z",
    "type": "completion"
   },
   {
    "id": "cd937080e33e4c628160900e27624cc8",
    "time": "2020-11-16T06:20:53.297Z",
    "type": "completion"
   },
   {
    "id": "37d6fd54149846c3ac09d16fb2da17a9",
    "time": "2020-11-16T06:20:53.373Z",
    "type": "completion"
   },
   {
    "id": "c489b03c2bb54d5483faa77f25914dfe",
    "time": "2020-11-16T06:20:53.447Z",
    "type": "completion"
   },
   {
    "id": "40c27591e6d24929b1bed0ba884935b0",
    "time": "2020-11-16T06:20:53.658Z",
    "type": "completion"
   },
   {
    "id": "5bd0490c799746ba8a512272769af41f",
    "time": "2020-11-16T06:20:53.668Z",
    "type": "completion"
   },
   {
    "id": "47ec41dd092a47d4b643c6a790ab9813",
    "time": "2020-11-16T06:20:53.670Z",
    "type": "completion"
   },
   {
    "id": "debe0f3b24f94c7085daac983292d151",
    "time": "2020-11-16T06:20:53.673Z",
    "type": "completion"
   },
   {
    "id": "5ebdc928dc5e4287ada5aea313da6e24",
    "time": "2020-11-16T06:20:53.675Z",
    "type": "completion"
   },
   {
    "id": "3ae32ac9c7014b6d8c345b07ce9b198e",
    "time": "2020-11-16T06:20:53.678Z",
    "type": "completion"
   },
   {
    "id": "f4fede40ff254bea8ec349efada36835",
    "time": "2020-11-16T06:20:53.679Z",
    "type": "completion"
   },
   {
    "id": "40c5cec225f14c448c18018e24ac40dc",
    "time": "2020-11-16T06:20:53.734Z",
    "type": "completion"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:21:02.675Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:21:43.227Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:21:52.026Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split().stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:23:20.617Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:23:21.548Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:23:36.995Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:23:43.573Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format['word'].count_values()\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:24:43.315Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:24:52.197Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\ntidy_format['word'].value_counts()\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:25:09.291Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:25:18.671Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nnew_table = tidy_format['word'].value_counts().to_frame()\nnew_table\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:26:30.232Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:26:39.587Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nnew_table = tidy_format['word'].value_counts()[:50]\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:27:14.324Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:27:22.958Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[:50]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:27:37.038Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:27:45.976Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'nbsp',\n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:28:31.950Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:28:33.719Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', \n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:29:02.700Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:29:04.708Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d'\n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:29:28.389Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:29:30.057Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d',\n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:29:55.304Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:29:57.085Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td',\n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'don', 'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:30:06.353Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:30:08.109Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td',\n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:30:22.082Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:30:23.866Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td',\n         'nomore2001', 'com', 'reply', 'news', 'desire', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:30:59.834Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:31:01.559Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'br',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:31:20.324Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:31:22.095Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:31:41.564Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:31:43.547Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'tr',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:32:04.396Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:32:06.156Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:32:22.230Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:32:24.006Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:32:55.422Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:32:57.265Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'face',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:33:38.676Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:33:40.510Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'center',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:33:52.605Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:33:54.462Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'verdana',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:34:08.525Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:34:10.357Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'border',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:34:25.685Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:34:27.690Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:34:46.327Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:34:48.107Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'arial',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:35:15.184Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:35:17.156Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'table',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:35:31.656Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:35:33.531Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:35:49.370Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:35:51.451Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:36:04.408Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:36:06.322Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[:100]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:36:24.402Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:36:33.907Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[:60]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:36:47.672Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:36:56.832Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:37:13.945Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:37:15.797Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', \n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:37:23.178Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:37:25.008Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:37:43.233Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:37:45.073Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:37:58.140Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:38:00.168Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'img',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:39:13.237Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:39:15.102Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:39:39.453Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:39:41.550Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:39:59.110Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:40:01.036Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:40:16.726Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:40:18.653Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'nbsp',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:41:06.520Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:41:08.568Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[60:100]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:41:34.649Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:41:43.554Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'bgcolor',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:41:56.549Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:41:58.870Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', '3e',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:42:12.269Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:42:14.144Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:42:26.598Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:42:28.533Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'images',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:43:02.166Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:43:04.095Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', '000000',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:43:17.431Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:43:19.430Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'option',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:43:36.704Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:43:38.805Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'cellspacing',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:43:54.168Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:43:56.096Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'free',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:44:11.929Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:44:13.939Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'cellpadding',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:44:32.862Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:44:34.810Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:44:55.602Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:44:57.556Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:45:07.610Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:45:09.892Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:45:15.267Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:45:17.216Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:45:38.697Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:45:40.545Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please','jabber']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:45:49.394Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:45:51.235Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:46:16.539Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:46:18.353Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:46:28.227Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:46:30.106Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:47:11.068Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:47:12.931Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:47:20.597Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:47:22.443Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:47:43.725Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:47:45.682Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:48:10.511Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:48:12.437Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'content',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:48:34.758Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:48:36.596Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'span',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:48:58.048Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:48:59.904Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[100:150]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:49:16.258Z",
    "type": "execution"
   },
   {
    "code": "ham_email = train[train[\"spam\"] == 0][\"email\"]\npunct_re = r'[^\\w\\s]'\nham_email = ham_email.str.replace(punct_re, \" \")",
    "id": "1870d235f4504b00a5ddc7172906fdc2",
    "idx": 65,
    "time": "2020-11-16T06:49:17.918Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:49:25.610Z",
    "type": "completion"
   },
   {
    "id": "1870d235f4504b00a5ddc7172906fdc2",
    "time": "2020-11-16T06:49:26.369Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'blockquote',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:49:43.714Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:49:45.566Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'li',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:50:01.778Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:50:03.913Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'colspan',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:50:22.051Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:50:24.000Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'ff0000',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:50:43.644Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:50:45.484Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', '3c',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:51:23.540Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:51:25.656Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:51:31.092Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:51:33.018Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'margin',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:51:51.173Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:51:53.078Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:52:18.750Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:52:20.611Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'order',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:52:39.436Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:52:41.424Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'form',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:52:57.951Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:53:00.068Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:53:15.927Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:53:18.466Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:53:36.119Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:53:37.985Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:53:45.561Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:53:47.436Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'information',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:54:09.873Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:54:11.782Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'valign',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:54:29.402Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:54:31.366Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'title',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:54:46.994Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:54:49.205Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:55:07.931Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:55:09.848Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:55:19.251Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:55:21.156Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', '%',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:55:38.620Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:55:40.626Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[150:200]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T06:55:52.068Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T06:56:01.460Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'mso',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:56:14.157Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:56:16.327Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'tbody',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:56:33.292Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:56:35.324Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'htm',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:56:58.109Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:57:00.183Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'jpg',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:57:25.310Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:57:28.346Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', \n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:57:33.990Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:57:36.018Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'charset',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:57:55.703Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:57:57.685Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'iiq',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:58:17.967Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:58:19.994Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'mailto',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:58:38.328Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:58:40.446Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'bottom',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:58:55.769Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:58:57.830Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'meta',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:59:17.457Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:59:19.583Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', '3d2',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:59:34.858Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:59:36.935Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'tahoma',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T06:59:49.898Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T06:59:51.854Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:00:17.707Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:00:19.698Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', \n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:00:29.492Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:00:31.437Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:00:39.014Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:00:41.626Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:01:21.853Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:01:23.977Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'report',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:01:42.477Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:01:44.577Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'program',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:01:57.494Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:01:59.517Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'c',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:02:31.279Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:02:33.482Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:02:43.704Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:02:45.838Z",
    "type": "completion"
   },
   {
    "code": "test_predictions = model2.predict(words_in_texts(words2, test['email']))",
    "id": "401b8d5b494148df887a97556a07132f",
    "idx": 71,
    "time": "2020-11-16T07:02:55.985Z",
    "type": "execution"
   },
   {
    "id": "401b8d5b494148df887a97556a07132f",
    "time": "2020-11-16T07:02:56.266Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q10\")",
    "id": "b11a4ca6c04d4e4a87c5d89b88defa5e",
    "idx": 72,
    "time": "2020-11-16T07:02:56.913Z",
    "type": "execution"
   },
   {
    "id": "b11a4ca6c04d4e4a87c5d89b88defa5e",
    "time": "2020-11-16T07:02:57.082Z",
    "type": "completion"
   },
   {
    "code": "from datetime import datetime\n\n# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n\n# Construct and save the submission:\nsubmission_df = pd.DataFrame({\n    \"Id\": test['id'], \n    \"Class\": test_predictions,\n}, columns=['Id', 'Class'])\ntimestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\nsubmission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n\nprint('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\nprint('You may now upload this CSV file to Gradescope for scoring.')",
    "id": "1a001e44233c43e196c1791b7933fc9a",
    "idx": 74,
    "time": "2020-11-16T07:02:58.335Z",
    "type": "execution"
   },
   {
    "id": "1a001e44233c43e196c1791b7933fc9a",
    "time": "2020-11-16T07:02:58.504Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[200:250]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T07:06:31.870Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T07:06:41.719Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'insurance']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:07:08.226Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:07:10.363Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'bordercolor']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:07:27.793Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:07:29.926Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'asp']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:07:49.306Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:07:51.335Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', '3darial']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:08:03.139Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:08:05.929Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', '2ffont']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:08:31.341Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:08:33.417Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'software']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:09:10.338Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:09:12.425Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'million']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:09:30.683Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:09:32.769Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'link']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:09:53.694Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:09:56.068Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'transfer']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:10:11.805Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:10:13.869Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', '3cfont']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:10:35.053Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:10:37.022Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', '3dcenter']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:10:54.448Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:10:56.348Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'government']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:11:09.448Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:11:11.415Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:11:26.897Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:11:29.058Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', 'legal',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:11:46.561Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:11:48.819Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', 'call',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:12:00.487Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:12:02.486Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', 'help',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:12:14.787Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:12:16.986Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', \n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:12:25.474Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:12:27.510Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', 'help',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:12:34.418Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:12:37.103Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:13:01.898Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:13:04.122Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[250:300]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T07:14:05.652Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T07:14:14.555Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'encoding',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:14:36.637Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:14:38.706Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'online',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:14:52.645Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:14:54.934Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'addresses',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:15:12.786Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:15:14.988Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'price',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:15:31.060Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:15:33.168Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'contact',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:15:46.491Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:15:48.494Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'equiv',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:16:15.685Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:16:17.793Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:16:26.388Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:16:28.859Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'grants',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:16:48.580Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:16:50.627Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', \n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:16:57.645Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:16:59.666Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'index',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:17:12.807Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:17:14.952Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'special',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:17:31.847Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:17:34.007Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'hidden',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:17:47.638Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:17:49.773Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'service',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:18:12.744Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:18:14.867Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:18:23.350Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:18:25.353Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[300:350]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T07:20:05.299Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T07:20:15.144Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'unsubscribe',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:20:43.117Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:20:45.269Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'ptsize',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:21:01.750Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:21:03.909Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'fax',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:21:24.854Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:21:26.964Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'product',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:21:50.784Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:21:52.954Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'financial',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:22:23.152Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:22:25.210Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:23:19.159Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:23:21.320Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:23:38.319Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:23:40.457Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[350:400]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "afb7c65e4df745099ca34997cbc69534",
    "idx": 64,
    "time": "2020-11-16T07:23:58.928Z",
    "type": "execution"
   },
   {
    "id": "afb7c65e4df745099ca34997cbc69534",
    "time": "2020-11-16T07:24:08.400Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'dollars',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:24:33.110Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:24:35.288Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'decoration',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:24:51.848Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:24:53.972Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'cost',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:25:30.743Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:25:32.960Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:25:58.304Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:26:00.482Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'rates',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:26:26.956Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:26:29.163Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'geneva',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:27:04.534Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:27:06.840Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "idx": 69,
    "time": "2020-11-16T07:27:13.046Z",
    "type": "execution"
   },
   {
    "id": "efdb0eac2e4b4c98aec6cd216aae8d4a",
    "time": "2020-11-16T07:27:15.202Z",
    "type": "completion"
   },
   {
    "code": "# Initialize Otter\nimport otter\ngrader = otter.Notebook()",
    "id": "9ae3e52e72ab4807994c9a3303152be9",
    "idx": 0,
    "time": "2020-11-17T05:23:04.969Z",
    "type": "execution"
   },
   {
    "code": "# Run this cell to suppress all FutureWarnings\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)",
    "id": "1a5ad3ca8d3d428f8066f5a064d11f43",
    "idx": 5,
    "time": "2020-11-17T05:23:04.979Z",
    "type": "execution"
   },
   {
    "code": "import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport seaborn as sns\nsns.set(style = \"whitegrid\", \n        color_codes = True,\n        font_scale = 1.5)",
    "id": "1ed8934afa98459f88d6afd9b1f682e3",
    "idx": 8,
    "time": "2020-11-17T05:23:04.983Z",
    "type": "execution"
   },
   {
    "code": "from utils import fetch_and_cache_gdrive\nfetch_and_cache_gdrive('1SCASpLZFKCp2zek-toR3xeKX3DZnBSyp', 'train.csv')\nfetch_and_cache_gdrive('1ZDFo9OTF96B5GP2Nzn8P8-AL7CTQXmC0', 'test.csv')\n\noriginal_training_data = pd.read_csv('data/train.csv')\ntest = pd.read_csv('data/test.csv')\n\n# Convert the emails to lower case as a first step to processing the text\noriginal_training_data['email'] = original_training_data['email'].str.lower()\ntest['email'] = test['email'].str.lower()\n\noriginal_training_data.head()",
    "id": "a8d9d7fca7c143be8448d1a3de229d76",
    "idx": 10,
    "time": "2020-11-17T05:23:04.987Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "ff0a5bae6321418387507db41337f600",
    "idx": 12,
    "time": "2020-11-17T05:23:04.991Z",
    "type": "execution"
   },
   {
    "code": "original_training_data['subject'].fillna('', inplace = True)",
    "id": "5e2fb29db5594f5e84a8f67b8a89748a",
    "idx": 13,
    "time": "2020-11-17T05:23:04.993Z",
    "type": "execution"
   },
   {
    "code": "original_training_data.isnull().sum()",
    "id": "f65affa98b2247b5b96200c5eed6b636",
    "idx": 14,
    "time": "2020-11-17T05:23:04.996Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1a\")",
    "id": "5110c769aecb4e6b82c052d7f11682fb",
    "idx": 15,
    "time": "2020-11-17T05:23:04.999Z",
    "type": "execution"
   },
   {
    "code": "first_ham = original_training_data[original_training_data['spam']==0]['email'].iloc[0]\nfirst_spam = original_training_data[original_training_data['spam']==1]['email'].iloc[0]\nprint(first_ham)\nprint(first_spam)",
    "id": "55b4c398288d4bb4b5412542d37a96fc",
    "idx": 17,
    "time": "2020-11-17T05:23:05.001Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q1b\")",
    "id": "41c01476da314b48a3760f034bf73535",
    "idx": 18,
    "time": "2020-11-17T05:23:05.004Z",
    "type": "execution"
   },
   {
    "code": "# This creates a 90/10 train-validation split on our labeled data\n\nfrom sklearn.model_selection import train_test_split\n\ntrain, val = train_test_split(original_training_data, test_size=0.1, random_state=42)",
    "id": "67fa715495304a96833ae152feee4540",
    "idx": 22,
    "time": "2020-11-17T05:23:05.007Z",
    "type": "execution"
   },
   {
    "code": "def words_in_texts(words, texts):\n    '''\n    Args:\n        words (list): words to find\n        texts (Series): strings to search in\n    \n    Returns:\n        NumPy array of 0s and 1s with shape (n, p) where n is the\n        number of texts and p is the number of words.\n    '''\n    indicator_array = np.array([[1 if i.find(j) != -1 else 0 for j in words] for i in texts])\n    return indicator_array",
    "id": "fe421dc0ff2745818491b4a3e4932301",
    "idx": 25,
    "time": "2020-11-17T05:23:05.010Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q2\")",
    "id": "a3811d65ca954815810d3ce3f3363315",
    "idx": 26,
    "time": "2020-11-17T05:23:05.014Z",
    "type": "execution"
   },
   {
    "code": "from IPython.display import display, Markdown\ndf = pd.DataFrame({\n    'word_1': [1, 0, 1, 0],\n    'word_2': [0, 1, 0, 1],\n    'type': ['spam', 'ham', 'ham', 'ham']\n})\ndisplay(Markdown(\"> Our Original DataFrame has a `type` column and some columns corresponding to words. You can think of each row as a sentence, and the value of 1 or 0 indicates the number of occurences of the word in this sentence.\"))\ndisplay(df);\ndisplay(Markdown(\"> `melt` will turn columns into entries in a variable column. Notice how `word_1` and `word_2` become entries in `variable`; their values are stored in the value column.\"))\ndisplay(df.melt(\"type\"))",
    "id": "57e0a7341d8640ee8576cdc693e68d45",
    "idx": 29,
    "time": "2020-11-17T05:23:05.018Z",
    "type": "execution"
   },
   {
    "code": "words = [\"sale\",\"credit\",\"link\",\"click\",\"off\",\"win\"]\ntemp = words_in_texts(words, train[\"email\"]).T\ndf = pd.DataFrame({\n    \"sale\":  temp[0],\n    \"credit\": temp[1],\n    \"link\": temp[2],\n    \"click\": temp[3],\n    \"off\": temp[4],\n    \"win\": temp[5],\n    'type': train[\"spam\"]\n})\ndf = df.melt(\"type\")\nd = df.groupby([\"type\",\"variable\"]).mean()\nd = d.reset_index()\nd = d.replace({\"type\":{0:\"Ham\", 1: \"Spam\"}})\nplt.figure(figsize=(8,8))\nsns.barplot(x=\"variable\", y=\"value\", hue=\"type\", data=d)\nplt.ylim(0, 1)\nplt.xlabel(\"Words\")\nplt.ylabel(\"Proportion of Emails\")\nplt.legend(title = \"\")\nplt.title(\"Frequency of Words in Spam/Ham Emails\");",
    "id": "3d233e212e724ad8a86c9912a874e0c3",
    "idx": 31,
    "time": "2020-11-17T05:23:05.021Z",
    "type": "execution"
   },
   {
    "code": "c = train.copy()\nc[\"length\"] = [len(i) for i in c[\"email\"]]\nx1 = c[c[\"spam\"] == 0][\"length\"]\nx2 = c[c[\"spam\"] == 1][\"length\"]\nplt.figure(figsize=(10,6))\nsns.distplot(x1, hist=False, label = \"Ham\")\nsns.distplot(x2, hist=False, label = \"Spam\")\nplt.legend()\nplt.xlim(0,50000)\nplt.ylabel(\"Distribution\")\nplt.xlabel(\"Length of email body\")\nplt.title(\"Distribution of Email Body Length\")\nplt.savefig('training_conditional_densities.png')",
    "id": "744e1bd068394bb38a9bd21f401b391f",
    "idx": 34,
    "time": "2020-11-17T05:23:05.024Z",
    "type": "execution"
   },
   {
    "code": "some_words = ['drug', 'bank', 'prescription', 'memo', 'private']\n\nX_train = words_in_texts(some_words, train[\"email\"])\nY_train = np.array(train[\"spam\"])\n\nX_train[:5], Y_train[:5]",
    "id": "91411a9bd8b84c2fbf81ced703763ee0",
    "idx": 37,
    "time": "2020-11-17T05:23:05.027Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q4\")",
    "id": "be1323d8fc8b48bfb18efc57f820ea76",
    "idx": 38,
    "time": "2020-11-17T05:23:05.030Z",
    "type": "execution"
   },
   {
    "code": "from sklearn.linear_model import LogisticRegression\n\nmodel = LogisticRegression()\nmodel.fit(X_train, Y_train)\n\ntraining_accuracy = model.score(X_train, Y_train)\nprint(\"Training Accuracy: \", training_accuracy)",
    "id": "f69548a2e5df40cb87cb45fb8a3f3099",
    "idx": 40,
    "time": "2020-11-17T05:23:05.033Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q5\")",
    "id": "4a8a828829334f7a805defc0b6b19237",
    "idx": 41,
    "time": "2020-11-17T05:23:05.037Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_fp = 0\nzero_predictor_fn = np.sum(Y_train != 0)\nzero_predictor_fp, zero_predictor_fn",
    "id": "7a0e7a65e2664b778360a3facdde3f38",
    "idx": 45,
    "time": "2020-11-17T05:23:05.041Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6a\")",
    "id": "94252a49d62b447b968b5682bdcd8135",
    "idx": 46,
    "time": "2020-11-17T05:23:05.044Z",
    "type": "execution"
   },
   {
    "code": "zero_predictor_acc = np.sum(Y_train == 0)/np.sum((Y_train == 0) | (Y_train == 1))\nzero_predictor_recall = 0\nzero_predictor_acc, zero_predictor_recall",
    "id": "56318b911edf455eac2f6f09a49c256d",
    "idx": 48,
    "time": "2020-11-17T05:23:05.047Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6b\")",
    "id": "41487c3d99a14004938359fb500df41d",
    "idx": 49,
    "time": "2020-11-17T05:23:05.050Z",
    "type": "execution"
   },
   {
    "code": "pred = model.predict(X_train)\nTP = np.sum((pred == Y_train) & (Y_train == 1))\nTN = np.sum((pred == Y_train) & (Y_train == 0))\nFP = np.sum((pred != Y_train) & (Y_train == 0))\nFN = np.sum((pred != Y_train) & (Y_train == 1))\nlogistic_predictor_precision = TP/(TP+FP)\nlogistic_predictor_recall = TP/(TP+FN)\nlogistic_predictor_far = FP/(FP+TN)",
    "id": "073a0a91fa31410899a23159823c0c1a",
    "idx": 53,
    "time": "2020-11-17T05:23:05.054Z",
    "type": "execution"
   },
   {
    "code": "grader.check(\"q6d\")",
    "id": "00564ed9b84941208310a5f1052a430d",
    "idx": 54,
    "time": "2020-11-17T05:23:05.057Z",
    "type": "execution"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[350:400]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:23:05.064Z",
    "type": "execution"
   },
   {
    "id": "9ae3e52e72ab4807994c9a3303152be9",
    "time": "2020-11-17T05:23:05.633Z",
    "type": "completion"
   },
   {
    "id": "1a5ad3ca8d3d428f8066f5a064d11f43",
    "time": "2020-11-17T05:23:05.635Z",
    "type": "completion"
   },
   {
    "id": "1ed8934afa98459f88d6afd9b1f682e3",
    "time": "2020-11-17T05:23:06.642Z",
    "type": "completion"
   },
   {
    "id": "a8d9d7fca7c143be8448d1a3de229d76",
    "time": "2020-11-17T05:23:07.320Z",
    "type": "completion"
   },
   {
    "id": "ff0a5bae6321418387507db41337f600",
    "time": "2020-11-17T05:23:07.327Z",
    "type": "completion"
   },
   {
    "id": "5e2fb29db5594f5e84a8f67b8a89748a",
    "time": "2020-11-17T05:23:07.379Z",
    "type": "completion"
   },
   {
    "id": "f65affa98b2247b5b96200c5eed6b636",
    "time": "2020-11-17T05:23:07.428Z",
    "type": "completion"
   },
   {
    "id": "5110c769aecb4e6b82c052d7f11682fb",
    "time": "2020-11-17T05:23:07.522Z",
    "type": "completion"
   },
   {
    "id": "55b4c398288d4bb4b5412542d37a96fc",
    "time": "2020-11-17T05:23:07.529Z",
    "type": "completion"
   },
   {
    "id": "41c01476da314b48a3760f034bf73535",
    "time": "2020-11-17T05:23:07.586Z",
    "type": "completion"
   },
   {
    "id": "67fa715495304a96833ae152feee4540",
    "time": "2020-11-17T05:23:07.716Z",
    "type": "completion"
   },
   {
    "id": "fe421dc0ff2745818491b4a3e4932301",
    "time": "2020-11-17T05:23:07.720Z",
    "type": "completion"
   },
   {
    "id": "a3811d65ca954815810d3ce3f3363315",
    "time": "2020-11-17T05:23:07.811Z",
    "type": "completion"
   },
   {
    "id": "57e0a7341d8640ee8576cdc693e68d45",
    "time": "2020-11-17T05:23:07.879Z",
    "type": "completion"
   },
   {
    "id": "3d233e212e724ad8a86c9912a874e0c3",
    "time": "2020-11-17T05:23:08.436Z",
    "type": "completion"
   },
   {
    "id": "744e1bd068394bb38a9bd21f401b391f",
    "time": "2020-11-17T05:23:09.162Z",
    "type": "completion"
   },
   {
    "id": "91411a9bd8b84c2fbf81ced703763ee0",
    "time": "2020-11-17T05:23:09.676Z",
    "type": "completion"
   },
   {
    "id": "be1323d8fc8b48bfb18efc57f820ea76",
    "time": "2020-11-17T05:23:09.713Z",
    "type": "completion"
   },
   {
    "id": "f69548a2e5df40cb87cb45fb8a3f3099",
    "time": "2020-11-17T05:23:09.721Z",
    "type": "completion"
   },
   {
    "id": "4a8a828829334f7a805defc0b6b19237",
    "time": "2020-11-17T05:23:09.723Z",
    "type": "completion"
   },
   {
    "id": "7a0e7a65e2664b778360a3facdde3f38",
    "time": "2020-11-17T05:23:09.725Z",
    "type": "completion"
   },
   {
    "id": "94252a49d62b447b968b5682bdcd8135",
    "time": "2020-11-17T05:23:09.769Z",
    "type": "completion"
   },
   {
    "id": "56318b911edf455eac2f6f09a49c256d",
    "time": "2020-11-17T05:23:09.776Z",
    "type": "completion"
   },
   {
    "id": "41487c3d99a14004938359fb500df41d",
    "time": "2020-11-17T05:23:09.788Z",
    "type": "completion"
   },
   {
    "id": "073a0a91fa31410899a23159823c0c1a",
    "time": "2020-11-17T05:23:09.795Z",
    "type": "completion"
   },
   {
    "id": "00564ed9b84941208310a5f1052a430d",
    "time": "2020-11-17T05:23:09.857Z",
    "type": "completion"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:23:21.164Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:23:59.380Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:24:01.554Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'bd',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:24:32.566Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:24:35.031Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'linux ',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:24:57.077Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:24:59.470Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[400:450]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:25:08.813Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:25:19.020Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[400:450]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:25:23.229Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:25:33.225Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:26:02.851Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:26:05.087Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'php',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:26:30.955Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:26:33.177Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:26:45.381Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:26:47.865Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'interest',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:27:11.028Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:27:13.297Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'account',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:27:24.150Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:27:26.469Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'buy',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:27:47.661Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:27:49.899Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:28:08.759Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:28:11.030Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'target',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:28:37.015Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:28:39.293Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', \n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:28:46.599Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:28:49.113Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'website',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:29:12.584Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:29:14.953Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'bf',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:29:20.712Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:29:22.916Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:29:37.097Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:29:39.501Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[450:500]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:29:53.329Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:30:04.610Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:30:35.897Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:30:38.197Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', \n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:30:44.834Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:30:47.054Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:30:52.922Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:30:55.061Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'collapse',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:31:09.882Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:31:12.285Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'insuranceiq',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:31:50.547Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:31:52.899Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', \n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:31:59.835Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:32:02.245Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:32:26.020Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:32:28.471Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'hr',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:32:52.798Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:32:55.223Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'action',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:33:08.166Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:33:10.830Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'step',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:33:30.590Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:33:32.981Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'plain',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:34:03.959Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:34:06.402Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'page',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:34:12.207Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:34:14.583Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:34:19.799Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:34:22.120Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[500:550]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:34:33.200Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:34:44.179Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'spacer',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:35:05.057Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:35:07.423Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'receiving',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:35:21.009Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:35:23.455Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'transaction',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:35:35.298Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:35:37.655Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'sending',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:36:00.058Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:36:02.661Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'bin',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:36:22.908Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:36:25.301Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'grant',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:36:38.909Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:36:41.384Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'milf',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:37:19.549Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:37:22.561Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'bidi',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:37:36.166Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:37:38.567Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'provide',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:37:50.510Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:37:53.051Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'format',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:38:08.542Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:38:10.895Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'post',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:38:19.550Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:38:21.994Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:38:27.967Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:38:30.332Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[550:600]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:38:40.671Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:38:51.370Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'bonus',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:39:03.336Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:39:05.775Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'heaven',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:39:22.242Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:39:24.615Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'security',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:40:15.666Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:40:18.074Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'select',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:40:31.171Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:40:33.503Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'printable',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:40:47.940Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:40:50.404Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'quoted',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:41:11.837Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:41:14.186Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'rowspan',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:41:25.883Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:41:28.348Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'required',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:41:49.229Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:41:51.594Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'policy',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:42:08.070Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:42:10.460Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'shipping',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:42:18.454Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:42:20.807Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[600:650]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:42:37.151Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:42:48.148Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'membership',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:43:02.119Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:43:04.551Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'bulk',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:43:59.848Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:44:02.503Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'advertising',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:44:22.049Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:44:24.652Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'interested',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:44:50.962Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:44:53.457Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:44:58.865Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:45:01.363Z",
    "type": "completion"
   },
   {
    "code": "test_predictions = model2.predict(words_in_texts(words2, test['email']))",
    "id": "4da3c4f2349840218206f9010372615e",
    "idx": 71,
    "time": "2020-11-17T05:45:19.498Z",
    "type": "execution"
   },
   {
    "id": "4da3c4f2349840218206f9010372615e",
    "time": "2020-11-17T05:45:19.842Z",
    "type": "completion"
   },
   {
    "code": "grader.check(\"q10\")",
    "id": "7ebf00e08d2340f19c3dc5d0cdf5a7e7",
    "idx": 72,
    "time": "2020-11-17T05:45:20.330Z",
    "type": "execution"
   },
   {
    "id": "7ebf00e08d2340f19c3dc5d0cdf5a7e7",
    "time": "2020-11-17T05:45:20.505Z",
    "type": "completion"
   },
   {
    "code": "from datetime import datetime\n\n# Assuming that your predictions on the test set are stored in a 1-dimensional array called\n# test_predictions. Feel free to modify this cell as long you create a CSV in the right format.\n\n# Construct and save the submission:\nsubmission_df = pd.DataFrame({\n    \"Id\": test['id'], \n    \"Class\": test_predictions,\n}, columns=['Id', 'Class'])\ntimestamp = datetime.isoformat(datetime.now()).split(\".\")[0]\nsubmission_df.to_csv(\"submission_{}.csv\".format(timestamp), index=False)\n\nprint('Created a CSV file: {}.'.format(\"submission_{}.csv\".format(timestamp)))\nprint('You may now upload this CSV file to Gradescope for scoring.')",
    "id": "9d2051088fcd40fa802408d8cdff4059",
    "idx": 74,
    "time": "2020-11-17T05:45:21.832Z",
    "type": "execution"
   },
   {
    "id": "9d2051088fcd40fa802408d8cdff4059",
    "time": "2020-11-17T05:45:21.981Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[650:700]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:48:09.002Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:48:19.702Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'application',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:48:44.694Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:48:47.088Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'deal',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:48:53.398Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:48:56.034Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'jeweldive',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:49:14.367Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:49:16.860Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'paid',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:49:43.760Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:49:46.142Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'quality',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:50:07.273Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:50:09.799Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'support',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:50:20.711Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:50:23.107Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'customer',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:50:36.857Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:50:39.405Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'yahoo',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:50:57.360Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:50:59.749Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:51:06.154Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:51:08.509Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[700:750]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:54:17.571Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:54:28.129Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','msonormal',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:54:49.287Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:54:51.804Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','netnoteinc',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:55:05.215Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:55:07.841Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','users',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:55:32.288Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:55:34.734Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','nasty',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:55:45.864Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:55:48.296Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','debt',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:56:02.058Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:56:04.635Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','download',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:56:17.147Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:56:19.600Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','trading ',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:56:43.906Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:56:46.275Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','loan',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:56:56.459Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:56:59.223Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','apply',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:57:20.667Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:57:23.241Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang','case',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:57:32.300Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:57:34.758Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:57:52.432Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:57:54.793Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:58:26.005Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:58:28.689Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:58:33.853Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:58:36.204Z",
    "type": "completion"
   },
   {
    "code": "spam_email = train[train[\"spam\"] == 1][\"email\"]\npunct_re = r'[^\\w\\s]'\nspam_email = spam_email.str.replace(punct_re, \" \")\ntidy_format = spam_email.str.split(expand=True).stack().reset_index(level=1).rename(columns = {\"level_1\":\"num\", 0:\"word\"})\ntidy_format.index.name = None\nn = tidy_format['word'].value_counts()[750:800]\nn\n# tidy_format.sort_values(by='num', ascending=False).tail(30)",
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "idx": 64,
    "time": "2020-11-17T05:58:53.861Z",
    "type": "execution"
   },
   {
    "id": "bdcc902c90c7432497e25902faeefc3d",
    "time": "2020-11-17T05:59:04.059Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'spam',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:59:21.528Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:59:23.947Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'database',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T05:59:40.104Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T05:59:42.545Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'assistance',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:00:04.976Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:00:07.604Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'earn',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:00:23.321Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:00:26.369Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'botanical',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:00:50.756Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:00:53.351Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', 'subscription',\n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:01:07.034Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:01:09.966Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:01:20.388Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:01:22.742Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nX_train2[X_train2 != Y_train]\n# model2 = LogisticRegression(solver = 'lbfgs')\n# model2.fit(X_train2, Y_train)\n\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:02:45.139Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:02:46.973Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nX_train2[X_train2 != Y_train].value_counts()\n# model2 = LogisticRegression(solver = 'lbfgs')\n# model2.fit(X_train2, Y_train)\n\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:03:38.727Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:03:40.676Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nY_train\n# model2 = LogisticRegression(solver = 'lbfgs')\n# model2.fit(X_train2, Y_train)\n\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:05:02.086Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:05:04.018Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:05:49.550Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:05:51.941Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\np\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:07:06.713Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:07:08.718Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\np != Y_train\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:07:45.473Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:07:47.668Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\n[(p != Y_train) == True]\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:08:12.091Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:08:14.304Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nsum(p != Y_train)\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:08:45.372Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:08:47.657Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nsum(p != Y_train)/len(Y_train)\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:08:58.996Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:09:01.197Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\n(p != Y_train).index()\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:10:09.464Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:10:11.796Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_tain[i]:\n        index.append(i)\nindex\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:12:27.286Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:12:29.700Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\n# accuracy2 = model2.score(X_train2, Y_train)\n# print(accuracy2)\n\n# pred2 = model2.predict_proba(X_train2)\n\n# FPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\n# plt.plot(FPR, TPR)\n# plt.xlabel('FPR')\n# plt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:12:36.883Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:12:38.985Z",
    "type": "completion"
   },
   {
    "code": "train[7]",
    "id": "cff02b30274545ab9738ee2a20220302",
    "idx": 70,
    "time": "2020-11-17T06:13:31.846Z",
    "type": "execution"
   },
   {
    "id": "cff02b30274545ab9738ee2a20220302",
    "time": "2020-11-17T06:13:32.014Z",
    "type": "completion"
   },
   {
    "code": "train['eamil'][7]",
    "id": "cff02b30274545ab9738ee2a20220302",
    "idx": 70,
    "time": "2020-11-17T06:14:03.063Z",
    "type": "execution"
   },
   {
    "id": "cff02b30274545ab9738ee2a20220302",
    "time": "2020-11-17T06:14:03.218Z",
    "type": "completion"
   },
   {
    "code": "train['email'][7]",
    "id": "cff02b30274545ab9738ee2a20220302",
    "idx": 70,
    "time": "2020-11-17T06:14:14.280Z",
    "type": "execution"
   },
   {
    "id": "cff02b30274545ab9738ee2a20220302",
    "time": "2020-11-17T06:14:14.368Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing', 'corporate']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:15:22.353Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:15:24.709Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing', 'jackpots']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:16:03.764Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:16:06.060Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing', 'fortunate']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:16:51.325Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:16:53.812Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing', 'mindupmerchants']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:17:13.325Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:17:15.678Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing', 'href']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:17:41.820Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:17:44.906Z",
    "type": "completion"
   },
   {
    "code": "train['email'][13]",
    "id": "cff02b30274545ab9738ee2a20220302",
    "idx": 70,
    "time": "2020-11-17T06:18:26.807Z",
    "type": "execution"
   },
   {
    "id": "cff02b30274545ab9738ee2a20220302",
    "time": "2020-11-17T06:18:26.916Z",
    "type": "completion"
   },
   {
    "code": "train['email'][13]",
    "id": "cff02b30274545ab9738ee2a20220302",
    "idx": 70,
    "time": "2020-11-17T06:18:31.439Z",
    "type": "execution"
   },
   {
    "id": "cff02b30274545ab9738ee2a20220302",
    "time": "2020-11-17T06:18:31.511Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing', 'copyrighted']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:18:45.096Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:18:48.728Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing', 'unauthorized']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:19:25.732Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:19:28.268Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing', 'lawsuits']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:19:47.061Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:19:49.457Z",
    "type": "completion"
   },
   {
    "code": "train['email'][24]",
    "id": "cff02b30274545ab9738ee2a20220302",
    "idx": 70,
    "time": "2020-11-17T06:20:48.021Z",
    "type": "execution"
   },
   {
    "id": "cff02b30274545ab9738ee2a20220302",
    "time": "2020-11-17T06:20:48.128Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing','messages']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:21:18.911Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:21:21.237Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing','copyright']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:21:38.296Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:21:40.714Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing','preferences']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\np = model2.predict(X_train2)\nindex = []\nfor i in range(len(Y_train)):\n    if p[i] != Y_train[i]:\n        index.append(i)\nindex\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "idx": 71,
    "time": "2020-11-17T06:22:05.478Z",
    "type": "execution"
   },
   {
    "id": "c38d6589f07c41f29c8a24c2aab4779f",
    "time": "2020-11-17T06:22:08.053Z",
    "type": "completion"
   },
   {
    "code": "train['email'][99]",
    "id": "cff02b30274545ab9738ee2a20220302",
    "idx": 70,
    "time": "2020-11-17T06:22:17.096Z",
    "type": "execution"
   },
   {
    "id": "cff02b30274545ab9738ee2a20220302",
    "time": "2020-11-17T06:22:17.230Z",
    "type": "completion"
   },
   {
    "code": "train['email'][7492]",
    "id": "cff02b30274545ab9738ee2a20220302",
    "idx": 70,
    "time": "2020-11-17T06:22:51.939Z",
    "type": "execution"
   },
   {
    "id": "cff02b30274545ab9738ee2a20220302",
    "time": "2020-11-17T06:22:52.384Z",
    "type": "completion"
   },
   {
    "code": "from sklearn.metrics import roc_curve\n\n# Note that you'll want to use the .predict_proba(...) method for your classifier\n# instead of .predict(...) so you get probabilities, not classes\n\nwords2 = ['message', 'removed', 'remove', 'mailto', '3d', 'td', 'width', 'ffffff', 'card',\n         'nomore2001', 'com', 'reply', 'news', 'desire', 'size', 'color', 'gif', 'response',\n         'held', 'bank', 'banks', 'clearance', 'days', 'payable', 'href', 'type', 'lang', \n         'communications', 'draft', 'new', 'check', 'information', 'helvetica', 'over', 'sansserif',\n          'original', 'list', 'sightings', 'spamassassin', 'listinfo', 'div', 'alt', 'investment',\n          'lists', 'sourceforge', 'https', 'xim', 'osdn', 'www', 'font', 'align', '0pt', 'opportunity',\n          'platform', 'time', 'deathtospamdeathtospamdeathtospam', 'serif', 'address', 'guaranteed',\n          'real', 'org', 'eleemosynary', 'enenkio', 'hermios', 'sf', 'src', 'receive', 'copy',\n         'click', 'cash', 'expire', 'mortgage', 'trade', 'credit', 'send', 'up', 'off', 'purchase',\n         'body','business','html','money','offer','please', 'marketing']\n\nX_train2 = words_in_texts(words2, train['email'])\n\nmodel2 = LogisticRegression(solver = 'lbfgs')\nmodel2.fit(X_train2, Y_train)\n\naccuracy2 = model2.score(X_train2, Y_train)\nprint(accuracy2)\n\npred2 = model2.predict_proba(X_train2)\n\nFPR, TPR, bound = roc_curve(Y_train, pred2[:, 1])\n\nplt.plot(FPR, TPR)\nplt.xlabel('FPR')\nplt.ylabel('TPR');\n",
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "idx": 69,
    "time": "2020-11-17T06:24:15.655Z",
    "type": "execution"
   },
   {
    "id": "d198cd31f912419ca5c58f4bf0ce75c7",
    "time": "2020-11-17T06:24:18.015Z",
    "type": "completion"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
